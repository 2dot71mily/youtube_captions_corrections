{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled transcripts example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the Fastai subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_titles', 'playlist_ids', 'channel_ids', 'autogen', 'manual',\n",
       "       'autogen_text', 'manual_text', 'diffs', 'common_to_both_seq',\n",
       "       'is_autogen_unique', 'is_manual_unique', 'autogen_seq', 'manual_seq',\n",
       "       'manual_addl_rep'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts=pd.read_json('~/youtube_captions_corrections/data/transcripts/en/labeled_transcripts/Jeremy_Howard.json')\n",
    "transcripts.columns   # DataFrame index is the `video_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_titles</th>\n",
       "      <th>playlist_ids</th>\n",
       "      <th>channel_ids</th>\n",
       "      <th>autogen</th>\n",
       "      <th>manual</th>\n",
       "      <th>autogen_text</th>\n",
       "      <th>manual_text</th>\n",
       "      <th>diffs</th>\n",
       "      <th>common_to_both_seq</th>\n",
       "      <th>is_autogen_unique</th>\n",
       "      <th>is_manual_unique</th>\n",
       "      <th>autogen_seq</th>\n",
       "      <th>manual_seq</th>\n",
       "      <th>manual_addl_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_QUEXsHfsA0</th>\n",
       "      <td>Lesson 1 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'so hello everybody and welcome to d...</td>\n",
       "      <td>[{'text': 'So hello everybody and welcome to D...</td>\n",
       "      <td>so hello everybody and welcome to deep learnin...</td>\n",
       "      <td>So hello everybody and welcome to Deep Learnin...</td>\n",
       "      <td>[{'-': ['so'], '+': ['So']}, hello, everybody,...</td>\n",
       "      <td>[, hello, everybody, and, welcome, to, , , for...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "      <td>[so, , , , , , deep, learning, , coders, lesso...</td>\n",
       "      <td>[So, , , , , , Deep Learning, Deep Learning, ,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BvHmRx14HQ8</th>\n",
       "      <td>Lesson 2 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'so uh hello everybody and welcome b...</td>\n",
       "      <td>[{'text': 'So, hello everybody, and welcome ba...</td>\n",
       "      <td>so uh hello everybody and welcome back to prac...</td>\n",
       "      <td>So, hello everybody, and welcome back to Pract...</td>\n",
       "      <td>[{'-': ['so', 'uh'], '+': ['So,']}, hello, {'-...</td>\n",
       "      <td>[, , hello, , and, welcome, back, to, , , , fo...</td>\n",
       "      <td>[2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[so, uh, , everybody, , , , , practical, deep,...</td>\n",
       "      <td>[So,, So,, , everybody,, , , , , Practical Dee...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5L3Ao5KuCC4</th>\n",
       "      <td>Lesson 3 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'oh hello and welcome to lesson thre...</td>\n",
       "      <td>[{'text': 'So hello, and welcome to Lesson 3 o...</td>\n",
       "      <td>oh hello and welcome to lesson three of practi...</td>\n",
       "      <td>So hello, and welcome to Lesson 3 of Practical...</td>\n",
       "      <td>[{'-': ['oh', 'hello'], '+': ['So', 'hello,']}...</td>\n",
       "      <td>[, , and, welcome, to, , , of, , , , for, , , ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[oh, hello, , , , lesson, three, , practical, ...</td>\n",
       "      <td>[So hello,, So hello,, , , , Lesson 3, Lesson ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p50s63nPq9I</th>\n",
       "      <td>Lesson 4 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'welcome back and here is lesson or ...</td>\n",
       "      <td>[{'text': 'Welcome back and here is lesson 4 w...</td>\n",
       "      <td>welcome back and here is lesson or which is wh...</td>\n",
       "      <td>Welcome back and here is lesson 4 which is\\nwh...</td>\n",
       "      <td>[{'-': ['welcome'], '+': ['Welcome']}, back, a...</td>\n",
       "      <td>[, back, and, here, is, lesson, , which, is, w...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[welcome, , , , , , or, , , , , , , , , , , , ...</td>\n",
       "      <td>[Welcome, , , , , , 4, , , , , , , , , , , , ,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krIVOb23EH8</th>\n",
       "      <td>Lesson 5 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'welcome to lesson five and we'll be...</td>\n",
       "      <td>[{'text': 'Welcome to lesson five and we'll be...</td>\n",
       "      <td>welcome to lesson five and we'll be talking ab...</td>\n",
       "      <td>Welcome to lesson five and we'll be talking\\na...</td>\n",
       "      <td>[{'-': ['welcome'], '+': ['Welcome']}, to, les...</td>\n",
       "      <td>[, to, lesson, five, and, we'll, be, talking, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[welcome, , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>[Welcome, , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           video_titles  \\\n",
       "_QUEXsHfsA0  Lesson 1 - Deep Learning for Coders (2020)   \n",
       "BvHmRx14HQ8  Lesson 2 - Deep Learning for Coders (2020)   \n",
       "5L3Ao5KuCC4  Lesson 3 - Deep Learning for Coders (2020)   \n",
       "p50s63nPq9I  Lesson 4 - Deep Learning for Coders (2020)   \n",
       "krIVOb23EH8  Lesson 5 - Deep Learning for Coders (2020)   \n",
       "\n",
       "                                   playlist_ids               channel_ids  \\\n",
       "_QUEXsHfsA0  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "BvHmRx14HQ8  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "5L3Ao5KuCC4  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "p50s63nPq9I  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "krIVOb23EH8  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "\n",
       "                                                       autogen  \\\n",
       "_QUEXsHfsA0  [{'text': 'so hello everybody and welcome to d...   \n",
       "BvHmRx14HQ8  [{'text': 'so uh hello everybody and welcome b...   \n",
       "5L3Ao5KuCC4  [{'text': 'oh hello and welcome to lesson thre...   \n",
       "p50s63nPq9I  [{'text': 'welcome back and here is lesson or ...   \n",
       "krIVOb23EH8  [{'text': 'welcome to lesson five and we'll be...   \n",
       "\n",
       "                                                        manual  \\\n",
       "_QUEXsHfsA0  [{'text': 'So hello everybody and welcome to D...   \n",
       "BvHmRx14HQ8  [{'text': 'So, hello everybody, and welcome ba...   \n",
       "5L3Ao5KuCC4  [{'text': 'So hello, and welcome to Lesson 3 o...   \n",
       "p50s63nPq9I  [{'text': 'Welcome back and here is lesson 4 w...   \n",
       "krIVOb23EH8  [{'text': 'Welcome to lesson five and we'll be...   \n",
       "\n",
       "                                                  autogen_text  \\\n",
       "_QUEXsHfsA0  so hello everybody and welcome to deep learnin...   \n",
       "BvHmRx14HQ8  so uh hello everybody and welcome back to prac...   \n",
       "5L3Ao5KuCC4  oh hello and welcome to lesson three of practi...   \n",
       "p50s63nPq9I  welcome back and here is lesson or which is wh...   \n",
       "krIVOb23EH8  welcome to lesson five and we'll be talking ab...   \n",
       "\n",
       "                                                   manual_text  \\\n",
       "_QUEXsHfsA0  So hello everybody and welcome to Deep Learnin...   \n",
       "BvHmRx14HQ8  So, hello everybody, and welcome back to Pract...   \n",
       "5L3Ao5KuCC4  So hello, and welcome to Lesson 3 of Practical...   \n",
       "p50s63nPq9I  Welcome back and here is lesson 4 which is\\nwh...   \n",
       "krIVOb23EH8  Welcome to lesson five and we'll be talking\\na...   \n",
       "\n",
       "                                                         diffs  \\\n",
       "_QUEXsHfsA0  [{'-': ['so'], '+': ['So']}, hello, everybody,...   \n",
       "BvHmRx14HQ8  [{'-': ['so', 'uh'], '+': ['So,']}, hello, {'-...   \n",
       "5L3Ao5KuCC4  [{'-': ['oh', 'hello'], '+': ['So', 'hello,']}...   \n",
       "p50s63nPq9I  [{'-': ['welcome'], '+': ['Welcome']}, back, a...   \n",
       "krIVOb23EH8  [{'-': ['welcome'], '+': ['Welcome']}, to, les...   \n",
       "\n",
       "                                            common_to_both_seq  \\\n",
       "_QUEXsHfsA0  [, hello, everybody, and, welcome, to, , , for...   \n",
       "BvHmRx14HQ8  [, , hello, , and, welcome, back, to, , , , fo...   \n",
       "5L3Ao5KuCC4  [, , and, welcome, to, , , of, , , , for, , , ...   \n",
       "p50s63nPq9I  [, back, and, here, is, lesson, , which, is, w...   \n",
       "krIVOb23EH8  [, to, lesson, five, and, we'll, be, talking, ...   \n",
       "\n",
       "                                             is_autogen_unique  \\\n",
       "_QUEXsHfsA0  [2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...   \n",
       "BvHmRx14HQ8  [2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "5L3Ao5KuCC4  [2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "p50s63nPq9I  [2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "krIVOb23EH8  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              is_manual_unique  \\\n",
       "_QUEXsHfsA0  [2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...   \n",
       "BvHmRx14HQ8  [2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "5L3Ao5KuCC4  [2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "p50s63nPq9I  [2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "krIVOb23EH8  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                   autogen_seq  \\\n",
       "_QUEXsHfsA0  [so, , , , , , deep, learning, , coders, lesso...   \n",
       "BvHmRx14HQ8  [so, uh, , everybody, , , , , practical, deep,...   \n",
       "5L3Ao5KuCC4  [oh, hello, , , , lesson, three, , practical, ...   \n",
       "p50s63nPq9I  [welcome, , , , , , or, , , , , , , , , , , , ...   \n",
       "krIVOb23EH8  [welcome, , , , , , , , , , , , , , , , , , , ...   \n",
       "\n",
       "                                                    manual_seq  \\\n",
       "_QUEXsHfsA0  [So, , , , , , Deep Learning, Deep Learning, ,...   \n",
       "BvHmRx14HQ8  [So,, So,, , everybody,, , , , , Practical Dee...   \n",
       "5L3Ao5KuCC4  [So hello,, So hello,, , , , Lesson 3, Lesson ...   \n",
       "p50s63nPq9I  [Welcome, , , , , , 4, , , , , , , , , , , , ,...   \n",
       "krIVOb23EH8  [Welcome, , , , , , , , , , , , , , , , , , , ...   \n",
       "\n",
       "                                               manual_addl_rep  \n",
       "_QUEXsHfsA0  [0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 3, 0, 0, ...  \n",
       "BvHmRx14HQ8  [1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, ...  \n",
       "5L3Ao5KuCC4  [1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, ...  \n",
       "p50s63nPq9I  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "krIVOb23EH8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_titles</th>\n",
       "      <th>playlist_ids</th>\n",
       "      <th>channel_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_QUEXsHfsA0</th>\n",
       "      <td>Lesson 1 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BvHmRx14HQ8</th>\n",
       "      <td>Lesson 2 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5L3Ao5KuCC4</th>\n",
       "      <td>Lesson 3 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p50s63nPq9I</th>\n",
       "      <td>Lesson 4 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krIVOb23EH8</th>\n",
       "      <td>Lesson 5 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cX30jxMNBUw</th>\n",
       "      <td>Lesson 6 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEG5xT5gAHc</th>\n",
       "      <td>Lesson 7 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WjnwWeGjZcM</th>\n",
       "      <td>Lesson 8 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XfoYk_Z5AkI</th>\n",
       "      <td>Lesson 1: Deep Learning 2019 - Image classific...</td>\n",
       "      <td>PLfYUBJiXbdtSIJb-Qd3pw0cqCbkGeS0xn</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccMHJeQU4Qw</th>\n",
       "      <td>Lesson 2: Deep Learning 2019 - Data cleaning a...</td>\n",
       "      <td>PLfYUBJiXbdtSIJb-Qd3pw0cqCbkGeS0xn</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPBSB1HLNLo</th>\n",
       "      <td>Lesson 1: Deep Learning 2018</td>\n",
       "      <td>PLfYUBJiXbdtS2UQRzyrxmyVHoGW0gmLSM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JNxcznsrRb8</th>\n",
       "      <td>Lesson 2: Deep Learning 2018</td>\n",
       "      <td>PLfYUBJiXbdtS2UQRzyrxmyVHoGW0gmLSM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CzdWqFTmn0Y</th>\n",
       "      <td>Intro to Machine Learning: Lesson 1</td>\n",
       "      <td>PLfYUBJiXbdtSyktd8A_x0JNd6lxDcZE96</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  video_titles  \\\n",
       "_QUEXsHfsA0         Lesson 1 - Deep Learning for Coders (2020)   \n",
       "BvHmRx14HQ8         Lesson 2 - Deep Learning for Coders (2020)   \n",
       "5L3Ao5KuCC4         Lesson 3 - Deep Learning for Coders (2020)   \n",
       "p50s63nPq9I         Lesson 4 - Deep Learning for Coders (2020)   \n",
       "krIVOb23EH8         Lesson 5 - Deep Learning for Coders (2020)   \n",
       "cX30jxMNBUw         Lesson 6 - Deep Learning for Coders (2020)   \n",
       "VEG5xT5gAHc         Lesson 7 - Deep Learning for Coders (2020)   \n",
       "WjnwWeGjZcM         Lesson 8 - Deep Learning for Coders (2020)   \n",
       "XfoYk_Z5AkI  Lesson 1: Deep Learning 2019 - Image classific...   \n",
       "ccMHJeQU4Qw  Lesson 2: Deep Learning 2019 - Data cleaning a...   \n",
       "IPBSB1HLNLo                       Lesson 1: Deep Learning 2018   \n",
       "JNxcznsrRb8                       Lesson 2: Deep Learning 2018   \n",
       "CzdWqFTmn0Y                Intro to Machine Learning: Lesson 1   \n",
       "\n",
       "                                   playlist_ids               channel_ids  \n",
       "_QUEXsHfsA0  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "BvHmRx14HQ8  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "5L3Ao5KuCC4  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "p50s63nPq9I  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "krIVOb23EH8  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "cX30jxMNBUw  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "VEG5xT5gAHc  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "WjnwWeGjZcM  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "XfoYk_Z5AkI  PLfYUBJiXbdtSIJb-Qd3pw0cqCbkGeS0xn  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "ccMHJeQU4Qw  PLfYUBJiXbdtSIJb-Qd3pw0cqCbkGeS0xn  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "IPBSB1HLNLo  PLfYUBJiXbdtS2UQRzyrxmyVHoGW0gmLSM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "JNxcznsrRb8  PLfYUBJiXbdtS2UQRzyrxmyVHoGW0gmLSM  UCX7Y2qWriXpqocG97SFW2OQ  \n",
       "CzdWqFTmn0Y  PLfYUBJiXbdtSyktd8A_x0JNd6lxDcZE96  UCX7Y2qWriXpqocG97SFW2OQ  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[['video_titles', 'playlist_ids', 'channel_ids']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript text and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autogen</th>\n",
       "      <th>manual</th>\n",
       "      <th>autogen_text</th>\n",
       "      <th>manual_text</th>\n",
       "      <th>diffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_QUEXsHfsA0</th>\n",
       "      <td>[{'text': 'so hello everybody and welcome to d...</td>\n",
       "      <td>[{'text': 'So hello everybody and welcome to D...</td>\n",
       "      <td>so hello everybody and welcome to deep learnin...</td>\n",
       "      <td>So hello everybody and welcome to Deep Learnin...</td>\n",
       "      <td>[{'-': ['so'], '+': ['So']}, hello, everybody,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BvHmRx14HQ8</th>\n",
       "      <td>[{'text': 'so uh hello everybody and welcome b...</td>\n",
       "      <td>[{'text': 'So, hello everybody, and welcome ba...</td>\n",
       "      <td>so uh hello everybody and welcome back to prac...</td>\n",
       "      <td>So, hello everybody, and welcome back to Pract...</td>\n",
       "      <td>[{'-': ['so', 'uh'], '+': ['So,']}, hello, {'-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5L3Ao5KuCC4</th>\n",
       "      <td>[{'text': 'oh hello and welcome to lesson thre...</td>\n",
       "      <td>[{'text': 'So hello, and welcome to Lesson 3 o...</td>\n",
       "      <td>oh hello and welcome to lesson three of practi...</td>\n",
       "      <td>So hello, and welcome to Lesson 3 of Practical...</td>\n",
       "      <td>[{'-': ['oh', 'hello'], '+': ['So', 'hello,']}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p50s63nPq9I</th>\n",
       "      <td>[{'text': 'welcome back and here is lesson or ...</td>\n",
       "      <td>[{'text': 'Welcome back and here is lesson 4 w...</td>\n",
       "      <td>welcome back and here is lesson or which is wh...</td>\n",
       "      <td>Welcome back and here is lesson 4 which is\\nwh...</td>\n",
       "      <td>[{'-': ['welcome'], '+': ['Welcome']}, back, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krIVOb23EH8</th>\n",
       "      <td>[{'text': 'welcome to lesson five and we'll be...</td>\n",
       "      <td>[{'text': 'Welcome to lesson five and we'll be...</td>\n",
       "      <td>welcome to lesson five and we'll be talking ab...</td>\n",
       "      <td>Welcome to lesson five and we'll be talking\\na...</td>\n",
       "      <td>[{'-': ['welcome'], '+': ['Welcome']}, to, les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cX30jxMNBUw</th>\n",
       "      <td>[{'text': 'hi everybody and welcome to lesson ...</td>\n",
       "      <td>[{'text': 'Hi everybody and welcome to Lesson ...</td>\n",
       "      <td>hi everybody and welcome to lesson six where w...</td>\n",
       "      <td>Hi everybody and welcome to Lesson 6, where\\nw...</td>\n",
       "      <td>[{'-': ['hi'], '+': ['Hi']}, everybody, and, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEG5xT5gAHc</th>\n",
       "      <td>[{'text': 'hi everybody and welcome to lesson ...</td>\n",
       "      <td>[{'text': 'Hi everybody and welcome to lesson ...</td>\n",
       "      <td>hi everybody and welcome to lesson 7 we're goi...</td>\n",
       "      <td>Hi everybody and welcome to lesson 7! We're\\ng...</td>\n",
       "      <td>[{'-': ['hi'], '+': ['Hi']}, everybody, and, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WjnwWeGjZcM</th>\n",
       "      <td>[{'text': 'hi everybody and welcome to lesson ...</td>\n",
       "      <td>[{'text': 'Hi everybody and welcome to lesson ...</td>\n",
       "      <td>hi everybody and welcome to lesson eight the l...</td>\n",
       "      <td>Hi everybody and welcome to lesson eight,\\nthe...</td>\n",
       "      <td>[{'-': ['hi'], '+': ['Hi']}, everybody, and, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XfoYk_Z5AkI</th>\n",
       "      <td>[{'text': 'okay so welcome practical deep lear...</td>\n",
       "      <td>[{'text': 'Okay', 'start': 0.159, 'duration': ...</td>\n",
       "      <td>okay so welcome practical deep learning for co...</td>\n",
       "      <td>Okay so Welcome Practical deep learning for co...</td>\n",
       "      <td>[{'-': ['okay'], '+': ['Okay']}, so, {'-': ['w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccMHJeQU4Qw</th>\n",
       "      <td>[{'text': 'welcome to lesson two where we're g...</td>\n",
       "      <td>[{'text': 'Welcome to Lesson 2 where we're goi...</td>\n",
       "      <td>welcome to lesson two where we're going to be ...</td>\n",
       "      <td>Welcome to Lesson 2 where we're going to be ta...</td>\n",
       "      <td>[{'-': ['welcome'], '+': ['Welcome']}, to, {'-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPBSB1HLNLo</th>\n",
       "      <td>[{'text': 'hi everybody welcome to practical d...</td>\n",
       "      <td>[{'text': 'Hi everybody welcome to practical d...</td>\n",
       "      <td>hi everybody welcome to practical deep learnin...</td>\n",
       "      <td>Hi everybody welcome to practical deep learnin...</td>\n",
       "      <td>[{'-': ['hi'], '+': ['Hi']}, everybody, welcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JNxcznsrRb8</th>\n",
       "      <td>[{'text': 'okay so welcome back to deep learni...</td>\n",
       "      <td>[{'text': 'Okay so welcome back to deep learni...</td>\n",
       "      <td>okay so welcome back to deep learning lesson 2...</td>\n",
       "      <td>Okay so welcome back to deep learning lesson 2...</td>\n",
       "      <td>[{'-': ['okay'], '+': ['Okay']}, so, welcome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CzdWqFTmn0Y</th>\n",
       "      <td>[{'text': 'Oh', 'start': 0.0, 'duration': 9.05...</td>\n",
       "      <td>[{'text': 'Okay, so let me introduce everybody...</td>\n",
       "      <td>Oh good okay so let me introduce everybody to ...</td>\n",
       "      <td>Okay, so let me introduce everybody to everybo...</td>\n",
       "      <td>[{'-': ['Oh', 'good', 'okay'], '+': ['Okay,']}...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       autogen  \\\n",
       "_QUEXsHfsA0  [{'text': 'so hello everybody and welcome to d...   \n",
       "BvHmRx14HQ8  [{'text': 'so uh hello everybody and welcome b...   \n",
       "5L3Ao5KuCC4  [{'text': 'oh hello and welcome to lesson thre...   \n",
       "p50s63nPq9I  [{'text': 'welcome back and here is lesson or ...   \n",
       "krIVOb23EH8  [{'text': 'welcome to lesson five and we'll be...   \n",
       "cX30jxMNBUw  [{'text': 'hi everybody and welcome to lesson ...   \n",
       "VEG5xT5gAHc  [{'text': 'hi everybody and welcome to lesson ...   \n",
       "WjnwWeGjZcM  [{'text': 'hi everybody and welcome to lesson ...   \n",
       "XfoYk_Z5AkI  [{'text': 'okay so welcome practical deep lear...   \n",
       "ccMHJeQU4Qw  [{'text': 'welcome to lesson two where we're g...   \n",
       "IPBSB1HLNLo  [{'text': 'hi everybody welcome to practical d...   \n",
       "JNxcznsrRb8  [{'text': 'okay so welcome back to deep learni...   \n",
       "CzdWqFTmn0Y  [{'text': 'Oh', 'start': 0.0, 'duration': 9.05...   \n",
       "\n",
       "                                                        manual  \\\n",
       "_QUEXsHfsA0  [{'text': 'So hello everybody and welcome to D...   \n",
       "BvHmRx14HQ8  [{'text': 'So, hello everybody, and welcome ba...   \n",
       "5L3Ao5KuCC4  [{'text': 'So hello, and welcome to Lesson 3 o...   \n",
       "p50s63nPq9I  [{'text': 'Welcome back and here is lesson 4 w...   \n",
       "krIVOb23EH8  [{'text': 'Welcome to lesson five and we'll be...   \n",
       "cX30jxMNBUw  [{'text': 'Hi everybody and welcome to Lesson ...   \n",
       "VEG5xT5gAHc  [{'text': 'Hi everybody and welcome to lesson ...   \n",
       "WjnwWeGjZcM  [{'text': 'Hi everybody and welcome to lesson ...   \n",
       "XfoYk_Z5AkI  [{'text': 'Okay', 'start': 0.159, 'duration': ...   \n",
       "ccMHJeQU4Qw  [{'text': 'Welcome to Lesson 2 where we're goi...   \n",
       "IPBSB1HLNLo  [{'text': 'Hi everybody welcome to practical d...   \n",
       "JNxcznsrRb8  [{'text': 'Okay so welcome back to deep learni...   \n",
       "CzdWqFTmn0Y  [{'text': 'Okay, so let me introduce everybody...   \n",
       "\n",
       "                                                  autogen_text  \\\n",
       "_QUEXsHfsA0  so hello everybody and welcome to deep learnin...   \n",
       "BvHmRx14HQ8  so uh hello everybody and welcome back to prac...   \n",
       "5L3Ao5KuCC4  oh hello and welcome to lesson three of practi...   \n",
       "p50s63nPq9I  welcome back and here is lesson or which is wh...   \n",
       "krIVOb23EH8  welcome to lesson five and we'll be talking ab...   \n",
       "cX30jxMNBUw  hi everybody and welcome to lesson six where w...   \n",
       "VEG5xT5gAHc  hi everybody and welcome to lesson 7 we're goi...   \n",
       "WjnwWeGjZcM  hi everybody and welcome to lesson eight the l...   \n",
       "XfoYk_Z5AkI  okay so welcome practical deep learning for co...   \n",
       "ccMHJeQU4Qw  welcome to lesson two where we're going to be ...   \n",
       "IPBSB1HLNLo  hi everybody welcome to practical deep learnin...   \n",
       "JNxcznsrRb8  okay so welcome back to deep learning lesson 2...   \n",
       "CzdWqFTmn0Y  Oh good okay so let me introduce everybody to ...   \n",
       "\n",
       "                                                   manual_text  \\\n",
       "_QUEXsHfsA0  So hello everybody and welcome to Deep Learnin...   \n",
       "BvHmRx14HQ8  So, hello everybody, and welcome back to Pract...   \n",
       "5L3Ao5KuCC4  So hello, and welcome to Lesson 3 of Practical...   \n",
       "p50s63nPq9I  Welcome back and here is lesson 4 which is\\nwh...   \n",
       "krIVOb23EH8  Welcome to lesson five and we'll be talking\\na...   \n",
       "cX30jxMNBUw  Hi everybody and welcome to Lesson 6, where\\nw...   \n",
       "VEG5xT5gAHc  Hi everybody and welcome to lesson 7! We're\\ng...   \n",
       "WjnwWeGjZcM  Hi everybody and welcome to lesson eight,\\nthe...   \n",
       "XfoYk_Z5AkI  Okay so Welcome Practical deep learning for co...   \n",
       "ccMHJeQU4Qw  Welcome to Lesson 2 where we're going to be ta...   \n",
       "IPBSB1HLNLo  Hi everybody welcome to practical deep learnin...   \n",
       "JNxcznsrRb8  Okay so welcome back to deep learning lesson 2...   \n",
       "CzdWqFTmn0Y  Okay, so let me introduce everybody to everybo...   \n",
       "\n",
       "                                                         diffs  \n",
       "_QUEXsHfsA0  [{'-': ['so'], '+': ['So']}, hello, everybody,...  \n",
       "BvHmRx14HQ8  [{'-': ['so', 'uh'], '+': ['So,']}, hello, {'-...  \n",
       "5L3Ao5KuCC4  [{'-': ['oh', 'hello'], '+': ['So', 'hello,']}...  \n",
       "p50s63nPq9I  [{'-': ['welcome'], '+': ['Welcome']}, back, a...  \n",
       "krIVOb23EH8  [{'-': ['welcome'], '+': ['Welcome']}, to, les...  \n",
       "cX30jxMNBUw  [{'-': ['hi'], '+': ['Hi']}, everybody, and, w...  \n",
       "VEG5xT5gAHc  [{'-': ['hi'], '+': ['Hi']}, everybody, and, w...  \n",
       "WjnwWeGjZcM  [{'-': ['hi'], '+': ['Hi']}, everybody, and, w...  \n",
       "XfoYk_Z5AkI  [{'-': ['okay'], '+': ['Okay']}, so, {'-': ['w...  \n",
       "ccMHJeQU4Qw  [{'-': ['welcome'], '+': ['Welcome']}, to, {'-...  \n",
       "IPBSB1HLNLo  [{'-': ['hi'], '+': ['Hi']}, everybody, welcom...  \n",
       "JNxcznsrRb8  [{'-': ['okay'], '+': ['Okay']}, so, welcome, ...  \n",
       "CzdWqFTmn0Y  [{'-': ['Oh', 'good', 'okay'], '+': ['Okay,']}...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[['autogen', 'manual','autogen_text', 'manual_text', 'diffs',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_autogen_unique</th>\n",
       "      <th>is_manual_unique</th>\n",
       "      <th>autogen_seq</th>\n",
       "      <th>manual_seq</th>\n",
       "      <th>manual_addl_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_QUEXsHfsA0</th>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "      <td>[so, , , , , , deep, learning, , coders, lesso...</td>\n",
       "      <td>[So, , , , , , Deep Learning, Deep Learning, ,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BvHmRx14HQ8</th>\n",
       "      <td>[2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[so, uh, , everybody, , , , , practical, deep,...</td>\n",
       "      <td>[So,, So,, , everybody,, , , , , Practical Dee...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5L3Ao5KuCC4</th>\n",
       "      <td>[2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[oh, hello, , , , lesson, three, , practical, ...</td>\n",
       "      <td>[So hello,, So hello,, , , , Lesson 3, Lesson ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p50s63nPq9I</th>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[welcome, , , , , , or, , , , , , , , , , , , ...</td>\n",
       "      <td>[Welcome, , , , , , 4, , , , , , , , , , , , ,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krIVOb23EH8</th>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[welcome, , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>[Welcome, , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cX30jxMNBUw</th>\n",
       "      <td>[2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[hi, , , , , lesson, six, , , , , , , , , , , ...</td>\n",
       "      <td>[Hi, , , , , Lesson 6,, Lesson 6,, , , , , , ,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEG5xT5gAHc</th>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[hi, , , , , , 7, we're, , , , , , , , , , , ,...</td>\n",
       "      <td>[Hi, , , , , , 7! We're, 7! We're, , , , , , ,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WjnwWeGjZcM</th>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[hi, , , , , , eight, , , , , , , , , course, ...</td>\n",
       "      <td>[Hi, , , , , , eight,, , , , , , , , , course....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XfoYk_Z5AkI</th>\n",
       "      <td>[2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[okay, , welcome, practical, , , , , , , , , ,...</td>\n",
       "      <td>[Okay, , Welcome Practical, Welcome Practical,...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccMHJeQU4Qw</th>\n",
       "      <td>[2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[welcome, , lesson, two, , , , , , , , , , , ,...</td>\n",
       "      <td>[Welcome, , Lesson 2, Lesson 2, , , , , , , , ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPBSB1HLNLo</th>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[hi, , , , , , , , , , , , , , , , course, , p...</td>\n",
       "      <td>[Hi, , , , , , , , , , , , , , , , course,, , ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JNxcznsrRb8</th>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, ...</td>\n",
       "      <td>[okay, , , , , , , , , last, , , got, , , , , ...</td>\n",
       "      <td>[Okay, , , , , , , , , Last, , , Got, , , , , ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CzdWqFTmn0Y</th>\n",
       "      <td>[2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, ...</td>\n",
       "      <td>[2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, ...</td>\n",
       "      <td>[Oh, good, okay, , , , , , , , else, , , , so,...</td>\n",
       "      <td>[Okay,, Okay,, Okay,, , , , , , , , else,, , ,...</td>\n",
       "      <td>[2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             is_autogen_unique  \\\n",
       "_QUEXsHfsA0  [2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...   \n",
       "BvHmRx14HQ8  [2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "5L3Ao5KuCC4  [2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "p50s63nPq9I  [2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "krIVOb23EH8  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "cX30jxMNBUw  [2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "VEG5xT5gAHc  [2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "WjnwWeGjZcM  [2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "XfoYk_Z5AkI  [2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "ccMHJeQU4Qw  [2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "IPBSB1HLNLo  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "JNxcznsrRb8  [2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, ...   \n",
       "CzdWqFTmn0Y  [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, ...   \n",
       "\n",
       "                                              is_manual_unique  \\\n",
       "_QUEXsHfsA0  [2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...   \n",
       "BvHmRx14HQ8  [2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "5L3Ao5KuCC4  [2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "p50s63nPq9I  [2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "krIVOb23EH8  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "cX30jxMNBUw  [2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "VEG5xT5gAHc  [2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "WjnwWeGjZcM  [2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "XfoYk_Z5AkI  [2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "ccMHJeQU4Qw  [2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "IPBSB1HLNLo  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "JNxcznsrRb8  [2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, ...   \n",
       "CzdWqFTmn0Y  [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, ...   \n",
       "\n",
       "                                                   autogen_seq  \\\n",
       "_QUEXsHfsA0  [so, , , , , , deep, learning, , coders, lesso...   \n",
       "BvHmRx14HQ8  [so, uh, , everybody, , , , , practical, deep,...   \n",
       "5L3Ao5KuCC4  [oh, hello, , , , lesson, three, , practical, ...   \n",
       "p50s63nPq9I  [welcome, , , , , , or, , , , , , , , , , , , ...   \n",
       "krIVOb23EH8  [welcome, , , , , , , , , , , , , , , , , , , ...   \n",
       "cX30jxMNBUw  [hi, , , , , lesson, six, , , , , , , , , , , ...   \n",
       "VEG5xT5gAHc  [hi, , , , , , 7, we're, , , , , , , , , , , ,...   \n",
       "WjnwWeGjZcM  [hi, , , , , , eight, , , , , , , , , course, ...   \n",
       "XfoYk_Z5AkI  [okay, , welcome, practical, , , , , , , , , ,...   \n",
       "ccMHJeQU4Qw  [welcome, , lesson, two, , , , , , , , , , , ,...   \n",
       "IPBSB1HLNLo  [hi, , , , , , , , , , , , , , , , course, , p...   \n",
       "JNxcznsrRb8  [okay, , , , , , , , , last, , , got, , , , , ...   \n",
       "CzdWqFTmn0Y  [Oh, good, okay, , , , , , , , else, , , , so,...   \n",
       "\n",
       "                                                    manual_seq  \\\n",
       "_QUEXsHfsA0  [So, , , , , , Deep Learning, Deep Learning, ,...   \n",
       "BvHmRx14HQ8  [So,, So,, , everybody,, , , , , Practical Dee...   \n",
       "5L3Ao5KuCC4  [So hello,, So hello,, , , , Lesson 3, Lesson ...   \n",
       "p50s63nPq9I  [Welcome, , , , , , 4, , , , , , , , , , , , ,...   \n",
       "krIVOb23EH8  [Welcome, , , , , , , , , , , , , , , , , , , ...   \n",
       "cX30jxMNBUw  [Hi, , , , , Lesson 6,, Lesson 6,, , , , , , ,...   \n",
       "VEG5xT5gAHc  [Hi, , , , , , 7! We're, 7! We're, , , , , , ,...   \n",
       "WjnwWeGjZcM  [Hi, , , , , , eight,, , , , , , , , , course....   \n",
       "XfoYk_Z5AkI  [Okay, , Welcome Practical, Welcome Practical,...   \n",
       "ccMHJeQU4Qw  [Welcome, , Lesson 2, Lesson 2, , , , , , , , ...   \n",
       "IPBSB1HLNLo  [Hi, , , , , , , , , , , , , , , , course,, , ...   \n",
       "JNxcznsrRb8  [Okay, , , , , , , , , Last, , , Got, , , , , ...   \n",
       "CzdWqFTmn0Y  [Okay,, Okay,, Okay,, , , , , , , , else,, , ,...   \n",
       "\n",
       "                                               manual_addl_rep  \n",
       "_QUEXsHfsA0  [0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 3, 0, 0, ...  \n",
       "BvHmRx14HQ8  [1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, ...  \n",
       "5L3Ao5KuCC4  [1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, ...  \n",
       "p50s63nPq9I  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "krIVOb23EH8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "cX30jxMNBUw  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "VEG5xT5gAHc  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "WjnwWeGjZcM  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "XfoYk_Z5AkI  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "ccMHJeQU4Qw  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "IPBSB1HLNLo  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "JNxcznsrRb8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "CzdWqFTmn0Y  [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[['is_autogen_unique', 'is_manual_unique', 'autogen_seq', 'manual_seq', 'manual_addl_rep']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `label_diff_targets()`\n",
    "```\n",
    "BOTH_AGREE = 0\n",
    "BOTH_DIFFER = 2\n",
    "AUTOGEN_INSERT = 1\n",
    "MANUAL_INSERT = -1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of transcripts from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autogen_reconstruct(example):\n",
    "    autogen_reconstruct = []\n",
    "    labels = example.is_autogen_unique\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label == 0:\n",
    "            autogen_reconstruct.append(example.common_to_both_seq[idx])\n",
    "        if label == 1 or label == 2:\n",
    "            autogen_reconstruct.append(example.autogen_seq[idx])\n",
    "        if label == -1:\n",
    "            autogen_reconstruct.append(\"\")\n",
    "    return autogen_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_manual_reconstruct(example):\n",
    "    manual_reconstruct = []\n",
    "    labels = example.is_manual_unique\n",
    "    i = 0\n",
    "    while i < len(labels):\n",
    "        if labels[i] == 0:\n",
    "            manual_reconstruct.append(example.common_to_both_seq[i])\n",
    "        elif labels[i] == -1:\n",
    "            manual_reconstruct.extend(example.manual_seq[i].split())\n",
    "        elif labels[i] == 2:\n",
    "            manual_reconstruct.extend(example.manual_seq[i].split())\n",
    "            i+=example.manual_addl_rep[i]\n",
    "        i+=1\n",
    "    return manual_reconstruct \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = transcripts.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so',\n",
       " 'hello',\n",
       " 'everybody',\n",
       " 'and',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'for',\n",
       " 'coders']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autogen_recon = (get_autogen_reconstruct(example))\n",
    "autogen_text = example.autogen_text.split()\n",
    "assert ' '.join(autogen_recon).split() == ' '.join(autogen_text).split()\n",
    "autogen_recon[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " 'hello',\n",
       " 'everybody',\n",
       " 'and',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'for',\n",
       " 'Coders,']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_recon = get_manual_reconstruct(example)\n",
    "manual_text = example.manual_text.split()\n",
    "assert manual_recon == manual_text\n",
    "manual_recon[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional label creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the labeled differences between the autogen and manual transcripts will not be useful for most tasks. But hopefully the labeling schema is flexible enough that people can use it to create their own more specific labels.\n",
    "\n",
    "Below is an example of adding labels for simple (removing case and punctuation) single token differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_simple_single_token_diff_labels(t, new_label_name, label):\n",
    "    REP_TARGET = 0 # looking for only a single token differences (no repetitions)\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    \n",
    "    new_labels = [0]*len(t.autogen_seq)\n",
    "    for idx in range(len(t.autogen_seq)):\n",
    "        if t.is_autogen_unique[idx] == 2 and t.manual_addl_rep[idx] == REP_TARGET:\n",
    "            auto_token = t.autogen_seq[idx]\n",
    "            man_token = t.manual_seq[idx]\n",
    "\n",
    "            auto_token = ' '.join(tokenizer.tokenize(auto_token.strip())).lower()\n",
    "            man_token = ' '.join(tokenizer.tokenize(man_token.strip())).lower()\n",
    "\n",
    "            if (\n",
    "                auto_token != man_token  # still different after above simplifications\n",
    "                and len(man_token.split()) == 1  # only a single token difference\n",
    "                and not re.match(\"\\d+\", man_token)  # no digits in either: \n",
    "                and not re.match(\"\\d+\", auto_token)  # e.g. `2` <-> `two` is a common diff\n",
    "            ):\n",
    "                new_labels[idx]=label\n",
    "\n",
    "    t[new_label_name] = new_labels\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_DIFF_LABEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = transcripts.apply(\n",
    "    add_simple_single_token_diff_labels, \n",
    "    axis=1, \n",
    "    args=('is_single_diff', SINGLE_DIFF_LABEL)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_titles</th>\n",
       "      <th>playlist_ids</th>\n",
       "      <th>channel_ids</th>\n",
       "      <th>autogen</th>\n",
       "      <th>manual</th>\n",
       "      <th>autogen_text</th>\n",
       "      <th>manual_text</th>\n",
       "      <th>diffs</th>\n",
       "      <th>common_to_both_seq</th>\n",
       "      <th>is_autogen_unique</th>\n",
       "      <th>is_manual_unique</th>\n",
       "      <th>autogen_seq</th>\n",
       "      <th>manual_seq</th>\n",
       "      <th>manual_addl_rep</th>\n",
       "      <th>is_single_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_QUEXsHfsA0</th>\n",
       "      <td>Lesson 1 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'so hello everybody and welcome to d...</td>\n",
       "      <td>[{'text': 'So hello everybody and welcome to D...</td>\n",
       "      <td>so hello everybody and welcome to deep learnin...</td>\n",
       "      <td>So hello everybody and welcome to Deep Learnin...</td>\n",
       "      <td>[{'-': ['so'], '+': ['So']}, hello, everybody,...</td>\n",
       "      <td>[, hello, everybody, and, welcome, to, , , for...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...</td>\n",
       "      <td>[so, , , , , , deep, learning, , coders, lesso...</td>\n",
       "      <td>[So, , , , , , Deep Learning, Deep Learning, ,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 3, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BvHmRx14HQ8</th>\n",
       "      <td>Lesson 2 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'so uh hello everybody and welcome b...</td>\n",
       "      <td>[{'text': 'So, hello everybody, and welcome ba...</td>\n",
       "      <td>so uh hello everybody and welcome back to prac...</td>\n",
       "      <td>So, hello everybody, and welcome back to Pract...</td>\n",
       "      <td>[{'-': ['so', 'uh'], '+': ['So,']}, hello, {'-...</td>\n",
       "      <td>[, , hello, , and, welcome, back, to, , , , fo...</td>\n",
       "      <td>[2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[so, uh, , everybody, , , , , practical, deep,...</td>\n",
       "      <td>[So,, So,, , everybody,, , , , , Practical Dee...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5L3Ao5KuCC4</th>\n",
       "      <td>Lesson 3 - Deep Learning for Coders (2020)</td>\n",
       "      <td>PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM</td>\n",
       "      <td>UCX7Y2qWriXpqocG97SFW2OQ</td>\n",
       "      <td>[{'text': 'oh hello and welcome to lesson thre...</td>\n",
       "      <td>[{'text': 'So hello, and welcome to Lesson 3 o...</td>\n",
       "      <td>oh hello and welcome to lesson three of practi...</td>\n",
       "      <td>So hello, and welcome to Lesson 3 of Practical...</td>\n",
       "      <td>[{'-': ['oh', 'hello'], '+': ['So', 'hello,']}...</td>\n",
       "      <td>[, , and, welcome, to, , , of, , , , for, , , ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...</td>\n",
       "      <td>[oh, hello, , , , lesson, three, , practical, ...</td>\n",
       "      <td>[So hello,, So hello,, , , , Lesson 3, Lesson ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           video_titles  \\\n",
       "_QUEXsHfsA0  Lesson 1 - Deep Learning for Coders (2020)   \n",
       "BvHmRx14HQ8  Lesson 2 - Deep Learning for Coders (2020)   \n",
       "5L3Ao5KuCC4  Lesson 3 - Deep Learning for Coders (2020)   \n",
       "\n",
       "                                   playlist_ids               channel_ids  \\\n",
       "_QUEXsHfsA0  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "BvHmRx14HQ8  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "5L3Ao5KuCC4  PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM  UCX7Y2qWriXpqocG97SFW2OQ   \n",
       "\n",
       "                                                       autogen  \\\n",
       "_QUEXsHfsA0  [{'text': 'so hello everybody and welcome to d...   \n",
       "BvHmRx14HQ8  [{'text': 'so uh hello everybody and welcome b...   \n",
       "5L3Ao5KuCC4  [{'text': 'oh hello and welcome to lesson thre...   \n",
       "\n",
       "                                                        manual  \\\n",
       "_QUEXsHfsA0  [{'text': 'So hello everybody and welcome to D...   \n",
       "BvHmRx14HQ8  [{'text': 'So, hello everybody, and welcome ba...   \n",
       "5L3Ao5KuCC4  [{'text': 'So hello, and welcome to Lesson 3 o...   \n",
       "\n",
       "                                                  autogen_text  \\\n",
       "_QUEXsHfsA0  so hello everybody and welcome to deep learnin...   \n",
       "BvHmRx14HQ8  so uh hello everybody and welcome back to prac...   \n",
       "5L3Ao5KuCC4  oh hello and welcome to lesson three of practi...   \n",
       "\n",
       "                                                   manual_text  \\\n",
       "_QUEXsHfsA0  So hello everybody and welcome to Deep Learnin...   \n",
       "BvHmRx14HQ8  So, hello everybody, and welcome back to Pract...   \n",
       "5L3Ao5KuCC4  So hello, and welcome to Lesson 3 of Practical...   \n",
       "\n",
       "                                                         diffs  \\\n",
       "_QUEXsHfsA0  [{'-': ['so'], '+': ['So']}, hello, everybody,...   \n",
       "BvHmRx14HQ8  [{'-': ['so', 'uh'], '+': ['So,']}, hello, {'-...   \n",
       "5L3Ao5KuCC4  [{'-': ['oh', 'hello'], '+': ['So', 'hello,']}...   \n",
       "\n",
       "                                            common_to_both_seq  \\\n",
       "_QUEXsHfsA0  [, hello, everybody, and, welcome, to, , , for...   \n",
       "BvHmRx14HQ8  [, , hello, , and, welcome, back, to, , , , fo...   \n",
       "5L3Ao5KuCC4  [, , and, welcome, to, , , of, , , , for, , , ...   \n",
       "\n",
       "                                             is_autogen_unique  \\\n",
       "_QUEXsHfsA0  [2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...   \n",
       "BvHmRx14HQ8  [2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "5L3Ao5KuCC4  [2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "\n",
       "                                              is_manual_unique  \\\n",
       "_QUEXsHfsA0  [2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, ...   \n",
       "BvHmRx14HQ8  [2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "5L3Ao5KuCC4  [2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, ...   \n",
       "\n",
       "                                                   autogen_seq  \\\n",
       "_QUEXsHfsA0  [so, , , , , , deep, learning, , coders, lesso...   \n",
       "BvHmRx14HQ8  [so, uh, , everybody, , , , , practical, deep,...   \n",
       "5L3Ao5KuCC4  [oh, hello, , , , lesson, three, , practical, ...   \n",
       "\n",
       "                                                    manual_seq  \\\n",
       "_QUEXsHfsA0  [So, , , , , , Deep Learning, Deep Learning, ,...   \n",
       "BvHmRx14HQ8  [So,, So,, , everybody,, , , , , Practical Dee...   \n",
       "5L3Ao5KuCC4  [So hello,, So hello,, , , , Lesson 3, Lesson ...   \n",
       "\n",
       "                                               manual_addl_rep  \\\n",
       "_QUEXsHfsA0  [0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 3, 0, 0, ...   \n",
       "BvHmRx14HQ8  [1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, ...   \n",
       "5L3Ao5KuCC4  [1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, ...   \n",
       "\n",
       "                                                is_single_diff  \n",
       "_QUEXsHfsA0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "BvHmRx14HQ8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5L3Ao5KuCC4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at some example simple single diff labels. \n",
    "- First line printed below is autogen sequences with the labeled `*simple single diff*` highlighted.\n",
    "- Second line is autogen sequences with the corresponding `**manual sequence token**` label inserted.\n",
    "\n",
    "Some of the diffs highlighted below do seem interesting and learnable by a trained language model, while others are less interesting and could ideally be further filtered out by improved additional label creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while now we've actually finally *gotten* to the point where\n",
      "while now we've actually finally **got** to the point where\n",
      "\n",
      "about to the point that *Sylvia* and I have actually\n",
      "about to the point that **Sylvain** and I have actually\n",
      "\n",
      "software from scratch called the *faster* library version 2 we've\n",
      "software from scratch called the **fastai** library version 2 we've\n",
      "\n",
      "as you see it's a *laughter* but by the time\n",
      "as you see it's a **draft,** but by the time\n",
      "\n",
      "is we well I mentioned *why* important part of the\n",
      "is we well I mentioned **one** important part of the\n",
      "\n",
      "Rachel Thomas and so maybe *richer* you can come and\n",
      "Rachel Thomas and so maybe **Rachel** you can come and\n",
      "\n",
      "the founding director of the *Centre* for applied data ethics\n",
      "the founding director of the **Center** for applied data ethics\n",
      "\n",
      "and I'll be the voice *to* hear asking questions from\n",
      "and I'll be the voice **you** hear asking questions from\n",
      "\n",
      "from the forums Rachel and *Sylvia* are also the people\n",
      "from the forums Rachel and **Sylvain** are also the people\n",
      "\n",
      "did you want to sure *well* thank you and as\n",
      "did you want to sure **oh** thank you and as\n",
      "\n",
      "the founding director of the *center* for applied data at\n",
      "the founding director of the **Centre** for applied data at\n",
      "\n",
      "or you don't have enough *vast* resources or whatever because\n",
      "or you don't have enough **fast** resources or whatever because\n",
      "\n",
      "philosophy major so there is *when* we'll see it throughout\n",
      "philosophy major so there is **- and** we'll see it throughout\n",
      "\n",
      "to 1943 when McCulloch and *Pitt's* created a mathematical model\n",
      "to 1943 when McCulloch and **Pitts** created a mathematical model\n",
      "\n",
      "built on top of that *to* basically create some subtle\n",
      "built on top of that **- he** basically create some subtle\n",
      "\n",
      "top of that to basically *create* some subtle changes to\n",
      "top of that to basically **created** some subtle changes to\n",
      "\n",
      "could witness the birth of *a* machine that is capable\n",
      "could witness the birth of **the** machine that is capable\n",
      "\n",
      "professor named Marvin Minsky and *tappet* wrote a book called\n",
      "professor named Marvin Minsky and **Papert** wrote a book called\n",
      "\n",
      "of the book and only *notice* the limitation and people\n",
      "of the book and only **noticed** the limitation and people\n",
      "\n",
      "and people basically decided that *dural* networks are going to\n",
      "and people basically decided that **neural** networks are going to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = transcripts.iloc[0]\n",
    "new_labels = torch.tensor(row.is_single_diff)\n",
    "idxs = torch.where(new_labels == SINGLE_DIFF_LABEL)[0]\n",
    "\n",
    "for idx in idxs[:20]:\n",
    "    autogen_seq_recon = get_autogen_reconstruct(row)\n",
    "    manual_seq_recon = get_manual_reconstruct(row)\n",
    "    \n",
    "    autogen_seq_recon[idx] = f\"*{autogen_seq_recon[idx]}*\"\n",
    "    print(' '.join(autogen_seq_recon[idx-5:idx+5]))\n",
    "    autogen_seq_recon[idx] = f\"**{example.manual_seq[idx]}**\"\n",
    "    print(' '.join(autogen_seq_recon[idx-5:idx+5]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the top 100 most common pairs of simple single diffs, displayed as:\n",
    "\n",
    "`('autogen \"typo\"' <--> 'manual \"correction\"')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_diffs_counter = Counter()\n",
    "for idx in range(len(transcripts)):\n",
    "    row = transcripts.iloc[idx]\n",
    "    new_labels = torch.tensor(row.is_single_diff)\n",
    "    idxs = torch.where(new_labels == SINGLE_DIFF_LABEL)[0]\n",
    "    single_diffs_counter.update([\n",
    "        f\"{row.autogen_seq[i]} <--> {row.manual_seq[i]}\"\n",
    "        for i in idxs\n",
    "    ])                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a <--> the', 15),\n",
       " ('Jupiter <--> Jupyter', 15),\n",
       " ('and <--> in', 11),\n",
       " ('main <--> mean', 10),\n",
       " ('in <--> and', 10),\n",
       " ('the <--> a', 7),\n",
       " ('or <--> for', 6),\n",
       " ('a <--> an', 6),\n",
       " ('is <--> as', 6),\n",
       " (\"it's <--> is\", 5),\n",
       " ('and <--> than', 5),\n",
       " ('use <--> used', 5),\n",
       " ('- <--> minus', 5),\n",
       " (\"we'll <--> will\", 5),\n",
       " ('see <--> say', 5),\n",
       " ('at <--> it', 5),\n",
       " ('Sylvia <--> Sylvain', 4),\n",
       " ('first <--> fast', 4),\n",
       " ('Pio <--> PIL', 4),\n",
       " ('or <--> all', 4),\n",
       " ('a <--> of', 3),\n",
       " ('of <--> to', 3),\n",
       " ('recognize <--> recognise', 3),\n",
       " ('ripple <--> REPL', 3),\n",
       " ('could <--> can', 3),\n",
       " ('recognizing <--> recognising', 3),\n",
       " ('then <--> than', 3),\n",
       " ('or <--> of', 3),\n",
       " ('our <--> R', 3),\n",
       " (\"you're <--> your\", 3),\n",
       " ('if <--> of', 3),\n",
       " ('and <--> kind', 3),\n",
       " ('quite <--> called', 3),\n",
       " ('amnesty <--> MNIST', 3),\n",
       " (\"we're <--> were\", 3),\n",
       " ('a <--> our', 3),\n",
       " ('Apple <--> tuple', 3),\n",
       " ('or <--> are', 3),\n",
       " ('Kegel <--> Kaggle', 3),\n",
       " ('with <--> of', 3),\n",
       " ('get <--> git', 3),\n",
       " ('faster <--> fastai', 2),\n",
       " ('role <--> rule', 2),\n",
       " ('is <--> was', 2),\n",
       " ('to <--> for', 2),\n",
       " ('were <--> are', 2),\n",
       " ('mentioned <--> mention', 2),\n",
       " ('chord <--> called', 2),\n",
       " (\"you're <--> you\", 2),\n",
       " ('moral <--> model', 2),\n",
       " ('do <--> to', 2),\n",
       " ('so <--> for', 2),\n",
       " ('they <--> there', 2),\n",
       " ('four <--> for', 2),\n",
       " ('is <--> has', 2),\n",
       " (\"they're <--> they\", 2),\n",
       " ('and <--> an', 2),\n",
       " ('our <--> are', 2),\n",
       " ('umpire <--> numpy', 2),\n",
       " ('the <--> that', 2),\n",
       " ('a3 <--> a_3', 2),\n",
       " ('some <--> sum', 2),\n",
       " ('tupple <--> tuple', 2),\n",
       " ('is <--> are', 2),\n",
       " ('two <--> to', 2),\n",
       " ('value <--> ReLU', 2),\n",
       " ('untie <--> untar', 2),\n",
       " ('or <--> will', 2),\n",
       " ('their <--> the', 2),\n",
       " ('wear <--> where', 2),\n",
       " ('air <--> error,', 2),\n",
       " ('risk <--> risks', 2),\n",
       " ('at <--> in', 2),\n",
       " ('markoulis <--> Markkula', 2),\n",
       " ('it <--> at', 2),\n",
       " ('tack <--> tech', 2),\n",
       " ('a <--> to', 2),\n",
       " ('through <--> do', 2),\n",
       " ('cable <--> Kaggle', 2),\n",
       " ('colon <--> column', 2),\n",
       " ('high <--> hi', 2),\n",
       " ('low <--> lo', 2),\n",
       " ('although <--> though', 2),\n",
       " ('as <--> is', 2),\n",
       " ('entire <--> untar', 2),\n",
       " ('lost <--> loss', 2),\n",
       " ('the <--> to', 2),\n",
       " ('train <--> trained', 2),\n",
       " ('bit <--> split', 2),\n",
       " ('IH <--> i_h,', 2),\n",
       " (\"don't <--> know,\", 2),\n",
       " (\"Teddy's <--> Teddies,\", 2),\n",
       " ('by <--> x', 2),\n",
       " ('Kressel <--> crestle', 2),\n",
       " ('Cargill <--> kaggle', 2),\n",
       " ('cable <--> keggle', 2),\n",
       " ('- <--> Python', 2),\n",
       " ('Kressel <--> crastle', 2),\n",
       " ('gotten <--> got', 1),\n",
       " ('laughter <--> draft,', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_diffs_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
