{"video_titles":{"pPN8d0E3900":"Capsule Networks (CapsNets) \u2013 Tutorial","2Kawrd5szHE":"How to implement CapsNets using TensorFlow"},"playlist_ids":{"pPN8d0E3900":"PLuTYjXW7aAt3HLCATBOkkXtifCVAm0O_A","2Kawrd5szHE":"PLuTYjXW7aAt3HLCATBOkkXtifCVAm0O_A"},"channel_ids":{"pPN8d0E3900":"UCCvGd1WBMpFQ_vtC89VF2qA","2Kawrd5szHE":"UCCvGd1WBMpFQ_vtC89VF2qA"},"autogen":{"pPN8d0E3900":[{"text":"hey I'm overly Asian and in this video","start":0.0,"duration":3.99},{"text":"I'll tell you all about capsule networks","start":2.04,"duration":4.279},{"text":"a hot new architecture for neural nets","start":3.99,"duration":4.95},{"text":"Jeffrey Henson had the idea of capsule","start":6.319,"duration":4.181},{"text":"Network several years ago and he","start":8.94,"duration":3.81},{"text":"published a paper in 2011 that","start":10.5,"duration":4.65},{"text":"introduced many of the key ideas but he","start":12.75,"duration":3.69},{"text":"had a hard time making them work","start":15.15,"duration":4.41},{"text":"properly until now a few weeks ago in","start":16.44,"duration":6.03},{"text":"October 2017 a paper called dynamic","start":19.56,"duration":5.37},{"text":"routing between capsules was published","start":22.47,"duration":4.41},{"text":"by Sarah saber Nicholas frost","start":24.93,"duration":3.81},{"text":"and of course Geoffrey Hinton they","start":26.88,"duration":3.45},{"text":"managed to reach state-of-the-art","start":28.74,"duration":4.22},{"text":"performance on the MS dataset and","start":30.33,"duration":5.28},{"text":"demonstrated considerably better results","start":32.96,"duration":5.02},{"text":"than convolutional neural nets on highly","start":35.61,"duration":5.64},{"text":"overlapping digits so what are capsule","start":37.98,"duration":5.73},{"text":"networks exactly well in computer","start":41.25,"duration":4.43},{"text":"graphics you start with an abstract","start":43.71,"duration":4.259},{"text":"representation of a scene for example a","start":45.68,"duration":5.62},{"text":"rectangle at position X 20 and y equals","start":47.969,"duration":5.91},{"text":"30 rotated by 16 degrees and and so on","start":51.3,"duration":5.13},{"text":"each object type has various","start":53.879,"duration":5.461},{"text":"instantiation parameters then you call","start":56.43,"duration":5.25},{"text":"some rendering function and boom you get","start":59.34,"duration":6.029},{"text":"an image inverse graphics is just the","start":61.68,"duration":5.85},{"text":"reverse process you start with an image","start":65.369,"duration":4.531},{"text":"and you try to find what objects it","start":67.53,"duration":4.83},{"text":"contains and what their instantiation","start":69.9,"duration":5.609},{"text":"parameters are a capsule Network is","start":72.36,"duration":5.189},{"text":"basically a neural network that tries to","start":75.509,"duration":5.61},{"text":"perform inverse graphics it is composed","start":77.549,"duration":6.781},{"text":"of many capsules a capsule is any","start":81.119,"duration":5.131},{"text":"function that tries to predict the","start":84.33,"duration":3.75},{"text":"presence and the instantiation","start":86.25,"duration":4.68},{"text":"parameters of a particular object at a","start":88.08,"duration":5.64},{"text":"given location for example the network","start":90.93,"duration":5.82},{"text":"above contains 50 capsules the arrows","start":93.72,"duration":5.67},{"text":"represent the output vectors of these","start":96.75,"duration":5.82},{"text":"capsules capsules output vectors the","start":99.39,"duration":5.909},{"text":"black arrows correspond to capsules that","start":102.57,"duration":5.339},{"text":"try to find rectangles while the blue","start":105.299,"duration":4.771},{"text":"arrows represent the output of capsules","start":107.909,"duration":5.67},{"text":"looking for triangles the length of an","start":110.07,"duration":5.67},{"text":"activation vector represents the","start":113.579,"duration":4.711},{"text":"estimated probability that the object","start":115.74,"duration":4.32},{"text":"the capsule is looking for is indeed","start":118.29,"duration":4.53},{"text":"present so you can see that most arrows","start":120.06,"duration":5.07},{"text":"are tiny meaning the capsules didn't","start":122.82,"duration":5.279},{"text":"detect anything but two arrows are quite","start":125.13,"duration":3.45},{"text":"long","start":128.099,"duration":2.61},{"text":"this means that the capsules at these","start":128.58,"duration":4.23},{"text":"locations are pretty confident that they","start":130.709,"duration":3.191},{"text":"found what they were looking","start":132.81,"duration":3.819},{"text":"for in this case a rectangle and the","start":133.9,"duration":6.6},{"text":"triangle so the orientation of the","start":136.629,"duration":5.911},{"text":"activation vector encodes the","start":140.5,"duration":4.079},{"text":"instantiation parameters of the object","start":142.54,"duration":3.93},{"text":"for example in this case the object's","start":144.579,"duration":3.931},{"text":"rotation but it could be also its","start":146.47,"duration":4.23},{"text":"thickness how stretched or skewed it is","start":148.51,"duration":4.8},{"text":"its exact location it might be slight","start":150.7,"duration":5.009},{"text":"translations and so on for simplicity","start":153.31,"duration":4.319},{"text":"I'll just focus on the rotation","start":155.709,"duration":4.17},{"text":"parameter but in real capsule Network","start":157.629,"duration":5.22},{"text":"the activation vectors may have five ten","start":159.879,"duration":6.42},{"text":"dimensions or more in practice a good","start":162.849,"duration":6.181},{"text":"way to implement this is to apply a","start":166.299,"duration":5.671},{"text":"couple convolutional layers just like in","start":169.03,"duration":5.609},{"text":"a regular convolutional neural net this","start":171.97,"duration":4.739},{"text":"will output an array containing a bunch","start":174.639,"duration":4.621},{"text":"of feature maps you can then reshape","start":176.709,"duration":5.28},{"text":"this array to get a set of vectors for","start":179.26,"duration":4.949},{"text":"each location for example suppose the","start":181.989,"duration":4.92},{"text":"convolutional layers output an array","start":184.209,"duration":5.101},{"text":"containing say 18 feature maps","start":186.909,"duration":5.371},{"text":"2 times 9 you can easily reshape this","start":189.31,"duration":5.25},{"text":"array to get two vectors of nine","start":192.28,"duration":5.73},{"text":"dimensions each for every location you","start":194.56,"duration":5.28},{"text":"could also get three vectors of six","start":198.01,"duration":4.589},{"text":"dimensions each and so on something that","start":199.84,"duration":4.44},{"text":"would look like the capsule network","start":202.599,"duration":3.631},{"text":"represented here with two vectors at","start":204.28,"duration":5.069},{"text":"each location the last step is to ensure","start":206.23,"duration":6.21},{"text":"that no vector is longer than one since","start":209.349,"duration":5.31},{"text":"the vectors length is meant to represent","start":212.44,"duration":4.379},{"text":"a probability it cannot be greater than","start":214.659,"duration":4.41},{"text":"one to do this we apply a squashing","start":216.819,"duration":4.411},{"text":"function it preserves the vectors","start":219.069,"duration":4.98},{"text":"orientation but it squashes it to ensure","start":221.23,"duration":5.899},{"text":"that its length is between zero and one","start":224.049,"duration":6.3},{"text":"one key feature of capsule networks is","start":227.129,"duration":5.801},{"text":"that they preserve detailed information","start":230.349,"duration":5.63},{"text":"about the object's location and its pose","start":232.93,"duration":6.029},{"text":"throughout the network for example if I","start":235.979,"duration":5.921},{"text":"rotate the image slightly notice that","start":238.959,"duration":4.801},{"text":"the activation vectors also change","start":241.9,"duration":4.29},{"text":"slightly right this is called","start":243.76,"duration":5.879},{"text":"equivariance in a regular convolutional","start":246.19,"duration":5.519},{"text":"neural net there are generally several","start":249.639,"duration":5.25},{"text":"pooling layers and unfortunately these","start":251.709,"duration":5.52},{"text":"pooling layers tend to lose information","start":254.889,"duration":5.07},{"text":"such as the precise location and pose of","start":257.229,"duration":4.951},{"text":"the objects it's really not a big deal","start":259.959,"duration":4.441},{"text":"if you just want to classify the whole","start":262.18,"duration":3.11},{"text":"image","start":264.4,"duration":2.72},{"text":"but it makes it challenging to perform","start":265.29,"duration":4.62},{"text":"accurate image segmentation or object","start":267.12,"duration":5.79},{"text":"detection which require precise you know","start":269.91,"duration":6.39},{"text":"location and pose the fact that capsules","start":272.91,"duration":5.55},{"text":"are equivariance makes them very","start":276.3,"duration":5.25},{"text":"promising for these applications alright","start":278.46,"duration":5.22},{"text":"so now let's see how capsule networks","start":281.55,"duration":4.32},{"text":"can handle objects that are composed of","start":283.68,"duration":4.35},{"text":"a hierarchy of parts for example","start":285.87,"duration":4.2},{"text":"consider a boat centered at position X","start":288.03,"duration":5.55},{"text":"equals 22 and y equals 28 and rotated by","start":290.07,"duration":4.47},{"text":"16 degrees","start":293.58,"duration":3.9},{"text":"this boat is compotes is composed of","start":294.54,"duration":5.55},{"text":"parts in this case one rectangle and one","start":297.48,"duration":5.16},{"text":"triangle so this is how would be rent","start":300.09,"duration":5.64},{"text":"rendered now we want to do the reverse","start":302.64,"duration":4.77},{"text":"we want universe graphics so we want to","start":305.73,"duration":3.9},{"text":"go from the image to this whole","start":307.41,"duration":4.17},{"text":"hierarchy of parts with their","start":309.63,"duration":4.95},{"text":"instantiation parameters similarly we","start":311.58,"duration":5.34},{"text":"could also draw a draw a house using the","start":314.58,"duration":4.29},{"text":"same parts a rectangle in a triangle","start":316.92,"duration":3.81},{"text":"that this arm organized in a different","start":318.87,"duration":5.31},{"text":"way so the trick will be to try to come","start":320.73,"duration":6.03},{"text":"to go from this image containing a","start":324.18,"duration":4.5},{"text":"rectangle in a triangle and figure out","start":326.76,"duration":4.59},{"text":"not only that the rectangle and triangle","start":328.68,"duration":5.46},{"text":"are at this location and this","start":331.35,"duration":4.8},{"text":"orientation but also that they are part","start":334.14,"duration":3.33},{"text":"of a boat not a house","start":336.15,"duration":4.02},{"text":"so yeah let's let's figure out how it","start":337.47,"duration":4.56},{"text":"would do this the first step we have","start":340.17,"duration":3.75},{"text":"already seen we run a couple of","start":342.03,"duration":3.69},{"text":"convolutional layers we reshape the","start":343.92,"duration":4.44},{"text":"output to get vectors and we squash them","start":345.72,"duration":5.43},{"text":"this gives us the output of the primary","start":348.36,"duration":4.41},{"text":"capsules we've got the first layer","start":351.15,"duration":4.56},{"text":"already the next step is where most of","start":352.77,"duration":4.68},{"text":"the magic and complexity of capsule","start":355.71,"duration":4.71},{"text":"networks takes place every capsule in","start":357.45,"duration":5.55},{"text":"the first layer tries to predict the","start":360.42,"duration":5.22},{"text":"output of every capsule in the next","start":363.0,"duration":5.07},{"text":"layer you might want to pause to think","start":365.64,"duration":4.47},{"text":"about what this means that the capsules","start":368.07,"duration":5.19},{"text":"at the primary the first layer tried to","start":370.11,"duration":5.1},{"text":"predict what the second layer capsules","start":373.26,"duration":4.83},{"text":"will output for example let's consider","start":375.21,"duration":5.04},{"text":"the capsule that detected the rectangle","start":378.09,"duration":6.24},{"text":"I'll call it the rectangle capsule let's","start":380.25,"duration":6.84},{"text":"suppose that there are two capsules in","start":384.33,"duration":5.46},{"text":"the next layer the house capsule and the","start":387.09,"duration":3.51},{"text":"boat capsule","start":389.79,"duration":3.6},{"text":"since the rectangle capsule detected a","start":390.6,"duration":5.569},{"text":"rectangle rotated by 16 degrees","start":393.39,"duration":5.089},{"text":"it predicts that the house capsule will","start":396.169,"duration":4.8},{"text":"detect a house rotated by 16 degrees","start":398.479,"duration":4.5},{"text":"that makes sense and the boat capsule","start":400.969,"duration":4.56},{"text":"will detect a boat rotated by 16 degrees","start":402.979,"duration":4.981},{"text":"as well that's what would be consistent","start":405.529,"duration":6.781},{"text":"with the orientation of the rectangle so","start":407.96,"duration":6.9},{"text":"to make this prediction what the","start":412.31,"duration":4.05},{"text":"rectangle capsule does is simply","start":414.86,"duration":4.5},{"text":"computes the dot product of a","start":416.36,"duration":6.54},{"text":"transformation matrix W IJ with its own","start":419.36,"duration":7.169},{"text":"activation vector at U at UI during","start":422.9,"duration":5.31},{"text":"training the network will gradually","start":426.529,"duration":3.75},{"text":"learn a transformation matrix for each","start":428.21,"duration":4.289},{"text":"pair of capsules in the first and second","start":430.279,"duration":4.47},{"text":"layer in other words it will learn all","start":432.499,"duration":4.711},{"text":"the part hole relationships for example","start":434.749,"duration":4.32},{"text":"the angle between the wall and the roof","start":437.21,"duration":3.979},{"text":"of a house and so on","start":439.069,"duration":4.65},{"text":"now let's see what the triangle capsule","start":441.189,"duration":6.01},{"text":"predicts right this time it's a bit more","start":443.719,"duration":5.91},{"text":"interesting given the rotation angle of","start":447.199,"duration":4.74},{"text":"the triangle it predicts that the house","start":449.629,"duration":4.891},{"text":"capsule will detect an upside-down house","start":451.939,"duration":5.7},{"text":"and the boat capsule will detect about","start":454.52,"duration":5.73},{"text":"rotated by 16 degrees these are the","start":457.639,"duration":5.131},{"text":"positions that would be consistent with","start":460.25,"duration":5.339},{"text":"the you know rotation angle of the","start":462.77,"duration":6.75},{"text":"triangle now we've got a bunch of","start":465.589,"duration":5.79},{"text":"predicted outputs what do we do with","start":469.52,"duration":4.41},{"text":"them well as you can see the rectangle","start":471.379,"duration":4.951},{"text":"capsule and the triangle capsules","start":473.93,"duration":5.099},{"text":"strongly agree on what the boat capsule","start":476.33,"duration":4.859},{"text":"will output in other words they agree","start":479.029,"duration":4.831},{"text":"that a boat positioned in this way would","start":481.189,"duration":4.23},{"text":"explain their own positions and","start":483.86,"duration":3.959},{"text":"rotations and they totally disagree on","start":485.419,"duration":4.43},{"text":"what the house capsule will output","start":487.819,"duration":4.5},{"text":"therefore it makes sense to assume that","start":489.849,"duration":4.84},{"text":"the rectangle and triangle are part of a","start":492.319,"duration":6.15},{"text":"boat not a house now that we know that","start":494.689,"duration":5.46},{"text":"the rectangle and triangle are part of","start":498.469,"duration":4.38},{"text":"the boat the outputs of the rectangle","start":500.149,"duration":5.19},{"text":"capsule and the triangle capsule really","start":502.849,"duration":4.05},{"text":"concern only the boat capsule this","start":505.339,"duration":3.54},{"text":"there's no need to send these outputs to","start":506.899,"duration":3.901},{"text":"any other capsule this would just add","start":508.879,"duration":4.44},{"text":"noise they should be sent only to the","start":510.8,"duration":3.45},{"text":"boat capsule","start":513.319,"duration":3.72},{"text":"this is called routing by agreements","start":514.25,"duration":5.699},{"text":"there are several benefits first since","start":517.039,"duration":5.49},{"text":"capsule outputs are only routed to the","start":519.949,"duration":4.38},{"text":"appropriate capsule in the next layer","start":522.529,"duration":4.441},{"text":"these capsules will get a cleaner input","start":524.329,"duration":3.551},{"text":"signal","start":526.97,"duration":3.46},{"text":"more accurate accurately determine the","start":527.88,"duration":5.82},{"text":"pose of the object second by looking at","start":530.43,"duration":5.37},{"text":"the paths of the activations you can","start":533.7,"duration":4.29},{"text":"easily navigate the hierarchy of parts","start":535.8,"duration":4.38},{"text":"and know exactly which part belongs to","start":537.99,"duration":4.53},{"text":"which objects like the rectangle biller","start":540.18,"duration":4.53},{"text":"belongs to the boats or the triangle","start":542.52,"duration":4.01},{"text":"belongs to the boat and so on","start":544.71,"duration":5.04},{"text":"lastly routing this by agreement helps","start":546.53,"duration":5.8},{"text":"parse crowded scenes with overlapping","start":549.75,"duration":4.68},{"text":"objects we will see this in a few slides","start":552.33,"duration":5.16},{"text":"but first let's look at how running by","start":554.43,"duration":5.43},{"text":"agreements is implemented in capsule","start":557.49,"duration":5.76},{"text":"networks here I have represented the","start":559.86,"duration":6.42},{"text":"various poses of the boat as predicted","start":563.25,"duration":5.1},{"text":"by the lower level capsules for example","start":566.28,"duration":4.47},{"text":"one of these circles may represent what","start":568.35,"duration":4.89},{"text":"the rectangle capsule thinks about the","start":570.75,"duration":5.4},{"text":"most likely pose of the boat and another","start":573.24,"duration":4.95},{"text":"circle may represent what the triangle","start":576.15,"duration":4.08},{"text":"capsule thinks and if we suppose that","start":578.19,"duration":4.23},{"text":"there are many other low level capsules","start":580.23,"duration":4.59},{"text":"then we might get a cloud of prediction","start":582.42,"duration":4.59},{"text":"vectors for the boat capsule like this","start":584.82,"duration":4.98},{"text":"in this example there are two post","start":587.01,"duration":4.65},{"text":"parameters one represents the rotation","start":589.8,"duration":3.72},{"text":"angle and the other represents the size","start":591.66,"duration":4.23},{"text":"of the boat as I mentioned earlier post","start":593.52,"duration":4.26},{"text":"parameters may capture many different","start":595.89,"duration":3.45},{"text":"kinds of visual features like skew","start":597.78,"duration":3.69},{"text":"thickness and so on or location a","start":599.34,"duration":4.14},{"text":"precise location so the first thing we","start":601.47,"duration":4.38},{"text":"do is we compute the mean of these","start":603.48,"duration":5.22},{"text":"predictions this gives us this vector","start":605.85,"duration":6.42},{"text":"the next step is to measure the distance","start":608.7,"duration":6.15},{"text":"between each predicted vector and the","start":612.27,"duration":4.98},{"text":"meet vector so I will use here the","start":614.85,"duration":5.58},{"text":"Euclidean distance but capsule networks","start":617.25,"duration":4.97},{"text":"actually use the scalar product","start":620.43,"duration":3.96},{"text":"basically we want to measure how much","start":622.22,"duration":4.9},{"text":"each predicted vector agrees with the","start":624.39,"duration":5.49},{"text":"mean predicted vector use using this","start":627.12,"duration":4.74},{"text":"agreement measure we can update the","start":629.88,"duration":3.99},{"text":"weights of every predicted vector","start":631.86,"duration":3.53},{"text":"accordingly","start":633.87,"duration":4.17},{"text":"note that the predicted vectors that are","start":635.39,"duration":5.47},{"text":"far from the mean now have a very small","start":638.04,"duration":5.73},{"text":"weight and the ones closest to the mean","start":640.86,"duration":4.86},{"text":"have a much stronger weight I've","start":643.77,"duration":4.16},{"text":"represent them represented them in black","start":645.72,"duration":5.19},{"text":"now we can compute the mean once again","start":647.93,"duration":6.31},{"text":"or I should say the weighted mean and","start":650.91,"duration":4.95},{"text":"notice that it moves slightly towards","start":654.24,"duration":4.65},{"text":"the cluster towards the center of the","start":655.86,"duration":5.43},{"text":"cluster so next we can once again update","start":658.89,"duration":7.5},{"text":"the weights and now most of the vectors","start":661.29,"duration":8.06},{"text":"within the cluster have turned black and","start":666.39,"duration":6.33},{"text":"again we can update the mean and we can","start":669.35,"duration":5.02},{"text":"repeat this process a few times in","start":672.72,"duration":3.6},{"text":"practice you know three to five","start":674.37,"duration":5.04},{"text":"iterations are generally sufficient this","start":676.32,"duration":5.22},{"text":"might remind you I suppose of the","start":679.41,"duration":4.08},{"text":"k-means clustering algorithm if you know","start":681.54,"duration":5.04},{"text":"it okay so this is how we find clusters","start":683.49,"duration":5.789},{"text":"of agreement now let's see how the whole","start":686.58,"duration":6.59},{"text":"algorithm works in a bit more details","start":689.279,"duration":7.291},{"text":"first for every predicted output we","start":693.17,"duration":5.68},{"text":"start by setting a raw routing weight","start":696.57,"duration":7.709},{"text":"bij equal to zero next we apply the","start":698.85,"duration":8.489},{"text":"softmax function softmax function to","start":704.279,"duration":4.891},{"text":"these raw weights for each primary","start":707.339,"duration":4.891},{"text":"capsule this gives the actual routing","start":709.17,"duration":4.979},{"text":"weights for each predicted output in","start":712.23,"duration":7.83},{"text":"this example 0.5 each equal weights next","start":714.149,"duration":7.68},{"text":"we compute a weighted sum of the","start":720.06,"duration":4.769},{"text":"predictions for each capsule in the next","start":721.829,"duration":6.331},{"text":"layer this might give vectors longer","start":724.829,"duration":6.151},{"text":"than one so as usual we apply the squash","start":728.16,"duration":8.16},{"text":"function and voila we now have the","start":730.98,"duration":7.83},{"text":"actual outputs of the house capsule and","start":736.32,"duration":4.95},{"text":"boat capsule but this is not the final","start":738.81,"duration":4.17},{"text":"output is just the end of the first","start":741.27,"duration":5.7},{"text":"round the first iteration now we can see","start":742.98,"duration":6.39},{"text":"which predictions were most accurate for","start":746.97,"duration":4.89},{"text":"example the rectangle capsule made a","start":749.37,"duration":4.77},{"text":"great prediction for the boat capsules","start":751.86,"duration":4.26},{"text":"output it really matches it pretty","start":754.14,"duration":5.1},{"text":"closely this is estimated by computing","start":756.12,"duration":5.19},{"text":"the scalar product of the predicted","start":759.24,"duration":5.61},{"text":"output vector U hat j-jake I and the","start":761.31,"duration":6.87},{"text":"actual product vector V J this scalar","start":764.85,"duration":5.76},{"text":"product is simply added to the predicted","start":768.18,"duration":8.37},{"text":"outputs raw routing weight bij so the","start":770.61,"duration":8.43},{"text":"weight of this particular predicted","start":776.55,"duration":6.21},{"text":"output is increased when there is a","start":779.04,"duration":5.82},{"text":"strong agreement the scalar product is","start":782.76,"duration":4.17},{"text":"going to be large so good predictions","start":784.86,"duration":2.66},{"text":"will","start":786.93,"duration":3.23},{"text":"have a higher weight on the other hand","start":787.52,"duration":5.1},{"text":"the rectangle capsule made a pretty bad","start":790.16,"duration":4.83},{"text":"prediction for the house capsules output","start":792.62,"duration":5.25},{"text":"so the scalar product in this case will","start":794.99,"duration":5.43},{"text":"be quite small and the raw routing","start":797.87,"duration":4.59},{"text":"weights of these predicted vector will","start":800.42,"duration":5.34},{"text":"not grow much next we update the routing","start":802.46,"duration":5.88},{"text":"weights by computing the softmax of the","start":805.76,"duration":5.07},{"text":"raw weights once again and as you can","start":808.34,"duration":4.65},{"text":"see the rectangle capsules predicted","start":810.83,"duration":4.41},{"text":"vector for the boat capsule now has a","start":812.99,"duration":5.22},{"text":"weight of 0.8 while it's predicted","start":815.24,"duration":4.83},{"text":"vector for the house capsule dropped","start":818.21,"duration":6.81},{"text":"down to 0.2 so most of its output is not","start":820.07,"duration":7.26},{"text":"going to go to the boat capsule not the","start":825.02,"duration":5.58},{"text":"house capsule once again we compute the","start":827.33,"duration":5.13},{"text":"weighted sum of all the predicted","start":830.6,"duration":3.9},{"text":"outputs vectors for each capsule in the","start":832.46,"duration":4.53},{"text":"next layer that is the house capsule in","start":834.5,"duration":4.56},{"text":"the boat capsule and this time the house","start":836.99,"duration":4.17},{"text":"capsule gets so little input that its","start":839.06,"duration":4.83},{"text":"output is a tiny vector on the other","start":841.16,"duration":4.68},{"text":"hand the boat capsule gets so much input","start":843.89,"duration":4.65},{"text":"that its output that it outputs a vector","start":845.84,"duration":5.16},{"text":"much longer than 1 so again we squash it","start":848.54,"duration":5.97},{"text":"and that's the end of round 2 and as you","start":851.0,"duration":5.43},{"text":"can see in just a couple iterations we","start":854.51,"duration":3.99},{"text":"have already ruled out the house and","start":856.43,"duration":4.8},{"text":"clearly chosen the boat after perhaps","start":858.5,"duration":5.85},{"text":"one or two more rounds we can stop and","start":861.23,"duration":4.89},{"text":"proceed to the next capsule layer in","start":864.35,"duration":5.85},{"text":"exactly the same way so as I mentioned","start":866.12,"duration":5.94},{"text":"earlier routing by agreement is really","start":870.2,"duration":4.2},{"text":"great to handle crowded scenes such as","start":872.06,"duration":6.12},{"text":"the one represented in this image one","start":874.4,"duration":5.55},{"text":"way to interpret this image as you can","start":878.18,"duration":3.0},{"text":"see there's a little bit of ambiguity","start":879.95,"duration":4.32},{"text":"you can see a house upside down in the","start":881.18,"duration":6.0},{"text":"middle however if this was the case then","start":884.27,"duration":5.07},{"text":"there would be no explanation for the","start":887.18,"duration":5.46},{"text":"bottom rectangle or the top triangle no","start":889.34,"duration":6.36},{"text":"reason for them to be where they are the","start":892.64,"duration":5.07},{"text":"best way to interpret the image is that","start":895.7,"duration":4.74},{"text":"there is a house at the top and a boat","start":897.71,"duration":5.19},{"text":"at the bottom and routing by agreement","start":900.44,"duration":4.71},{"text":"will tend to choose this solution since","start":902.9,"duration":4.11},{"text":"it makes all the capsules perfectly","start":905.15,"duration":3.63},{"text":"happy each of them making perfect","start":907.01,"duration":3.75},{"text":"predictions for the capsules in the next","start":908.78,"duration":6.54},{"text":"layer the ambiguity is explained away ok","start":910.76,"duration":7.08},{"text":"so what can you do with a capsule","start":915.32,"duration":3.68},{"text":"network now that you know","start":917.84,"duration":3.5},{"text":"how it works well for one you can create","start":919.0,"duration":5.73},{"text":"a nice image classifier of course just","start":921.34,"duration":5.55},{"text":"have one capsule per class in the top","start":924.73,"duration":4.71},{"text":"capsule layer and that's almost all","start":926.89,"duration":4.71},{"text":"there is to it all you need to add is a","start":929.44,"duration":4.5},{"text":"layer that computes the length of the","start":931.6,"duration":4.59},{"text":"top layer activation vectors and this","start":933.94,"duration":3.51},{"text":"gives you the estimated class","start":936.19,"duration":4.23},{"text":"probabilities you could then just train","start":937.45,"duration":4.59},{"text":"the network by minimizing the cross","start":940.42,"duration":3.69},{"text":"entropy loss has an irregular","start":942.04,"duration":4.29},{"text":"classification neural network and you","start":944.11,"duration":4.86},{"text":"know you'd be done however in the paper","start":946.33,"duration":4.59},{"text":"they use a margin loss that makes it","start":948.97,"duration":5.22},{"text":"possible to detect multiple classes in","start":950.92,"duration":6.51},{"text":"the image so without going into too much","start":954.19,"duration":6.03},{"text":"detail this margin loss is such that if","start":957.43,"duration":5.58},{"text":"an object of class K is present in the","start":960.22,"duration":5.31},{"text":"image then the corresponding top-level","start":963.01,"duration":4.92},{"text":"capsule should help put a vector whose","start":965.53,"duration":5.79},{"text":"squared length is at least 0.9 it should","start":967.93,"duration":6.06},{"text":"be long conversely if an object of class","start":971.32,"duration":5.31},{"text":"K is not present in the image then the","start":973.99,"duration":4.95},{"text":"capsule should output a short vector one","start":976.63,"duration":4.76},{"text":"whose squared length is shorter than 0.1","start":978.94,"duration":5.7},{"text":"so the total loss is the sum of losses","start":981.39,"duration":6.88},{"text":"for all classes in the paper they also","start":984.64,"duration":5.97},{"text":"add a decoder network on top of the","start":988.27,"duration":4.65},{"text":"capsule network it's just a three you","start":990.61,"duration":3.96},{"text":"know three connected layers fully","start":992.92,"duration":3.84},{"text":"connected with a sigmoid activation","start":994.57,"duration":4.65},{"text":"function in the output layer and it","start":996.76,"duration":5.19},{"text":"learns to reconstruct the input image by","start":999.22,"duration":4.44},{"text":"minimizing the squared difference","start":1001.95,"duration":4.47},{"text":"between the reconstructed image and the","start":1003.66,"duration":7.35},{"text":"input image the full loss is margin loss","start":1006.42,"duration":6.6},{"text":"we discussed earlier plus the","start":1011.01,"duration":3.87},{"text":"reconstruction loss scaled down","start":1013.02,"duration":4.2},{"text":"considerably so as to ensure that the","start":1014.88,"duration":4.89},{"text":"margin loss dominates training the","start":1017.22,"duration":4.47},{"text":"benefit of applying this reconstruction","start":1019.77,"duration":4.02},{"text":"loss is that it forces the network to","start":1021.69,"duration":4.35},{"text":"preserve all the information required to","start":1023.79,"duration":5.01},{"text":"construct to reconstruct the image up to","start":1026.04,"duration":5.73},{"text":"the top layer of the capsule network its","start":1028.8,"duration":6.33},{"text":"output layer this constraint acts a bit","start":1031.77,"duration":5.939},{"text":"like a regularizer it reduces the risk","start":1035.13,"duration":5.88},{"text":"of overfitting and helps generalize to","start":1037.709,"duration":7.23},{"text":"new examples and that's it you know how","start":1041.01,"duration":5.079},{"text":"a","start":1044.939,"duration":3.34},{"text":"capsule Network works and how to train","start":1046.089,"duration":4.111},{"text":"it let's look a little bit at some of","start":1048.279,"duration":3.63},{"text":"the figures in the paper which I find","start":1050.2,"duration":3.66},{"text":"interesting so this is figure one","start":1051.909,"duration":5.01},{"text":"showing a full capsule network for mmm","start":1053.86,"duration":5.939},{"text":"mist you can see the the first two","start":1056.919,"duration":4.951},{"text":"regular convolutional layers whose","start":1059.799,"duration":4.561},{"text":"output is reshaped and squashed to get","start":1061.87,"duration":4.77},{"text":"the activation vectors of the primary","start":1064.36,"duration":5.37},{"text":"capsules and these primary capsules are","start":1066.64,"duration":6.45},{"text":"organized in a six by six grid with 32","start":1069.73,"duration":5.91},{"text":"primary capsules in each cell of this","start":1073.09,"duration":5.73},{"text":"grid and each primary capsule outputs an","start":1075.64,"duration":6.36},{"text":"eight dimensional vector so this first","start":1078.82,"duration":6.03},{"text":"layer of capsules is fully connected to","start":1082.0,"duration":5.46},{"text":"the ten output capsules which output","start":1084.85,"duration":5.699},{"text":"sixteen dimensional lectures the length","start":1087.46,"duration":4.74},{"text":"of these vectors is yoots","start":1090.549,"duration":3.931},{"text":"is used to compute the margin loss as","start":1092.2,"duration":5.13},{"text":"explained earlier now this is figure two","start":1094.48,"duration":3.809},{"text":"from the paper","start":1097.33,"duration":3.36},{"text":"it shows the decoder sitting on top of","start":1098.289,"duration":4.62},{"text":"the caps net it is composed of two fully","start":1100.69,"duration":4.38},{"text":"connected relu layers plus a fully","start":1102.909,"duration":4.88},{"text":"connected sigmoid layer which outputs","start":1105.07,"duration":5.76},{"text":"784 numbers that correspond to the pixel","start":1107.789,"duration":5.441},{"text":"intensities of the richens reconstructed","start":1110.83,"duration":6.209},{"text":"image which is 28 by 28 pixel the","start":1113.23,"duration":5.28},{"text":"squared difference between this","start":1117.039,"duration":4.26},{"text":"reconstructed image and the input image","start":1118.51,"duration":6.33},{"text":"gives the reconstruction loss right and","start":1121.299,"duration":6.0},{"text":"this is figure four from the paper also","start":1124.84,"duration":4.29},{"text":"interesting one nice thing about capsule","start":1127.299,"duration":4.141},{"text":"networks is that the activation vectors","start":1129.13,"duration":4.26},{"text":"are often quite interpretable","start":1131.44,"duration":4.07},{"text":"for example this image shows the","start":1133.39,"duration":4.169},{"text":"reconstructions that you get when you","start":1135.51,"duration":4.029},{"text":"gradually modify one of the 16","start":1137.559,"duration":3.84},{"text":"dimensions of the top layer capsules","start":1139.539,"duration":4.411},{"text":"output you can see that the first","start":1141.399,"duration":4.591},{"text":"dimension seems to represent you know","start":1143.95,"duration":5.87},{"text":"scale and thickness the fourth dimension","start":1145.99,"duration":7.02},{"text":"represents a localized skew if you look","start":1149.82,"duration":6.28},{"text":"at how it that number 4 is modified from","start":1153.01,"duration":4.59},{"text":"the left to the right the fifth","start":1156.1,"duration":3.84},{"text":"represents the width of the digit plus a","start":1157.6,"duration":4.35},{"text":"slight translation to get the exact","start":1159.94,"duration":3.719},{"text":"position so as you can see it's rather","start":1161.95,"duration":5.24},{"text":"clear what most of these parameters do","start":1163.659,"duration":6.031},{"text":"ok to conclude let's summarize the pros","start":1167.19,"duration":4.209},{"text":"and cons capsule networks have reached","start":1169.69,"duration":4.109},{"text":"state-of-the-art accuracy on a missed on","start":1171.399,"duration":4.951},{"text":"so far 10 they they got a bit over 10","start":1173.799,"duration":4.141},{"text":"percent error which is far from a","start":1176.35,"duration":2.88},{"text":"state-of-the-art but it's","start":1177.94,"duration":3.81},{"text":"- what was first obtained with other","start":1179.23,"duration":4.5},{"text":"techniques before you know years of","start":1181.75,"duration":3.87},{"text":"efforts were put into them so it's still","start":1183.73,"duration":2.569},{"text":"a good start","start":1185.62,"duration":3.36},{"text":"capsule networks require less training","start":1186.299,"duration":5.201},{"text":"data they offer equivariance which means","start":1188.98,"duration":4.199},{"text":"that position and pose information are","start":1191.5,"duration":4.32},{"text":"preserved and this is very promising for","start":1193.179,"duration":4.671},{"text":"image segmentation and object detection","start":1195.82,"duration":4.83},{"text":"the routing by agreement algorithm is","start":1197.85,"duration":5.079},{"text":"great for crowded scenes the routing","start":1200.65,"duration":4.38},{"text":"tree also maps the hierarchy of objects","start":1202.929,"duration":4.411},{"text":"parts so every part is associated to a","start":1205.03,"duration":4.8},{"text":"whole and it's rather robust to","start":1207.34,"duration":5.339},{"text":"rotations translations and other FIM","start":1209.83,"duration":5.88},{"text":"transformations the activation vectors","start":1212.679,"duration":5.551},{"text":"are somewhat interpretable and finally","start":1215.71,"duration":4.95},{"text":"obviously its sentence idea so don't bet","start":1218.23,"duration":5.37},{"text":"against it however there are a few cons","start":1220.66,"duration":5.73},{"text":"first as I mentioned the results are not","start":1223.6,"duration":5.22},{"text":"yet state-of-the-art on cipher 10 even","start":1226.39,"duration":4.02},{"text":"though it's a good start plus it's still","start":1228.82,"duration":3.39},{"text":"unclear whether capsule networks can","start":1230.41,"duration":4.35},{"text":"scale to larger images such as the image","start":1232.21,"duration":4.62},{"text":"net data set you know what will the","start":1234.76,"duration":5.22},{"text":"accuracy be capsule networks are also","start":1236.83,"duration":5.61},{"text":"quite slow to Train in large part","start":1239.98,"duration":4.439},{"text":"because of the routing by agreement","start":1242.44,"duration":4.56},{"text":"algorithm which has an inner loop as you","start":1244.419,"duration":3.331},{"text":"saw earlier","start":1247.0,"duration":3.78},{"text":"finally there is only one capsule of any","start":1247.75,"duration":4.86},{"text":"type in a given location so it's","start":1250.78,"duration":3.54},{"text":"impossible for a capsule network to","start":1252.61,"duration":3.87},{"text":"detect two objects of the same type if","start":1254.32,"duration":4.859},{"text":"they are too close to one another this","start":1256.48,"duration":4.8},{"text":"is called crowding and it's been","start":1259.179,"duration":4.021},{"text":"observed in human vision as well so it's","start":1261.28,"duration":5.49},{"text":"probably not a showstopper alright I","start":1263.2,"duration":5.49},{"text":"highly recommend you take a look at the","start":1266.77,"duration":4.11},{"text":"code of a caps net implementation such","start":1268.69,"duration":4.59},{"text":"as the ones listed here I'll leave the","start":1270.88,"duration":4.169},{"text":"links in the video description below if","start":1273.28,"duration":3.63},{"text":"you take your time you should have no","start":1275.049,"duration":3.271},{"text":"problem understanding everything the","start":1276.91,"duration":3.45},{"text":"code is doing the main difficulty in","start":1278.32,"duration":3.989},{"text":"implementing caps nets is that it","start":1280.36,"duration":3.93},{"text":"contains an inner loop for the routing","start":1282.309,"duration":4.321},{"text":"by agreement algorithm implementing","start":1284.29,"duration":3.9},{"text":"loops in Kerris and tensorflow","start":1286.63,"duration":3.78},{"text":"can be a little bit trickier than in pi","start":1288.19,"duration":5.46},{"text":"torch but it can be done so if you don't","start":1290.41,"duration":4.8},{"text":"have a particular preference then I","start":1293.65,"duration":3.12},{"text":"would say that the PI torch code is","start":1295.21,"duration":4.56},{"text":"probably the easiest to understand and","start":1296.77,"duration":5.01},{"text":"that's all I had I hope you enjoyed this","start":1299.77,"duration":4.08},{"text":"video if you did please thumbs up share","start":1301.78,"duration":4.38},{"text":"comment subscribe blah blah blah it's my","start":1303.85,"duration":4.709},{"text":"first real YouTube video and if people","start":1306.16,"duration":4.11},{"text":"find it useful I'm","start":1308.559,"duration":4.021},{"text":"make some more if you want to learn more","start":1310.27,"duration":4.44},{"text":"about machine learning deep learning and","start":1312.58,"duration":4.02},{"text":"deep reinforcement learning you may want","start":1314.71,"duration":4.08},{"text":"to read my Holly book hands on machine","start":1316.6,"duration":3.63},{"text":"learning with scikit-learn and","start":1318.79,"duration":4.41},{"text":"tensorflow it covers a ton of topics","start":1320.23,"duration":4.77},{"text":"with many code examples that you will","start":1323.2,"duration":4.44},{"text":"find on my github account so I'll leave","start":1325.0,"duration":4.55},{"text":"the links in the video description","start":1327.64,"duration":4.95},{"text":"that's all for today have fun and see","start":1329.55,"duration":5.49},{"text":"you next time","start":1332.59,"duration":2.45}],"2Kawrd5szHE":[{"text":"hi I'm over LaVon and today I'm going to","start":0.35,"duration":5.11},{"text":"show you how to implement a capsule","start":3.72,"duration":4.23},{"text":"network using tensor flow in my previous","start":5.46,"duration":4.41},{"text":"video I presented the key ideas behind","start":7.95,"duration":4.08},{"text":"capsule networks a recently published","start":9.87,"duration":4.41},{"text":"neural net architecture if you haven't","start":12.03,"duration":4.29},{"text":"seen this video I encourage you to do so","start":14.28,"duration":4.62},{"text":"now today I will focus on the tensor","start":16.32,"duration":3.75},{"text":"flow implementation","start":18.9,"duration":3.99},{"text":"I wrote a jupiter notebook containing","start":20.07,"duration":4.83},{"text":"all the code and detailed explanations","start":22.89,"duration":4.02},{"text":"and i published it on my github account","start":24.9,"duration":4.949},{"text":"as always I'll put all the links in the","start":26.91,"duration":4.98},{"text":"video description below so I encourage","start":29.849,"duration":5.071},{"text":"you to clone it and play with it so it","start":31.89,"duration":4.65},{"text":"reaches over ninety-nine point four","start":34.92,"duration":3.63},{"text":"accuracy on the test set which is pretty","start":36.54,"duration":4.44},{"text":"good considering it's a shallow network","start":38.55,"duration":4.86},{"text":"with just two capsule layers and a total","start":40.98,"duration":5.94},{"text":"of about 1200 capsules there's a lot of","start":43.41,"duration":5.85},{"text":"code in the in this notebook so I won't","start":46.92,"duration":4.02},{"text":"go through every single line in this","start":49.26,"duration":3.299},{"text":"video but I'll explain the main","start":50.94,"duration":3.599},{"text":"difficulties I came across and hopefully","start":52.559,"duration":3.511},{"text":"this will be useful to you for other","start":54.539,"duration":3.901},{"text":"tensor flow implementations not just","start":56.07,"duration":4.86},{"text":"caps nets okay let's build a network","start":58.44,"duration":5.16},{"text":"first we need to feed the input images","start":60.93,"duration":5.34},{"text":"to the network and that's our input","start":63.6,"duration":5.49},{"text":"layer we implement it using a simple","start":66.27,"duration":5.34},{"text":"tensor flow placeholder the batch size","start":69.09,"duration":5.04},{"text":"is unspecified so that we can pass any","start":71.61,"duration":5.13},{"text":"number of images in each batch in this","start":74.13,"duration":5.97},{"text":"example 5 note that we directly send","start":76.74,"duration":6.15},{"text":"Tony 8 by 28 pixel images with a single","start":80.1,"duration":4.71},{"text":"channel since the images are grayscale","start":82.89,"duration":3.99},{"text":"color images would typically have 3","start":84.81,"duration":4.11},{"text":"channels for red green and blue and","start":86.88,"duration":5.4},{"text":"that's it for the input layer next let's","start":88.92,"duration":6.12},{"text":"build the primary capsule layer for each","start":92.28,"duration":5.97},{"text":"digit in the batch it will output 32","start":95.04,"duration":6.36},{"text":"maps each containing a 6 by 6 grid of 8","start":98.25,"duration":6.299},{"text":"dimensional vectors the capsules in this","start":101.4,"duration":5.34},{"text":"particular map seem to detect the start","start":104.549,"duration":4.801},{"text":"of a line segment that you can see that","start":106.74,"duration":4.559},{"text":"the output vectors are long in the","start":109.35,"duration":3.629},{"text":"locations where there's a start of a","start":111.299,"duration":4.5},{"text":"line and the orientation of the ad","start":112.979,"duration":5.731},{"text":"vector gives the pose parameters in this","start":115.799,"duration":5.701},{"text":"case I've represented the rotation angle","start":118.71,"duration":4.47},{"text":"but the vectors a dimensional","start":121.5,"duration":3.78},{"text":"orientation would also capture things","start":123.18,"duration":4.259},{"text":"like the thickness of the line the","start":125.28,"duration":4.199},{"text":"precise location of the start of the","start":127.439,"duration":4.981},{"text":"line relative to the cell in the 6 by 6","start":129.479,"duration":4.161},{"text":"grid and so","start":132.42,"duration":3.45},{"text":"the implementation is really","start":133.64,"duration":2.95},{"text":"straightforward","start":135.87,"duration":2.61},{"text":"first we define two regular","start":136.59,"duration":4.44},{"text":"convolutional layers the input of the","start":138.48,"duration":5.28},{"text":"first layer is X the placeholder that","start":141.03,"duration":4.95},{"text":"will contain the input images we will","start":143.76,"duration":4.77},{"text":"feed at runtime the second layer takes","start":145.98,"duration":5.07},{"text":"the output of the first layer of course","start":148.53,"duration":5.19},{"text":"and we use the parameters specified in","start":151.05,"duration":5.46},{"text":"the paper the second layer is configured","start":153.72,"duration":6.45},{"text":"to output 256 feature maps each feature","start":156.51,"duration":7.29},{"text":"map contains 6x6 grid of scalars we want","start":160.17,"duration":6.99},{"text":"a 6x6 a grid of vectors instead so we","start":163.8,"duration":6.0},{"text":"use tensor flows reshape function to get","start":167.16,"duration":5.07},{"text":"32 Maps of eight dimensional vectors","start":169.8,"duration":6.06},{"text":"instead of 256 maps of scalars in fact","start":172.23,"duration":5.759},{"text":"since the primary capsules will be fully","start":175.86,"duration":4.53},{"text":"connected to the digit capsules we can","start":177.989,"duration":7.53},{"text":"simply reshape to one long list of 1152","start":180.39,"duration":7.56},{"text":"output vectors that's a thirty-two times","start":185.519,"duration":4.8},{"text":"six times six for each instance in the","start":187.95,"duration":5.61},{"text":"batch and the last step is to squash the","start":190.319,"duration":5.041},{"text":"vectors to ensure that their length is","start":193.56,"duration":5.13},{"text":"always between zero and one for this we","start":195.36,"duration":6.39},{"text":"use a homemade squash function here it","start":198.69,"duration":5.34},{"text":"is this function implements the squash","start":201.75,"duration":5.73},{"text":"equation given in the paper it squashes","start":204.03,"duration":5.28},{"text":"every vector in an array along the","start":207.48,"duration":4.259},{"text":"specified dimension by default the last","start":209.31,"duration":5.25},{"text":"one so as you can see it involves a","start":211.739,"duration":5.25},{"text":"division by the norm of the vector so","start":214.56,"duration":4.59},{"text":"there's a risk of a division by zero if","start":216.989,"duration":4.201},{"text":"at least one of the vectors is a zero","start":219.15,"duration":4.8},{"text":"vector so you could just add a tiny","start":221.19,"duration":5.19},{"text":"epsilon value in the denominator and it","start":223.95,"duration":4.5},{"text":"would fix the division by zero problem","start":226.38,"duration":4.77},{"text":"however you would still run into another","start":228.45,"duration":5.64},{"text":"issue the norm of a vector has no","start":231.15,"duration":5.339},{"text":"defined gradients when the vector is","start":234.09,"duration":4.979},{"text":"zero so if you just use tensor flows","start":236.489,"duration":4.711},{"text":"norm function to compute the norm in","start":239.069,"duration":4.621},{"text":"this equation then if at least one of","start":241.2,"duration":4.74},{"text":"the vectors is zero the gradients will","start":243.69,"duration":5.46},{"text":"be undefined it will return n a n and","start":245.94,"duration":4.05},{"text":"not","start":249.15,"duration":3.54},{"text":"so as a result when greed in descent","start":249.99,"duration":5.01},{"text":"updates the weights of our model the","start":252.69,"duration":4.8},{"text":"weights will end up being undefined as","start":255.0,"duration":4.89},{"text":"well the model would effectively be dead","start":257.49,"duration":5.07},{"text":"then you don't want that so the trick is","start":259.89,"duration":5.07},{"text":"to compute a safe approximation of the","start":262.56,"duration":4.97},{"text":"norm shown in the equation on the right","start":264.96,"duration":6.09},{"text":"and that's about it that's all for the","start":267.53,"duration":5.98},{"text":"primary capsules apart for computing the","start":271.05,"duration":4.89},{"text":"norm safely it was pretty straight","start":273.51,"duration":5.61},{"text":"forward on to the next layer where all","start":275.94,"duration":5.58},{"text":"the complexity is the digit capsules","start":279.12,"duration":5.64},{"text":"there are just ten of them one for each","start":281.52,"duration":6.27},{"text":"digits 0 to 9 and the output 16","start":284.76,"duration":5.13},{"text":"dimensional vectors in this particular","start":287.79,"duration":3.99},{"text":"example you can see that the longest","start":289.89,"duration":5.1},{"text":"output vector is the one for digit 4 and","start":291.78,"duration":6.21},{"text":"again it's orientation in the 16","start":294.99,"duration":4.8},{"text":"dimensional space gives information","start":297.99,"duration":3.69},{"text":"about the pose of this digit its","start":299.79,"duration":3.99},{"text":"rotation its thickness its Q its","start":301.68,"duration":5.01},{"text":"position and so on by the way note that","start":303.78,"duration":5.43},{"text":"most of the position information in the","start":306.69,"duration":5.22},{"text":"first layer was encoded in the location","start":309.21,"duration":5.37},{"text":"of the active capsules in the 6x6 grid","start":311.91,"duration":5.82},{"text":"so for example if I shift the digit 4","start":314.58,"duration":6.08},{"text":"slightly to the left in the input image","start":317.73,"duration":5.52},{"text":"they then different capsules in the","start":320.66,"duration":6.49},{"text":"first layer get activated see so the","start":323.25,"duration":5.88},{"text":"output of these first layer capsules","start":327.15,"duration":4.32},{"text":"only contains a local shift information","start":329.13,"duration":4.17},{"text":"relative to the position of the capsule","start":331.47,"duration":5.04},{"text":"in the 6x6 grid but in the second","start":333.3,"duration":5.49},{"text":"capsule layer the full position","start":336.51,"duration":4.2},{"text":"information is now encoded in the","start":338.79,"duration":4.95},{"text":"orientation of the output vector in 16","start":340.71,"duration":6.39},{"text":"dimensional space ok now let's see how","start":343.74,"duration":5.61},{"text":"to implement this layer the first step","start":347.1,"duration":3.87},{"text":"is to compute the predicted output","start":349.35,"duration":5.13},{"text":"vectors since this second layer is fully","start":350.97,"duration":5.55},{"text":"connected to the first layer we will","start":354.48,"duration":4.38},{"text":"compute one predicted output for each","start":356.52,"duration":4.77},{"text":"pair of first and second layer capsules","start":358.86,"duration":5.19},{"text":"for example using the output of the","start":361.29,"duration":5.25},{"text":"first primary capsule we can predict the","start":364.05,"duration":5.07},{"text":"output vector of the first digit capsule","start":366.54,"duration":5.19},{"text":"for this we just use a transformation","start":369.12,"duration":6.21},{"text":"matrix w11 which will gradually be","start":371.73,"duration":5.85},{"text":"learned during training and we multiply","start":375.33,"duration":4.41},{"text":"it by the output of the first layer","start":377.58,"duration":6.0},{"text":"capsule this gives us u hat 1 1","start":379.74,"duration":5.76},{"text":"which is the predicted output of the","start":383.58,"duration":4.32},{"text":"first digit capsule based on the output","start":385.5,"duration":5.159},{"text":"of the first primary capsule since the","start":387.9,"duration":4.5},{"text":"primary capsules output eight","start":390.659,"duration":3.841},{"text":"dimensional vectors and the digit","start":392.4,"duration":4.139},{"text":"capsules output sixteen dimensional","start":394.5,"duration":5.099},{"text":"vectors the transformation matrix w11","start":396.539,"duration":6.711},{"text":"must be a sixteen by eight matrix","start":399.599,"duration":6.481},{"text":"next we try to predict the output of the","start":403.25,"duration":5.59},{"text":"second digit capsule still based on the","start":406.08,"duration":5.549},{"text":"output of the first primary capsule note","start":408.84,"duration":4.229},{"text":"that we are using a different","start":411.629,"duration":6.03},{"text":"transformation matrix w12 and we do the","start":413.069,"duration":7.32},{"text":"same for the third capsule using W one","start":417.659,"duration":5.521},{"text":"three and so on for all the digit","start":420.389,"duration":5.851},{"text":"capsules then we move on to the second","start":423.18,"duration":5.82},{"text":"primary capsule and we use its output to","start":426.24,"duration":4.769},{"text":"predict the output of the first digit","start":429.0,"duration":4.83},{"text":"capsule and so on for all the digit","start":431.009,"duration":5.791},{"text":"capsules then we move on to the third","start":433.83,"duration":4.98},{"text":"primary capsule we make ten predictions","start":436.8,"duration":6.44},{"text":"and so on you get the picture there are","start":438.81,"duration":7.53},{"text":"1152 primary capsules multiply six by","start":443.24,"duration":7.899},{"text":"six by 32 and ten digit capsules so we","start":446.34,"duration":6.75},{"text":"end up with eleven thousand five hundred","start":451.139,"duration":4.59},{"text":"and twenty predicted output vectors now","start":453.09,"duration":4.289},{"text":"we could just compute them one by one","start":455.729,"duration":4.41},{"text":"but it would be terribly inefficient so","start":457.379,"duration":4.5},{"text":"let's see how we can get all the","start":460.139,"duration":3.75},{"text":"predicted output vectors in just one","start":461.879,"duration":5.13},{"text":"matte small operation now you know that","start":463.889,"duration":5.49},{"text":"tensorflow mat small function lets you","start":467.009,"duration":4.921},{"text":"multiply two matrices but you may not","start":469.379,"duration":3.96},{"text":"know that you can also use it to","start":471.93,"duration":4.44},{"text":"multiply many matrices in one shot this","start":473.339,"duration":4.561},{"text":"will be incredibly efficient especially","start":476.37,"duration":4.949},{"text":"if you are using a GPU card because it","start":477.9,"duration":4.859},{"text":"will perform all the matrix","start":481.319,"duration":3.541},{"text":"multiplications in parallel in many","start":482.759,"duration":4.801},{"text":"different GPU threads so here's how it","start":484.86,"duration":3.089},{"text":"works","start":487.56,"duration":4.56},{"text":"suppose a b c d e f and g h i j k l are","start":487.949,"duration":6.9},{"text":"all matrices you can put these matrices","start":492.12,"duration":5.88},{"text":"in two arrays each with two rows and","start":494.849,"duration":5.701},{"text":"three columns for example so we have two","start":498.0,"duration":4.83},{"text":"dimensions for this 2x3 grid of matrices","start":500.55,"duration":5.459},{"text":"and each matrix is two-dimensional","start":502.83,"duration":5.73},{"text":"so these arrays are two plus two equals","start":506.009,"duration":5.34},{"text":"four dimensional arrays if you pass","start":508.56,"duration":4.889},{"text":"these arrays these four d arrays two","start":511.349,"duration":4.62},{"text":"matmo it will perform an element-wise","start":513.449,"duration":3.421},{"text":"matrix","start":515.969,"duration":4.07},{"text":"application so the result will be this","start":516.87,"duration":8.1},{"text":"four dimensional array containing a x G","start":520.039,"duration":9.101},{"text":"here and B multiplied by H here and so","start":524.97,"duration":7.35},{"text":"on so let's use this to compute all the","start":529.14,"duration":6.3},{"text":"predicted output vectors we can create","start":532.32,"duration":5.58},{"text":"first 4d array containing all the","start":535.44,"duration":5.64},{"text":"transformation matrices there's one row","start":537.9,"duration":6.03},{"text":"per primary capsule and one column per","start":541.08,"duration":6.21},{"text":"digit capsule the second array must","start":543.93,"duration":5.34},{"text":"contain the output vectors of each","start":547.29,"duration":5.549},{"text":"primary capsule then we just pass these","start":549.27,"duration":6.63},{"text":"two arrays to the mole function and it","start":552.839,"duration":4.801},{"text":"gives us the predicted output vectors","start":555.9,"duration":4.35},{"text":"for all the pairs of primary and digit","start":557.64,"duration":6.27},{"text":"capsules since we need to predict the","start":560.25,"duration":6.3},{"text":"outputs of all ten-digit capsules for","start":563.91,"duration":5.76},{"text":"each primary capsule this array must","start":566.55,"duration":5.31},{"text":"contain ten copies of the primary","start":569.67,"duration":5.1},{"text":"capsules outputs we will use the tile","start":571.86,"duration":5.25},{"text":"function to replicate the first column","start":574.77,"duration":7.11},{"text":"of output vectors ten times but there's","start":577.11,"duration":6.99},{"text":"one additional catch we want to make","start":581.88,"duration":4.44},{"text":"these predictions for all the instances","start":584.1,"duration":4.8},{"text":"in the batch not just one instance so","start":586.32,"duration":4.56},{"text":"there's an additional dimension for the","start":588.9,"duration":4.59},{"text":"batch size it turns out that the primary","start":590.88,"duration":5.67},{"text":"output vectors were already computed for","start":593.49,"duration":4.53},{"text":"every single instance","start":596.55,"duration":3.6},{"text":"so the second array is fine it already","start":598.02,"duration":5.88},{"text":"has this dimension but we need to","start":600.15,"duration":6.059},{"text":"replicate the 4d array containing all","start":603.9,"duration":5.01},{"text":"the transformation matrices so that we","start":606.209,"duration":4.981},{"text":"end up with one copy per instance in the","start":608.91,"duration":5.369},{"text":"batch now if you understand this then","start":611.19,"duration":6.6},{"text":"the code should be pretty clear first we","start":614.279,"duration":5.401},{"text":"create a variable containing all the","start":617.79,"duration":4.83},{"text":"transformation matrices it has a one row","start":619.68,"duration":6.54},{"text":"per primary capsule one column per digit","start":622.62,"duration":7.11},{"text":"castle capsule and it contains 16 by 8","start":626.22,"duration":6.72},{"text":"matrices that's four dimensions and we","start":629.73,"duration":5.22},{"text":"add another dimension at the beginning","start":632.94,"duration":5.61},{"text":"of size one to make it easy to tile this","start":634.95,"duration":6.57},{"text":"array for each instance in the batch now","start":638.55,"duration":4.979},{"text":"the variable is initialized randomly","start":641.52,"duration":4.47},{"text":"using a normal distribution of standard","start":643.529,"duration":4.321},{"text":"deviation 0.01","start":645.99,"duration":4.039},{"text":"that's a hyper parameter you can tweet","start":647.85,"duration":5.089},{"text":"and that's about it we create this","start":650.029,"duration":6.511},{"text":"variable next we want to tile this array","start":652.939,"duration":6.45},{"text":"for each instance so first we need to","start":656.54,"duration":4.89},{"text":"know the batch size we don't actually","start":659.389,"duration":4.081},{"text":"know it at graph construction time it","start":661.43,"duration":3.959},{"text":"will only be known when we run the graph","start":663.47,"duration":4.65},{"text":"but we can use tensor flows shape","start":665.389,"duration":5.01},{"text":"function it creates a tensor that will","start":668.12,"duration":5.13},{"text":"know the shape at run time and we grab","start":670.399,"duration":5.011},{"text":"its first dimension which is the batch","start":673.25,"duration":6.18},{"text":"size then we simply tile our big W array","start":675.41,"duration":6.45},{"text":"along the first dimension to get one","start":679.43,"duration":6.029},{"text":"copy per instance now recall that the","start":681.86,"duration":5.849},{"text":"output of the primary capsules was a","start":685.459,"duration":4.081},{"text":"three dimensional array the first","start":687.709,"duration":4.32},{"text":"dimension is the batch size that we will","start":689.54,"duration":5.279},{"text":"know at runtime then there's one row per","start":692.029,"duration":5.341},{"text":"capsule and each capsule has eight","start":694.819,"duration":4.77},{"text":"dimensions so we need to reshape this","start":697.37,"duration":4.259},{"text":"array a bit to get the shape that we are","start":699.589,"duration":5.25},{"text":"looking for to to do the big mat Mulla","start":701.629,"duration":6.45},{"text":"operation first we add an extra","start":704.839,"duration":5.761},{"text":"dimension at the end using tensor flows","start":708.079,"duration":5.641},{"text":"expand dims function and vectors are now","start":710.6,"duration":6.06},{"text":"represented as column vectors instead of","start":713.72,"duration":4.919},{"text":"one dimensional array each of these is a","start":716.66,"duration":4.44},{"text":"column vector column vector is a matrix","start":718.639,"duration":6.3},{"text":"a 2d array with a single column then we","start":721.1,"duration":5.76},{"text":"add another dimension for the digit","start":724.939,"duration":5.731},{"text":"capsules and we replicate all the output","start":726.86,"duration":5.49},{"text":"vectors ten times across this new","start":730.67,"duration":5.839},{"text":"dimension once per digit capsule and","start":732.35,"duration":7.08},{"text":"lastly we just use map Moll to multiply","start":736.509,"duration":4.87},{"text":"the transformation matrices with the","start":739.43,"duration":4.889},{"text":"primary capsules output vectors and we","start":741.379,"duration":4.801},{"text":"get all the digit capsules predicted","start":744.319,"duration":4.14},{"text":"outputs for each pair of primary and","start":746.18,"duration":4.589},{"text":"digit capsules and for each instance in","start":748.459,"duration":5.73},{"text":"the batch in one shot and that's the end","start":750.769,"duration":5.25},{"text":"of the first step for computing the","start":754.189,"duration":4.801},{"text":"digit capsules outputs we now have a","start":756.019,"duration":5.49},{"text":"bunch of predicted output vectors the","start":758.99,"duration":4.889},{"text":"second step is the routing by agreement","start":761.509,"duration":5.43},{"text":"algorithm so first we set all the","start":763.879,"duration":5.4},{"text":"routing weights to 0 for this we just","start":766.939,"duration":5.851},{"text":"use TF zeros there is one weight for","start":769.279,"duration":5.85},{"text":"each pair of primary and digit capsules","start":772.79,"duration":5.099},{"text":"and for each instance the last two","start":775.129,"duration":5.611},{"text":"dimensions here are equal to 1 they will","start":777.889,"duration":6.271},{"text":"be useful in a minute next we compute","start":780.74,"duration":6.42},{"text":"the softmax of each primary capsules 10","start":784.16,"duration":4.529},{"text":"raw routing weights","start":787.16,"duration":4.38},{"text":"okay so softmax happens along this","start":788.689,"duration":7.14},{"text":"dimension next we compute the weighted","start":791.54,"duration":7.229},{"text":"sum of all the predicted output vectors","start":795.829,"duration":5.461},{"text":"for each digit capsule using the routing","start":798.769,"duration":4.231},{"text":"weights so the weighted sum is along","start":801.29,"duration":5.01},{"text":"this dimension this is pretty","start":803.0,"duration":5.25},{"text":"straightforward tensorflow code first","start":806.3,"duration":3.87},{"text":"multiply the routing weights and the","start":808.25,"duration":4.17},{"text":"predicted vectors this is a element-wise","start":810.17,"duration":4.169},{"text":"multiplication not a matrix","start":812.42,"duration":4.8},{"text":"multiplication then just compute the sum","start":814.339,"duration":5.011},{"text":"over the primary capsule dimension and","start":817.22,"duration":4.589},{"text":"the two dimensions we added earlier for","start":819.35,"duration":3.959},{"text":"the routing weights are useful in the","start":821.809,"duration":4.02},{"text":"multiplication step so that the two","start":823.309,"duration":3.811},{"text":"arrays have the same number of","start":825.829,"duration":4.531},{"text":"dimensions the same rank they don't have","start":827.12,"duration":5.43},{"text":"the exact same shape but they have","start":830.36,"duration":4.86},{"text":"compatible shapes so tensorflow will","start":832.55,"duration":5.07},{"text":"perform broadcasting now if you don't","start":835.22,"duration":4.739},{"text":"know what broadcasting is this should","start":837.62,"duration":5.009},{"text":"make it clear I'm multiplying two","start":839.959,"duration":4.531},{"text":"matrices but one of them just has one","start":842.629,"duration":4.71},{"text":"row so tensorflow will act as if this","start":844.49,"duration":5.159},{"text":"row were repeated the appropriate number","start":847.339,"duration":4.201},{"text":"of times you could achieve the same","start":849.649,"duration":4.41},{"text":"thing using tiling as we did earlier but","start":851.54,"duration":4.769},{"text":"this is more efficient and you may","start":854.059,"duration":4.5},{"text":"wonder why we didn't use broadcasting","start":856.309,"duration":4.14},{"text":"earlier but the reason is it does not","start":858.559,"duration":3.931},{"text":"work for matrix multiplication here","start":860.449,"duration":4.7},{"text":"we're doing element wise multiplication","start":862.49,"duration":5.789},{"text":"okay back to the digit capsules we","start":865.149,"duration":5.74},{"text":"computed a weighted sum of the predicted","start":868.279,"duration":5.4},{"text":"vectors for each digit capsule and we","start":870.889,"duration":5.64},{"text":"just run the squash function and we get","start":873.679,"duration":6.27},{"text":"the outputs of the digit capsules all","start":876.529,"duration":6.511},{"text":"right but wait this is just the end of","start":879.949,"duration":5.31},{"text":"round one of the routing by agreement","start":883.04,"duration":4.859},{"text":"algorithm now on to round two","start":885.259,"duration":5.64},{"text":"so first we need to measure how good","start":887.899,"duration":5.55},{"text":"each prediction was and use this to","start":890.899,"duration":5.071},{"text":"update the routing weights for example","start":893.449,"duration":4.14},{"text":"look at the predictions that we made","start":895.97,"duration":4.429},{"text":"using this primary capsules output","start":897.589,"duration":5.881},{"text":"notice that for example the prediction","start":900.399,"duration":5.831},{"text":"for digit four is excellent and this is","start":903.47,"duration":4.949},{"text":"measured using the scalar product of the","start":906.23,"duration":3.93},{"text":"predicted output vector and the","start":908.419,"duration":4.801},{"text":"actual output vector these two vectors","start":910.16,"duration":4.859},{"text":"are actually represented as column","start":913.22,"duration":4.109},{"text":"vectors meaning a matrix with a single","start":915.019,"duration":4.711},{"text":"column so to compute the scalar product","start":917.329,"duration":5.37},{"text":"we must transpose the predicted column","start":919.73,"duration":6.57},{"text":"vector you had J I to get a row vector","start":922.699,"duration":7.2},{"text":"and multiply this this row vector and","start":926.3,"duration":6.389},{"text":"the actual output vector V J which is a","start":929.899,"duration":5.13},{"text":"column vector we will get a one by one","start":932.689,"duration":4.561},{"text":"matrix containing the scalar product of","start":935.029,"duration":4.56},{"text":"the vectors and now of course we need to","start":937.25,"duration":4.829},{"text":"do this for each predicted vector so","start":939.589,"duration":4.651},{"text":"once again we can use the map mol","start":942.079,"duration":4.2},{"text":"function to perform all the matrix","start":944.24,"duration":4.159},{"text":"multiplications in just one shot","start":946.279,"duration":5.191},{"text":"first we must use the tile function to","start":948.399,"duration":5.17},{"text":"get one copy of the actual output","start":951.47,"duration":4.88},{"text":"vectors V J for each primary capsule","start":953.569,"duration":6.21},{"text":"then we use map mo telling it to","start":956.35,"duration":5.799},{"text":"transpose each metric matrix in the","start":959.779,"duration":6.0},{"text":"first array on the fly and lo and behold","start":962.149,"duration":5.94},{"text":"we get all the scalar products at once","start":965.779,"duration":5.191},{"text":"so now we have a measure of agreements","start":968.089,"duration":5.19},{"text":"between each predicted vector and the","start":970.97,"duration":5.52},{"text":"actual output vector we can then add","start":973.279,"duration":5.841},{"text":"these scalar products to the raw whites","start":976.49,"duration":6.0},{"text":"using a simple addition and the rest of","start":979.12,"duration":5.23},{"text":"round 2 is exactly the same as the end","start":982.49,"duration":4.44},{"text":"of round 1 the code is really identical","start":984.35,"duration":4.979},{"text":"except we're now using the raw routing","start":986.93,"duration":5.219},{"text":"ways of round 2 we compute their softmax","start":989.329,"duration":4.711},{"text":"to get the actual routing weights for","start":992.149,"duration":3.99},{"text":"round 2 then we compute the weighted sum","start":994.04,"duration":4.2},{"text":"of all the predicted vectors for each","start":996.139,"duration":4.32},{"text":"digit capsule and finally we squash the","start":998.24,"duration":5.039},{"text":"results and now we have the new digit","start":1000.459,"duration":5.641},{"text":"capsule outputs and we finish round 2 we","start":1003.279,"duration":5.31},{"text":"could do a few more rounds exactly like","start":1006.1,"duration":5.25},{"text":"this one but I'll stop now and use the","start":1008.589,"duration":4.411},{"text":"current output vectors at the end of","start":1011.35,"duration":3.989},{"text":"round 2 as the output of the digit","start":1013.0,"duration":5.79},{"text":"capsules now you probably noticed that I","start":1015.339,"duration":5.521},{"text":"implemented the routing algorithms loop","start":1018.79,"duration":4.409},{"text":"without an actual loop it's a bit like","start":1020.86,"duration":4.5},{"text":"computing the sum of squares from 1 to","start":1023.199,"duration":4.921},{"text":"100 with this code of course this will","start":1025.36,"duration":5.579},{"text":"build a very big tensor flow graph but","start":1028.12,"duration":5.28},{"text":"it works you can think of it as an","start":1030.939,"duration":5.37},{"text":"unrolled loop now cleaner a way to do","start":1033.4,"duration":4.889},{"text":"this would be to write a for loop in","start":1036.309,"duration":3.5},{"text":"Python like this","start":1038.289,"duration":4.43},{"text":"much better however it's important to","start":1039.809,"duration":4.77},{"text":"understand that the resulting tensor","start":1042.719,"duration":4.05},{"text":"photograph will be absolutely identical","start":1044.579,"duration":4.501},{"text":"to the one produced by the previous code","start":1046.769,"duration":4.921},{"text":"all we're doing here is constructing a","start":1049.08,"duration":5.039},{"text":"graph and tensorflow will not even know","start":1051.69,"duration":4.219},{"text":"that we use the loop to build a graph","start":1054.119,"duration":4.98},{"text":"again this works fine it's just that you","start":1055.909,"duration":5.411},{"text":"end up with a very large graph so you","start":1059.099,"duration":4.56},{"text":"can think of this loop as a static loop","start":1061.32,"duration":4.349},{"text":"that only runs at graph construction","start":1063.659,"duration":5.041},{"text":"time if you want a dynamic loop one that","start":1065.669,"duration":5.521},{"text":"tensorflow itself will run then you must","start":1068.7,"duration":4.319},{"text":"use tensor flows while loop function","start":1071.19,"duration":5.609},{"text":"like this the while loop function takes","start":1073.019,"duration":6.21},{"text":"three parameters the first one is a","start":1076.799,"duration":5.61},{"text":"function that must return a tensor that","start":1079.229,"duration":6.3},{"text":"will determine whether the loop should","start":1082.409,"duration":5.82},{"text":"go on or not at each iteration the","start":1085.529,"duration":5.4},{"text":"second parameter is also a function that","start":1088.229,"duration":5.52},{"text":"must build the body of the loop and that","start":1090.929,"duration":4.56},{"text":"will also be evaluated at each iteration","start":1093.749,"duration":5.01},{"text":"and finally third parameter contains a","start":1095.489,"duration":5.4},{"text":"list of tensors that will be sent to","start":1098.759,"duration":4.5},{"text":"both the condition and loop body","start":1100.889,"duration":5.551},{"text":"function at the first iteration for the","start":1103.259,"duration":5.16},{"text":"following iterations these functions","start":1106.44,"duration":4.469},{"text":"will receive the output of the loop body","start":1108.419,"duration":5.1},{"text":"function so you can pause the video if","start":1110.909,"duration":4.08},{"text":"you need to take a closer look at this","start":1113.519,"duration":3.45},{"text":"code once you get it you can try","start":1114.989,"duration":4.201},{"text":"modifying my caps net implementation to","start":1116.969,"duration":4.5},{"text":"use a dynamic loop rather than a static","start":1119.19,"duration":5.279},{"text":"unrolled loop apart from making the code","start":1121.469,"duration":5.79},{"text":"cleaner and the graph smaller using a","start":1124.469,"duration":4.77},{"text":"dynamic loop allows you to change the","start":1127.259,"duration":4.38},{"text":"number of iterations using the exact","start":1129.239,"duration":5.581},{"text":"same model also if you set the swap","start":1131.639,"duration":5.071},{"text":"memory parameter of the while loop","start":1134.82,"duration":4.019},{"text":"function if you set it to true","start":1136.71,"duration":4.469},{"text":"tensorflow will automatically swap the","start":1138.839,"duration":6.0},{"text":"GPU memory to CPU memory when it can to","start":1141.179,"duration":6.99},{"text":"save GPU memory since CPU Ram is much","start":1144.839,"duration":5.611},{"text":"cheaper and abundant this can really be","start":1148.169,"duration":6.45},{"text":"useful and that's it we've computed the","start":1150.45,"duration":6.929},{"text":"output of the digit capsules cool now","start":1154.619,"duration":5.04},{"text":"the length of each output vector","start":1157.379,"duration":4.77},{"text":"represents the probability that a digit","start":1159.659,"duration":6.45},{"text":"of that class is present in the image so","start":1162.149,"duration":6.72},{"text":"let's compute these probabilities for","start":1166.109,"duration":5.581},{"text":"this we cannot use tensor flows norm","start":1168.869,"duration":3.631},{"text":"function","start":1171.69,"duration":3.479},{"text":"because training will explode if there's","start":1172.5,"duration":4.5},{"text":"a zero vector at any point as I","start":1175.169,"duration":4.351},{"text":"mentioned earlier so instead we used a","start":1177.0,"duration":5.49},{"text":"homemade safe norm function similar to","start":1179.52,"duration":5.18},{"text":"what we did with the squash function and","start":1182.49,"duration":4.98},{"text":"note that the sum of the probabilities","start":1184.7,"duration":5.469},{"text":"don't necessarily add up to one because","start":1187.47,"duration":6.12},{"text":"we are not using a soft max layer this","start":1190.169,"duration":5.161},{"text":"makes it possible to detect multiple","start":1193.59,"duration":4.199},{"text":"different digits in the same image but","start":1195.33,"duration":4.86},{"text":"they all have to be different digits","start":1197.789,"duration":5.071},{"text":"view you can detect a 5 and a 3 but you","start":1200.19,"duration":6.96},{"text":"cannot detect say two fives next let's","start":1202.86,"duration":8.01},{"text":"predict the most likely digit we just","start":1207.15,"duration":6.18},{"text":"used the Arg max function that gives us","start":1210.87,"duration":5.16},{"text":"the index of the highest probability the","start":1213.33,"duration":5.16},{"text":"index happens to be the number of the","start":1216.03,"duration":5.31},{"text":"digit itself note that we first get a","start":1218.49,"duration":4.919},{"text":"tensor that has a couple extra","start":1221.34,"duration":5.04},{"text":"dimensions of size one at the end so we","start":1223.409,"duration":4.561},{"text":"get rid of them using the squeeze","start":1226.38,"duration":4.59},{"text":"function if we called squeeze without","start":1227.97,"duration":6.089},{"text":"specifying the axes to remove it would","start":1230.97,"duration":6.03},{"text":"remove all dimensions of size 1 this","start":1234.059,"duration":6.091},{"text":"would generally be okay except if the","start":1237.0,"duration":5.58},{"text":"batch size was equal to 1 in which case","start":1240.15,"duration":4.44},{"text":"we would be left with a scalar value","start":1242.58,"duration":4.77},{"text":"rather than an array and we don't want","start":1244.59,"duration":6.38},{"text":"that so it's better to specify the axes","start":1247.35,"duration":6.75},{"text":"great now we have a capsule network that","start":1250.97,"duration":5.319},{"text":"can estimate class probabilities and","start":1254.1,"duration":5.22},{"text":"make predictions we can measure the","start":1256.289,"duration":5.64},{"text":"models accuracy on the batch by simply","start":1259.32,"duration":4.349},{"text":"comparing the predictions and the labels","start":1261.929,"duration":4.11},{"text":"in this case the prediction for the last","start":1263.669,"duration":4.231},{"text":"digit in the batch is wrong it's seven","start":1266.039,"duration":5.13},{"text":"instead of one so we get 80% accuracy","start":1267.9,"duration":5.61},{"text":"now the code is really straightforward","start":1271.169,"duration":4.38},{"text":"we just use the equal function to","start":1273.51,"duration":3.84},{"text":"compare the labels and the predictions","start":1275.549,"duration":4.801},{"text":"wipe red and this gives us an array of","start":1277.35,"duration":5.579},{"text":"boolean z' so we cast these boolean stew","start":1280.35,"duration":4.53},{"text":"floats which gives us a bunch of zeros","start":1282.929,"duration":4.891},{"text":"for bad predictions and ones for good","start":1284.88,"duration":5.88},{"text":"predictions and we compute the mean to","start":1287.82,"duration":6.57},{"text":"get the batch accuracy the labels Y are","start":1290.76,"duration":5.669},{"text":"just a regular placeholder nothing","start":1294.39,"duration":5.25},{"text":"special and that's it we have a full","start":1296.429,"duration":5.551},{"text":"model able to make predictions now let's","start":1299.64,"duration":5.279},{"text":"look at the training code this diagram","start":1301.98,"duration":3.49},{"text":"is about two","start":1304.919,"duration":2.521},{"text":"get pretty crowded so I'll remove the","start":1305.47,"duration":6.18},{"text":"accuracy for clarity and now first we","start":1307.44,"duration":6.91},{"text":"want to compute the margin loss it's","start":1311.65,"duration":5.37},{"text":"given by this equation by the way I made","start":1314.35,"duration":4.53},{"text":"a mistake in my first video I squared","start":1317.02,"duration":4.32},{"text":"norms instead of squaring the max","start":1318.88,"duration":5.31},{"text":"operations sorry about that this here is","start":1321.34,"duration":5.79},{"text":"the correct equation computing it is","start":1324.19,"duration":4.619},{"text":"pretty straightforward so I won't go","start":1327.13,"duration":3.81},{"text":"through it in details the only trick is","start":1328.809,"duration":4.23},{"text":"to understand how you can easily compute","start":1330.94,"duration":5.34},{"text":"all the TK values for a given instance","start":1333.039,"duration":6.151},{"text":"TK is equal to 1 if a digit of cos K is","start":1336.28,"duration":4.769},{"text":"present in the image otherwise it's","start":1339.19,"duration":5.25},{"text":"equal to 0 you can get all the TK values","start":1341.049,"duration":5.61},{"text":"for each instance by simply converting","start":1344.44,"duration":5.099},{"text":"the labels to one hot representation for","start":1346.659,"duration":5.731},{"text":"example if an instance label is three","start":1349.539,"duration":5.311},{"text":"then for this instance T will contain a","start":1352.39,"duration":4.44},{"text":"10 dimensional vector full of zeros","start":1354.85,"duration":6.0},{"text":"except for a 1 its index 3 okay next we","start":1356.83,"duration":5.94},{"text":"want to compute the reconstruction loss","start":1360.85,"duration":5.04},{"text":"so first we must send the outputs of the","start":1362.77,"duration":5.49},{"text":"digit capsules to a decoder that will","start":1365.89,"duration":4.35},{"text":"try to use them to reconstruct the input","start":1368.26,"duration":5.13},{"text":"images this decoder is just a regular","start":1370.24,"duration":5.22},{"text":"feed-forward neural net composed of","start":1373.39,"duration":4.89},{"text":"three fully connected layers it's really","start":1375.46,"duration":4.949},{"text":"simple code so you can pause the video","start":1378.28,"duration":4.019},{"text":"if you want and take a close look at it","start":1380.409,"duration":5.25},{"text":"it outputs an array containing 784","start":1382.299,"duration":6.171},{"text":"values from 0 to 1 for each instance","start":1385.659,"duration":6.0},{"text":"representing the pixel intensities of 28","start":1388.47,"duration":7.18},{"text":"by 28 pixel images and that's it we have","start":1391.659,"duration":6.601},{"text":"our reconstructed images we can now","start":1395.65,"duration":5.46},{"text":"compute the reconstruction loss this is","start":1398.26,"duration":4.62},{"text":"just the squared difference between the","start":1401.11,"duration":3.98},{"text":"input images and the reconstructions","start":1402.88,"duration":6.029},{"text":"since the input images are 28 by 28 by 1","start":1405.09,"duration":6.49},{"text":"we first reshape them to one dimension","start":1408.909,"duration":6.091},{"text":"per instance with 784 values each then","start":1411.58,"duration":6.27},{"text":"we compute the squared difference now we","start":1415.0,"duration":6.21},{"text":"can compute the final loss it's just the","start":1417.85,"duration":5.49},{"text":"sum of the margin loss and the","start":1421.21,"duration":4.56},{"text":"reconstruction loss scale down to let","start":1423.34,"duration":4.98},{"text":"the margin loss dominate training pretty","start":1425.77,"duration":4.529},{"text":"simple as you can see now let's add the","start":1428.32,"duration":4.41},{"text":"training operation the paper mentions","start":1430.299,"duration":4.771},{"text":"they use tensor flows implementation of","start":1432.73,"duration":4.38},{"text":"the atom optimizer using the default","start":1435.07,"duration":3.75},{"text":"parameters so let's do that","start":1437.11,"duration":3.99},{"text":"we create the optimizer and call it's","start":1438.82,"duration":3.9},{"text":"minimized method to get the training","start":1441.1,"duration":3.3},{"text":"operation that will tweak the model","start":1442.72,"duration":4.32},{"text":"parameters to minimize the loss we're","start":1444.4,"duration":4.74},{"text":"almost done but there's one last detail","start":1447.04,"duration":4.17},{"text":"I didn't mention in the first video the","start":1449.14,"duration":4.65},{"text":"paper indicates that the outputs of the","start":1451.21,"duration":5.16},{"text":"digit capsules should all be masked out","start":1453.79,"duration":4.98},{"text":"except for the ones corresponding to the","start":1456.37,"duration":5.01},{"text":"target digit so instead of sending the","start":1458.77,"duration":5.13},{"text":"digit capsules outputs directly to the","start":1461.38,"duration":5.37},{"text":"decoder we want to apply a mask first","start":1463.9,"duration":6.15},{"text":"like this the mask will have the same","start":1466.75,"duration":5.94},{"text":"shape as the digit capsules output array","start":1470.05,"duration":5.55},{"text":"and it will be equal to zero everywhere","start":1472.69,"duration":5.91},{"text":"except for once at the location of the","start":1475.6,"duration":6.3},{"text":"target digits by multiplying the digit","start":1478.6,"duration":5.97},{"text":"capsules output in the mask we get the","start":1481.9,"duration":5.79},{"text":"input to the decoder but there's one","start":1484.57,"duration":4.83},{"text":"catch this picture is good for training","start":1487.69,"duration":4.5},{"text":"but at test time we won't have the","start":1489.4,"duration":5.76},{"text":"labels so instead we will master the","start":1492.19,"duration":5.07},{"text":"output vectors using the predicted","start":1495.16,"duration":6.39},{"text":"classes rather than labels like this now","start":1497.26,"duration":5.82},{"text":"we could build a different graph for","start":1501.55,"duration":4.32},{"text":"training and for testing but it wouldn't","start":1503.08,"duration":5.22},{"text":"be very convenient so instead let's","start":1505.87,"duration":4.89},{"text":"build a conditioned operation we will","start":1508.3,"duration":4.68},{"text":"add a boolean a placeholder called mask","start":1510.76,"duration":5.19},{"text":"with labels if it is true then we use","start":1512.98,"duration":5.7},{"text":"the labels to build the mask if it is","start":1515.95,"duration":4.68},{"text":"false then we use the prediction note","start":1518.68,"duration":5.7},{"text":"the difference okay and here's the code","start":1520.63,"duration":6.3},{"text":"we build the mask of labels placeholder","start":1524.38,"duration":4.77},{"text":"which will default to false so that we","start":1526.93,"duration":4.26},{"text":"only need to set it during training and","start":1529.15,"duration":3.99},{"text":"then we define the reconstruction","start":1531.19,"duration":4.14},{"text":"targets using tensorflow scon function","start":1533.14,"duration":5.58},{"text":"it takes three arguments the first one","start":1535.33,"duration":6.42},{"text":"is a tensor representing the condition","start":1538.72,"duration":5.04},{"text":"in this case simply the mask with labels","start":1541.75,"duration":4.47},{"text":"placeholder the second parameter is a","start":1543.76,"duration":4.38},{"text":"function that returns the tensor to use","start":1546.22,"duration":4.44},{"text":"if the condition is true and the third","start":1548.14,"duration":4.77},{"text":"parameter is a function that returns the","start":1550.66,"duration":3.75},{"text":"tensor to use that the condition is","start":1552.91,"duration":4.56},{"text":"false then to build the mask we simply","start":1554.41,"duration":5.88},{"text":"use the one-hot function now there's","start":1557.47,"duration":4.92},{"text":"actually one slight problem with this","start":1560.29,"duration":5.13},{"text":"implementation and to explain it I need","start":1562.39,"duration":5.07},{"text":"to step back for a second and talk about","start":1565.42,"duration":4.71},{"text":"how tensorflow evaluates","start":1567.46,"duration":6.31},{"text":"suppose we built this graph these are","start":1570.13,"duration":4.51},{"text":"all tensorflow","start":1573.77,"duration":3.42},{"text":"operations and we want to evaluate the","start":1574.64,"duration":5.46},{"text":"output of operation a the first thing","start":1577.19,"duration":5.22},{"text":"tensorflow will do is resolve the","start":1580.1,"duration":5.64},{"text":"dependencies it will find all the","start":1582.41,"duration":5.97},{"text":"operations that a depends on directly or","start":1585.74,"duration":4.89},{"text":"indirectly by traversing the graph","start":1588.38,"duration":5.19},{"text":"backwards in this case we'll find C D","start":1590.63,"duration":6.27},{"text":"and F next it will run any of these","start":1593.57,"duration":5.91},{"text":"operations that has no inputs these are","start":1596.9,"duration":6.06},{"text":"called root nodes in this case F once F","start":1599.48,"duration":6.42},{"text":"is evaluated operation C and D now have","start":1602.96,"duration":5.1},{"text":"all the inputs they need so they can be","start":1605.9,"duration":4.92},{"text":"evaluated and tensorflow will actually","start":1608.06,"duration":5.73},{"text":"try to run them in parallel say D","start":1610.82,"duration":6.0},{"text":"finishes first a still has one unev","start":1613.79,"duration":6.48},{"text":"alyou ated input so it can't run yet but","start":1616.82,"duration":5.76},{"text":"as soon as C is finished a can be","start":1620.27,"duration":5.04},{"text":"evaluated and once it's done the eval","start":1622.58,"duration":4.47},{"text":"method returns the result in we're good","start":1625.31,"duration":4.47},{"text":"you can actually evaluate multiple","start":1627.05,"duration":4.98},{"text":"operations at once for example a and E","start":1629.78,"duration":4.62},{"text":"and the process is really the same it","start":1632.03,"duration":5.31},{"text":"finds all the dependencies runs the root","start":1634.4,"duration":5.25},{"text":"operations and then you know goes upward","start":1637.34,"duration":6.18},{"text":"running every operation whose inputs are","start":1639.65,"duration":6.3},{"text":"satisfied and once it's got both the","start":1643.52,"duration":4.77},{"text":"values for a and E it returns the","start":1645.95,"duration":5.58},{"text":"results so let's apply this to our","start":1648.29,"duration":6.06},{"text":"reconstruction targets this tensor is","start":1651.53,"duration":6.3},{"text":"the output of the cond operation which","start":1654.35,"duration":6.45},{"text":"has three parameters mask with labels a","start":1657.83,"duration":6.39},{"text":"function that returns Y and a function","start":1660.8,"duration":6.36},{"text":"that returns wipe red and when we","start":1664.22,"duration":5.16},{"text":"evaluate the reconstruction targets or","start":1667.16,"duration":4.32},{"text":"any tensor that depends on it such as","start":1669.38,"duration":4.62},{"text":"the final loss which depends on the","start":1671.48,"duration":4.05},{"text":"reconstruction loss which eventually","start":1674.0,"duration":3.39},{"text":"depends on the reconstruction targets","start":1675.53,"duration":4.05},{"text":"well what happens is as earlier","start":1677.39,"duration":3.99},{"text":"tensorflow starts by resolving the","start":1679.58,"duration":4.8},{"text":"dependencies it finds all three bottom","start":1681.38,"duration":6.69},{"text":"nodes and it evaluates them all so Y","start":1684.38,"duration":4.98},{"text":"pred may finish first","start":1688.07,"duration":2.97},{"text":"since these operations are run in","start":1689.36,"duration":3.72},{"text":"parallel there's no way to know in which","start":1691.04,"duration":5.31},{"text":"order they will finish so you know Y may","start":1693.08,"duration":6.36},{"text":"finish next and finally mask what label","start":1696.35,"duration":5.7},{"text":"finishes so suppose it evaluates to true","start":1699.44,"duration":4.32},{"text":"now the reconstruct","start":1702.05,"duration":3.87},{"text":"target's has all the inputs it needs so","start":1703.76,"duration":4.65},{"text":"it can it can be evaluated and of course","start":1705.92,"duration":3.54},{"text":"it does the right thing","start":1708.41,"duration":2.91},{"text":"since masks with labels is true it","start":1709.46,"duration":5.97},{"text":"returns the value of y which is good but","start":1711.32,"duration":6.15},{"text":"notice that y pred was evaluated for","start":1715.43,"duration":4.74},{"text":"nothing we're not using its output it's","start":1717.47,"duration":4.59},{"text":"not a big deal since during training we","start":1720.17,"duration":3.96},{"text":"need to evaluate the margin loss which","start":1722.06,"duration":3.45},{"text":"depends on the estimated class","start":1724.13,"duration":3.84},{"text":"probabilities which is just one step","start":1725.51,"duration":4.17},{"text":"away from the prediction so computing","start":1727.97,"duration":4.11},{"text":"the predictions won't add much overhead","start":1729.68,"duration":4.94},{"text":"but still it's a bit unfortunate","start":1732.08,"duration":5.37},{"text":"now suppose mask what labels evaluates","start":1734.62,"duration":6.16},{"text":"to false then again the reconstruction","start":1737.45,"duration":5.07},{"text":"targets will do the right thing it will","start":1740.78,"duration":5.07},{"text":"output the value of y pred but this time","start":1742.52,"duration":6.33},{"text":"how we evaluated y for nothing it's just","start":1745.85,"duration":4.65},{"text":"a placeholder so it won't add much","start":1748.85,"duration":3.36},{"text":"computation time but it means that we","start":1750.5,"duration":4.32},{"text":"must feed why even if mask with labels","start":1752.21,"duration":3.24},{"text":"is false","start":1754.82,"duration":3.06},{"text":"well actually we can just pass an empty","start":1755.45,"duration":5.46},{"text":"array and that's fine so it will work","start":1757.88,"duration":4.85},{"text":"but it's kind of ugly","start":1760.91,"duration":4.59},{"text":"so this unfortunate situation is due to","start":1762.73,"duration":5.08},{"text":"the fact that the functions we passed to","start":1765.5,"duration":4.92},{"text":"the con function do not actually create","start":1767.81,"duration":5.43},{"text":"any tensor they just return tensors that","start":1770.42,"duration":5.43},{"text":"were created outside of these functions","start":1773.24,"duration":5.37},{"text":"so if you build tensors within these","start":1775.85,"duration":5.01},{"text":"functions then tensorflow will do what","start":1778.61,"duration":4.5},{"text":"you expect it will stitch together the","start":1780.86,"duration":4.2},{"text":"partial graphs created within these","start":1783.11,"duration":3.81},{"text":"functions into a graph that will","start":1785.06,"duration":5.22},{"text":"properly handle the dependencies so you","start":1786.92,"duration":5.52},{"text":"might be able to modify my code and fix","start":1790.28,"duration":4.68},{"text":"this ugliness I tried but I ended up","start":1792.44,"duration":4.5},{"text":"with pretty convoluted code so I decided","start":1794.96,"duration":4.47},{"text":"to stick with this implementation I hope","start":1796.94,"duration":5.18},{"text":"it won't keep you awake at night so","start":1799.43,"duration":5.37},{"text":"we've actually finished here's the full","start":1802.12,"duration":5.05},{"text":"picture again the construction phase is","start":1804.8,"duration":5.79},{"text":"over our graph is built now on to the","start":1807.17,"duration":5.91},{"text":"execution phase let's run this graph","start":1810.59,"duration":5.15},{"text":"first let's look at the training code","start":1813.08,"duration":5.55},{"text":"it's really really completely standard","start":1815.74,"duration":6.19},{"text":"you create a session if a check point","start":1818.63,"duration":7.08},{"text":"file exists load it or else initialize","start":1821.93,"duration":6.3},{"text":"all the variables then run the main","start":1825.71,"duration":4.74},{"text":"training loop for a number of epochs and","start":1828.23,"duration":5.34},{"text":"for each epoch run enough iterations to","start":1830.45,"duration":4.56},{"text":"go through the full training set and","start":1833.57,"duration":3.1},{"text":"inside this loop","start":1835.01,"duration":4.36},{"text":"we simply evaluate the training","start":1836.67,"duration":6.51},{"text":"operation and the loss on the next batch","start":1839.37,"duration":7.29},{"text":"we feed the images and the labels of the","start":1843.18,"duration":5.76},{"text":"current training batch and we set masks","start":1846.66,"duration":4.95},{"text":"with labels to true that's pretty much","start":1848.94,"duration":4.53},{"text":"all there is to it and the note book I","start":1851.61,"duration":3.84},{"text":"also added a simple implementation of","start":1853.47,"duration":3.96},{"text":"early stopping and I print out the","start":1855.45,"duration":4.47},{"text":"progress plus I evaluate the model on","start":1857.43,"duration":4.11},{"text":"the validation set at the end of each","start":1859.92,"duration":4.26},{"text":"epoch but the most important part is","start":1861.54,"duration":6.21},{"text":"here after training I just run a few","start":1864.18,"duration":5.61},{"text":"tests images through the network and get","start":1867.75,"duration":3.69},{"text":"the predictions and reconstructions as","start":1869.79,"duration":3.9},{"text":"you can see the predictions are all","start":1871.44,"duration":4.38},{"text":"correct and the reconstructions are","start":1873.69,"duration":3.78},{"text":"pretty good they're pretty close to the","start":1875.82,"duration":3.81},{"text":"original images except that they're","start":1877.47,"duration":4.97},{"text":"slightly fuzzier and as you can see","start":1879.63,"duration":5.43},{"text":"here's the code there's really nothing","start":1882.44,"duration":5.32},{"text":"special about it I take a few images I","start":1885.06,"duration":5.82},{"text":"start a session and load the model then","start":1887.76,"duration":5.49},{"text":"I just evaluate predictions the","start":1890.88,"duration":4.65},{"text":"predictions and the decoders output and","start":1893.25,"duration":5.43},{"text":"I also get the capsules output so I can","start":1895.53,"duration":6.75},{"text":"tweak them later the ugliness I","start":1898.68,"duration":5.73},{"text":"mentioned earlier is right here right","start":1902.28,"duration":5.61},{"text":"I'm forced to pass an empty array this","start":1904.41,"duration":6.93},{"text":"value will be ignored anyway and finally","start":1907.89,"duration":5.67},{"text":"the code tweaks the output vectors and","start":1911.34,"duration":5.19},{"text":"passes the results to the decoder so we","start":1913.56,"duration":5.07},{"text":"can see what each of the sixteen","start":1916.53,"duration":4.2},{"text":"dimensions represent and the digit","start":1918.63,"duration":4.23},{"text":"capsules output vector for example this","start":1920.73,"duration":4.26},{"text":"image shows the reconstructions we get","start":1922.86,"duration":4.95},{"text":"by tweaking the first parameter so the","start":1924.99,"duration":4.59},{"text":"notebook produces one such image for","start":1927.81,"duration":4.2},{"text":"each of the sixteen parameters and as","start":1929.58,"duration":5.79},{"text":"you can see in the first second and last","start":1932.01,"duration":5.88},{"text":"rows we see that the digits become","start":1935.37,"duration":4.17},{"text":"thinner and thinner we're going to the","start":1937.89,"duration":3.32},{"text":"right or thicker and thicker to the left","start":1939.54,"duration":4.47},{"text":"so it holds information about thickness","start":1941.21,"duration":5.47},{"text":"and in the middle row you can see that","start":1944.01,"duration":5.91},{"text":"the bottom part of the number five gets","start":1946.68,"duration":6.39},{"text":"lifted towards the top so probably","start":1949.92,"duration":5.67},{"text":"that's what this parameter does for this","start":1953.07,"duration":5.61},{"text":"digit before I finish I'd like to thank","start":1955.59,"duration":5.04},{"text":"everyone who shared and commented on my","start":1958.68,"duration":5.25},{"text":"first video I really had no idea it","start":1960.63,"duration":4.62},{"text":"would receive such an enthusiastic","start":1963.93,"duration":4.17},{"text":"response and I'm very very grateful to","start":1965.25,"duration":3.27},{"text":"all of you","start":1968.1,"duration":2.31},{"text":"it definitely motivates me to","start":1968.52,"duration":4.17},{"text":"more videos if you want to learn more","start":1970.41,"duration":4.08},{"text":"about machine learning and support this","start":1972.69,"duration":3.96},{"text":"channel check out my O'Reilly book hands","start":1974.49,"duration":3.36},{"text":"on machine learning with scikit-learn","start":1976.65,"duration":2.04},{"text":"and tensorflow","start":1977.85,"duration":2.31},{"text":"I leave the links in the video","start":1978.69,"duration":3.39},{"text":"description if you speak German there's","start":1980.16,"duration":3.51},{"text":"actually a German translation coming up","start":1982.08,"duration":3.72},{"text":"for Christmas and if you speak French","start":1983.67,"duration":4.41},{"text":"the translation is already available it","start":1985.8,"duration":4.29},{"text":"was split in two books but it's really","start":1988.08,"duration":4.56},{"text":"the same content and that's all I have","start":1990.09,"duration":4.11},{"text":"for today I hope you enjoyed this video","start":1992.64,"duration":3.09},{"text":"and that you learned a thing or two","start":1994.2,"duration":3.87},{"text":"about tensorflow and capsule networks if","start":1995.73,"duration":4.56},{"text":"you did please like share comment","start":1998.07,"duration":3.96},{"text":"subscribe and click on the bell icon","start":2000.29,"duration":3.48},{"text":"next to the subscribe button to receive","start":2002.03,"duration":3.59},{"text":"notifications when I upload new videos","start":2003.77,"duration":5.33},{"text":"see you next time","start":2005.62,"duration":3.48}]},"manual":{"pPN8d0E3900":[{"text":"Hey! I\u2019m Aur\u00e9lien G\u00e9ron, and in this video\nI\u2019ll tell you all about Capsule Networks,","start":0.14,"duration":4.06},{"text":"a hot new architecture for neural nets. Geoffrey\nHinton had the idea of Capsule Networks several","start":4.2,"duration":5.36},{"text":"years ago, and he published a paper in 2011\nthat introduced many of the key ideas, but","start":9.56,"duration":5.431},{"text":"he had a hard time making them work properly,\nuntil now.","start":14.991,"duration":3.669},{"text":"A few weeks ago, in October 2017, a paper\ncalled \u201cDynamic Routing Between Capsules\u201d","start":18.66,"duration":5.839},{"text":"was published by Sara Sabour, Nicholas Frosst\nand of course Geoffrey Hinton. They managed","start":24.499,"duration":4.66},{"text":"to reach state of the art performance on the\nMNIST dataset, and demonstrated considerably","start":29.159,"duration":5.391},{"text":"better results than convolutional neural nets\non highly overlapping digits. So what are","start":34.55,"duration":6.12},{"text":"capsule networks exactly?","start":40.67,"duration":1.76},{"text":"Well, in computer graphics, you start with\nan abstract representation of a scene, for","start":42.43,"duration":4.91},{"text":"example a rectangle at position x=20 and y=30,\nrotated by 16\u00b0, and so on. Each object type","start":47.34,"duration":8.249},{"text":"has various instantiation parameters. Then\nyou call some rendering function, and boom,","start":55.589,"duration":5.86},{"text":"you get an image.","start":61.449,"duration":2.311},{"text":"Inverse graphics, is just the reverse process.\nYou start with an image, and you try to find","start":63.76,"duration":5.249},{"text":"what objects it contains, and what their instantiation\nparameters are. A capsule network is basically","start":69.009,"duration":7.021},{"text":"a neural network that tries to perform inverse\ngraphics.","start":76.03,"duration":4.57},{"text":"It is composed of many capsules. A capsule\nis any function that tries to predict the","start":80.6,"duration":5.64},{"text":"presence and the instantiation parameters\nof a particular object at a given location.","start":86.24,"duration":6.449},{"text":"For example, the network above contains 50\ncapsules. The arrows represent the output","start":92.689,"duration":5.901},{"text":"vectors of these capsules. The capsules output\nvectors. The black arrows correspond to capsules","start":98.59,"duration":6.45},{"text":"that try to find rectangles, while the blue\narrows represent the output of capsules looking","start":105.04,"duration":5.49},{"text":"for triangles. The length of an activation\nvector represents the estimated probability","start":110.53,"duration":7.03},{"text":"that the object the capsule is looking for\nis indeed present. You can see that most arrows","start":117.56,"duration":5.379},{"text":"are tiny, meaning the capsules didn\u2019t detect\nanything, but two arrows are quite long. This","start":122.939,"duration":6.19},{"text":"means that the capsules at these locations\nare pretty confident that they found what","start":129.129,"duration":4.241},{"text":"they were looking for, in this case a rectangle,\nand a triangle.","start":133.37,"duration":4.72},{"text":"Next, the orientation of the activation vector\nencodes the instantiation parameters of the","start":138.09,"duration":6.46},{"text":"object, for example in this case the object\u2019s\nrotation, but it could be also its thickness,","start":144.55,"duration":4.71},{"text":"how stretched or skewed it is, its exact position\n(there might be slight translations), and","start":149.26,"duration":4.97},{"text":"so on. For simplicity, I\u2019ll just focus on\nthe rotation parameter, but in a real capsule","start":154.23,"duration":5.7},{"text":"network, the activation vectors may have 5,\n10 dimensions or more.","start":159.93,"duration":5.22},{"text":"In practice, a good way to implement this\nis to first apply a couple convolutional layers,","start":165.15,"duration":6.449},{"text":"just like in a regular convolutional neural\nnet. This will output an array containing","start":171.599,"duration":5.03},{"text":"a bunch of feature maps. You can then reshape\nthis array to get a set of vectors for each","start":176.629,"duration":6.071},{"text":"location. For example, suppose the convolutional\nlayers output an array containing, say, 18","start":182.7,"duration":5.86},{"text":"feature maps (2 times 9), you can easily reshape\nthis array to get 2 vectors of 9 dimensions","start":188.56,"duration":6.649},{"text":"each, for every location. You could also get\n3 vectors of 6 dimensions each, and so on.","start":195.209,"duration":6.981},{"text":"Something that would look like the capsule\nnetwork represented here with two vectors","start":202.19,"duration":3.85},{"text":"at each location. The last step is to ensure\nthat no vector is longer than 1, since the","start":206.04,"duration":7.16},{"text":"vector\u2019s length is meant to represent a\nprobability, it cannot be greater than 1.","start":213.2,"duration":4.239},{"text":"To do this, we apply a squashing function.\nIt preserves the vector\u2019s orientation, but","start":217.439,"duration":5.181},{"text":"it squashes it to ensure that its length is\nbetween 0 and 1.","start":222.62,"duration":5.47},{"text":"One key feature of Capsule Networks is that\nthey preserve detailed information about the","start":228.09,"duration":5.83},{"text":"object\u2019s location and its pose, throughout\nthe network. For example, if I rotate the","start":233.92,"duration":5.71},{"text":"image slightly, notice that the activation\nvectors also change slightly. Right? This","start":239.63,"duration":6.15},{"text":"is called equivariance. In a regular convolutional\nneural net, there are generally several pooling","start":245.78,"duration":6.55},{"text":"layers, and unfortunately these pooling layers\ntend to lose information, such as the precise","start":252.33,"duration":6.37},{"text":"location and pose of the objects. It\u2019s really\nnot a big deal if you just want to classify","start":258.7,"duration":5.21},{"text":"the whole image, but it makes it challenging\nto perform accurate image segmentation or","start":263.91,"duration":5.47},{"text":"object detection (which require precise location\nand pose). The fact that capsules are equivariant","start":269.38,"duration":8.44},{"text":"makes them very promising for these applications.","start":277.82,"duration":2.59},{"text":"All right, so now let\u2019s see how capsule\nnetworks can handle objects that are composed","start":280.41,"duration":5.32},{"text":"of a hierarchy of parts. For example, consider\na boat centered at position x=22 and y=28,","start":285.73,"duration":7.24},{"text":"and rotated by 16\u00b0. This boat is composed\nof parts. In this case one rectangle and one","start":292.97,"duration":7.56},{"text":"triangle. So this is how it would be rendered.\nNow we want to do the reverse, we want inverse","start":300.53,"duration":6.1},{"text":"graphics, so we want to go from the image\nto this whole hierarchy of parts with their","start":306.63,"duration":4.92},{"text":"instantiation parameters.","start":311.55,"duration":1.87},{"text":"Similarly, we could also draw a house, using\nthe same parts, a rectangle and a triangle,","start":313.42,"duration":5.68},{"text":"but this time organized in a different way.\nSo the trick will be to try to go from this","start":319.1,"duration":6.1},{"text":"image containing a rectangle and a triangle,\nand figure out, not only that the rectangle","start":325.2,"duration":5.83},{"text":"and triangle are at this location and this\norientation, but also that they are part of","start":331.03,"duration":5.24},{"text":"a boat, not a house. So, yeah, let\u2019s figure\nout how it would do this.","start":336.27,"duration":4.73},{"text":"The first step we have already seen: we run\na couple convolutional layers, we reshape","start":341.0,"duration":4.57},{"text":"the output to get vectors, and we squash them.\nThis gives us the output of the primary capsules.","start":345.57,"duration":5.89},{"text":"We\u2019ve got the first layer already. The next\nstep is where most of the magic and complexity","start":351.46,"duration":5.42},{"text":"of capsule networks takes place. Every capsule\nin the first layer tries to predict the output","start":356.88,"duration":7.15},{"text":"of every capsule in the next layer. You might\nwant to pause to think about what this means.","start":364.03,"duration":5.4},{"text":"The capsules in the first layer try to predict\nwhat the second layer capsules will output.","start":369.43,"duration":7.67},{"text":"For example, let\u2019s consider the capsule\nthat detected the rectangle. I\u2019ll call it","start":377.1,"duration":4.06},{"text":"the rectangle-capsule.","start":381.16,"duration":1.99},{"text":"Let\u2019s suppose that there are just two capsules\nin the next layer, the house-capsule and the","start":383.15,"duration":6.78},{"text":"boat-capsule. Since the rectangle-capsule\ndetected a rectangle rotated by 16\u00b0, it predicts","start":389.93,"duration":7.09},{"text":"that the house-capsule will detect a house\nrotated by 16\u00b0, that makes sense, and the","start":397.02,"duration":5.48},{"text":"boat-capsule will detect a boat rotated by\n16\u00b0 as well. That\u2019s what would be consistent","start":402.5,"duration":5.69},{"text":"with the orientation of the rectangle.","start":408.19,"duration":3.53},{"text":"So, to make this prediction, what the rectangle-capsule\ndoes is it simply computes the dot product","start":411.72,"duration":7.21},{"text":"of a transformation matrix W_i,j with its\nown activation vector u_i. During training,","start":418.93,"duration":8.12},{"text":"the network will gradually learn a transformation\nmatrix for each pair of capsules in the first","start":427.05,"duration":4.95},{"text":"and second layer. In other words, it will\nlearn all the part-whole relationships, for","start":432.0,"duration":4.85},{"text":"example the angle between the wall and the\nroof of a house, and so on.","start":436.85,"duration":5.33},{"text":"Now let\u2019s see what the triangle-capsule\npredicts.","start":442.18,"duration":4.15},{"text":"This time, it\u2019s a bit more interesting:\ngiven the rotation angle of the triangle,","start":446.33,"duration":4.69},{"text":"it predicts that the house-capsule will detect\nan upside-down house, and that the boat-capsule","start":451.02,"duration":5.66},{"text":"will detect a boat rotated by 16\u00b0. These\nare the positions that would be consistent","start":456.68,"duration":5.91},{"text":"with the rotation angle of the triangle.","start":462.59,"duration":5.109},{"text":"Now we have a bunch of predicted outputs,\nwhat do we do with them?","start":467.699,"duration":4.821},{"text":"As you can see, the rectangle-capsule and\nthe triangle-capsule strongly agree on what","start":472.52,"duration":5.6},{"text":"the boat-capsule will output. In other words,\nthey agree that a boat positioned in this","start":478.12,"duration":4.72},{"text":"way would explain their own positions and\nrotations. And they totally disagree on what","start":482.84,"duration":5.32},{"text":"the house-capsule will output. Therefore,\nit makes sense to assume that the rectangle","start":488.16,"duration":4.9},{"text":"and triangle are part of a boat, not a house.","start":493.06,"duration":4.6},{"text":"Now that we know that the rectangle and triangle\nare part of a boat, the outputs of the rectangle","start":497.66,"duration":5.43},{"text":"capsule and the triangle capsule really concern\nonly the boat capsule, there\u2019s no need to","start":503.09,"duration":4.6},{"text":"send these outputs to any other capsule, this\nwould just add noise. They should be sent","start":507.69,"duration":5.05},{"text":"only to the boat capsule.","start":512.74,"duration":2.48},{"text":"This is called routing by agreement. There\nare several benefits: first, since capsule","start":515.22,"duration":5.41},{"text":"outputs are only routed to the appropriate\ncapsule in the next layer, these capsules","start":520.63,"duration":5.14},{"text":"will get a cleaner input signal and will more\naccurately determine the pose of the object.","start":525.77,"duration":6.37},{"text":"Second, by looking at the paths of the activations,\nyou can easily navigate the hierarchy of parts,","start":532.14,"duration":6.36},{"text":"and know exactly which part belongs to which\nobject (like, the rectangle belongs to the","start":538.5,"duration":4.75},{"text":"boat, or the triangle belongs to the boat,\nand so on). Lastly, routing by agreement helps","start":543.25,"duration":6.81},{"text":"parse crowded scenes with overlapping objects\n(we will see this in a few slides). But first,","start":550.06,"duration":5.75},{"text":"let\u2019s look at how routing by agreement is\nimplemented in Capsule Networks.","start":555.81,"duration":5.4},{"text":"Here, I have represented the various poses\nof the boat, as predicted by the lower-level","start":561.21,"duration":6.41},{"text":"capsules. For example, one of these circles\nmay represent what the rectangle-capsule thinks","start":567.62,"duration":5.2},{"text":"about the most likely pose of the boat, and\nanother circle may represent what the triangle-capsule","start":572.82,"duration":5.82},{"text":"thinks, and if we suppose that there are many\nother low-level capsules, then we might get","start":578.64,"duration":5.12},{"text":"a cloud of prediction vectors, for the boat\ncapsule, like this. In this example, there","start":583.76,"duration":5.351},{"text":"are two pose parameters: one represents the\nrotation angle, and the other represents the","start":589.111,"duration":4.149},{"text":"size of the boat. As I mentioned earlier,\npose parameters may capture many different","start":593.26,"duration":4.46},{"text":"kinds of visual features, like skew, thickness,\nand so on. Or precise location. So the first","start":597.72,"duration":5.48},{"text":"thing we do, is we compute the mean of all\nthese predictions. This gives us this vector.","start":603.2,"duration":6.37},{"text":"The next step is to measure the distance between\neach predicted vector and the mean vector.","start":609.57,"duration":6.76},{"text":"I will use here the euclidian distance here,\nbut capsule networks actually use the scalar","start":616.33,"duration":5.34},{"text":"product. Basically, we want to measure how\nmuch each predicted vector agrees with the","start":621.67,"duration":5.38},{"text":"mean predicted vector. Using this agreement\nmeasure, we can update the weight of every","start":627.05,"duration":6.03},{"text":"predicted vector accordingly.","start":633.08,"duration":3.32},{"text":"Note that the predicted vectors that are far\nfrom the mean now have a very small weight,","start":636.4,"duration":5.72},{"text":"and the ones closest to the mean have a much\nstronger weight. I\u2019ve represented them in","start":642.12,"duration":6.15},{"text":"black. Now we can just compute the mean once\nagain (or I should say, the weighted mean),","start":648.27,"duration":5.56},{"text":"and you\u2019ll notice that it moves slightly\ntowards the cluster, towards the center of","start":653.83,"duration":5.01},{"text":"the cluster.","start":658.84,"duration":1.0},{"text":"So next, we can once again update the weights.\nAnd now most of the vectors within the cluster","start":659.84,"duration":7.9},{"text":"have turned black.\nAnd again, we can update the mean.","start":667.74,"duration":4.23},{"text":"And we can repeat this process a few times.\nIn practice 3 to 5 iterations are generally","start":671.97,"duration":5.95},{"text":"sufficient. This might remind you, I suppose,\nof the k-means clustering algorithm if you","start":677.92,"duration":5.46},{"text":"know it. Okay, so this is how we find clusters\nof agreement. Now let\u2019s see how the whole","start":683.38,"duration":6.31},{"text":"algorithm works in a bit more details.","start":689.69,"duration":3.66},{"text":"First, for every predicted output, we start\nby setting a raw routing weight b_i,j equal","start":693.35,"duration":7.49},{"text":"to 0.","start":700.84,"duration":1.29},{"text":"Next, we apply the softmax function to these\nraw weights, for each primary capsule. This","start":702.13,"duration":8.491},{"text":"gives the actual routing weights for each\npredicted output, in this example 0.5 each.","start":710.621,"duration":9.399},{"text":"Next we compute a weighted sum of the predictions,\nfor each capsule in the next layer. This might","start":720.02,"duration":7.11},{"text":"give vectors longer than 1, so as usual we\napply the squash function.","start":727.13,"duration":7.5},{"text":"And voil\u00e0! We now have the actual outputs\nof the house-capsule and boat-capsule. But","start":734.63,"duration":5.72},{"text":"this is not the final output, it\u2019s just\nthe end of the first round, the first iteration.","start":740.35,"duration":6.07},{"text":"Now we can see which predictions were most\naccurate. For example, the rectangle-capsule","start":746.42,"duration":4.98},{"text":"made a great prediction for the boat-capsule\u2019s\noutput. It really matches it pretty closely.","start":751.4,"duration":6.41},{"text":"This is estimated by computing the scalar\nproduct of the predicted output vector \u00fb_j|i","start":757.81,"duration":5.94},{"text":"and the actual product vector v_j. This scalar\nproduct is simply added to the predicted output\u2019s","start":763.75,"duration":7.78},{"text":"raw routing weight, b_i,j. So the weight of\nthis particular predicted output is increased.","start":771.53,"duration":10.62},{"text":"When there is a strong agreement, this scalar\nproduct is large, so good predictions will","start":782.15,"duration":5.16},{"text":"have a higher weight.","start":787.31,"duration":2.34},{"text":"On the other hand, the rectangle-capsule made\na pretty bad prediction for the house-capsule\u2019s","start":789.65,"duration":4.75},{"text":"output, so the scalar product in this case\nwill be quite small, and the raw routing weight","start":794.4,"duration":6.5},{"text":"of this predicted vector will not grow much.","start":800.9,"duration":2.99},{"text":"Next, we update the routing weights by computing\nthe softmax of the raw weights, once again.","start":803.89,"duration":6.5},{"text":"And as you can see, the rectangle-capsule\u2019s\npredicted vector for the boat-capsule now","start":810.39,"duration":4.53},{"text":"has a weight of 0.8, while it\u2019s predicted\nvector for the house-capsule dropped down","start":814.92,"duration":5.89},{"text":"to 0.2. So most of its output is now going\nto go to the boat capsule, not the house capsule.","start":820.81,"duration":8.89},{"text":"Once again we compute the weighted sum of\nall the predicted output vectors for each","start":829.7,"duration":4.15},{"text":"capsule in the next layer, that is the house-capsule\nand the boat-capsule. And this time, the house-capsule","start":833.85,"duration":5.61},{"text":"gets so little input that its output is a\ntiny vector. On the other hand the boat-capsule","start":839.46,"duration":5.44},{"text":"gets so much input that it outputs a vector\nmuch longer than 1. So again we squash it.","start":844.9,"duration":8.05},{"text":"And that\u2019s the end of round #2. And as you\ncan see, in just a couple iterations, we have","start":852.95,"duration":3.75},{"text":"already ruled out the house and clearly chosen\nthe boat. After perhaps one or two more rounds,","start":856.7,"duration":6.91},{"text":"we can stop and proceed to the next capsule\nlayer in exactly the same way.","start":863.61,"duration":5.58},{"text":"So as I mentioned earlier, routing by agreement\nis really great to handle crowded scenes,","start":869.19,"duration":5.08},{"text":"such as the one represented in this image.\nOne way to interpret this image (as you can","start":874.27,"duration":5.66},{"text":"see there is a bit of ambiguity), you can\nsee a house upside down in the middle. However,","start":879.93,"duration":5.99},{"text":"if this was the case, then there would be\nno explanation for the bottom rectangle or","start":885.92,"duration":5.18},{"text":"the top triangle, no reason for them to be\nwhere they are.","start":891.1,"duration":4.58},{"text":"The best way to interpret the image is that\nthere is a house at the top and a boat at","start":895.68,"duration":5.01},{"text":"the bottom. And routing by agreement will\ntend to choose this solution, since it makes","start":900.69,"duration":5.1},{"text":"all the capsules perfectly happy, each of\nthem making perfect predictions for the capsules","start":905.79,"duration":4.51},{"text":"in the next layer. The ambiguity is explained\naway.","start":910.3,"duration":4.51},{"text":"Okay, so what can you do with a capsule network\nnow that you know how it works.","start":914.81,"duration":5.43},{"text":"Well for one, you can create a nice image\nclassifier of course. Just have one capsule","start":920.24,"duration":5.62},{"text":"per class in the top layer and that\u2019s almost\nall there is to it. All you need to add is","start":925.86,"duration":5.67},{"text":"a layer that computes the length of the top-layer\nactivation vectors, and this gives you the","start":931.53,"duration":5.07},{"text":"estimated class probabilities. You could then\njust train the network by minimizing the cross-entropy","start":936.6,"duration":6.14},{"text":"loss, as in a regular classification neural\nnetwork, and you would be done.","start":942.74,"duration":4.84},{"text":"However, in the paper they use a margin loss\nthat makes it possible to detect multiple","start":947.58,"duration":5.14},{"text":"classes in the image. So without going into\ntoo much details, this margin loss is such","start":952.72,"duration":6.72},{"text":"that if an object of class k is present in\nthe image, then the corresponding top-level","start":959.44,"duration":6.149},{"text":"capsule should output a vector whose\nlength is at least 0.9. It should be long.","start":965.589,"duration":6.721},{"text":"Conversely, if an object of class k is not\npresent in the image, then the capsule should","start":972.31,"duration":4.87},{"text":"output a short vector, one whose length\nis shorter than 0.1. So the total loss is","start":977.18,"duration":6.44},{"text":"the sum of losses for all classes.","start":983.62,"duration":3.719},{"text":"In the paper, they also add a decoder network\non top of the capsule network. It\u2019s just","start":987.339,"duration":4.841},{"text":"3 fully connected layers with a sigmoid activation\nfunction in the output layer. It learns to","start":992.18,"duration":7.54},{"text":"reconstruct the input image by minimizing\nthe squared difference between the reconstructed","start":999.72,"duration":5.48},{"text":"image and the input image.","start":1005.2,"duration":3.6},{"text":"The full loss is the margin loss we discussed\nearlier, plus the reconstruction loss (scaled","start":1008.8,"duration":5.92},{"text":"down considerably so as to ensure that the\nmargin loss dominates training). The benefit","start":1014.72,"duration":5.7},{"text":"of applying this reconstruction loss is that\nit forces the network to preserve all the","start":1020.42,"duration":4.41},{"text":"information required to reconstruct the image,\nup to the top layer of the capsule network,","start":1024.83,"duration":6.86},{"text":"its output layer. This constraint acts a bit\nlike a regularizer: it reduces the risk of","start":1031.69,"duration":6.499},{"text":"overfitting and helps generalize to new examples.","start":1038.189,"duration":5.521},{"text":"And that\u2019s it, you know how a capsule network\nworks, and how to train it. Let\u2019s look a","start":1043.71,"duration":5.62},{"text":"little bit at some of the figures in the paper,\nwhich I find interesting.","start":1049.33,"duration":3.55},{"text":"This is figure 1 from the paper, showing a\nfull capsule network for MNIST. You can see","start":1052.88,"duration":5.87},{"text":"the first two regular convolutional layers,\nwhose output is reshaped and squashed to get","start":1058.75,"duration":5.72},{"text":"the activation vectors of the primary capsules.\nAnd these primary capsules are organized in","start":1064.47,"duration":6.27},{"text":"a 6 by 6 grid, with 32 primary capsules in\neach cell of this grid, and each primary capsule","start":1070.74,"duration":7.53},{"text":"outputs an 8-dimensional vector. So this first\nlayer of capsules is fully connected to the","start":1078.27,"duration":6.671},{"text":"10 output capsules, which output 16 dimensional\nvectors. The length of these vectors is used","start":1084.941,"duration":7.669},{"text":"to compute the margin loss, as explained earlier.","start":1092.61,"duration":3.74},{"text":"Now this is figure 2 from the paper. It shows\nthe decoder sitting on top of the capsnet.","start":1096.35,"duration":5.4},{"text":"It is composed of 2 fully connected ReLU layers\nplus a fully connected sigmoid layer which","start":1101.75,"duration":5.059},{"text":"outputs 784 numbers that correspond to the\npixel intensities of the reconstructed image","start":1106.809,"duration":6.861},{"text":"(which is a 28 by 28 pixel image). The squared\ndifference between this reconstructed image","start":1113.67,"duration":5.99},{"text":"and the input image gives the reconstruction\nloss.","start":1119.66,"duration":3.99},{"text":"Right, and this is figure 4 from the paper.\nOne nice thing about capsule networks is that","start":1123.65,"duration":6.63},{"text":"the activation vectors are often interpretable.\nFor example, this image shows the reconstructions","start":1130.28,"duration":6.32},{"text":"that you get when you gradually modify one\nof the 16 dimensions of the top layer capsules\u2019","start":1136.6,"duration":5.29},{"text":"output. You can see that the first dimension\nseems to represent scale and thickness. The","start":1141.89,"duration":6.53},{"text":"fourth dimension represents a localized skew.\nThe fifth represents the width of the digit","start":1148.42,"duration":11.08},{"text":"plus a slight translation to get the exact\nposition. So as you can see, it\u2019s rather","start":1159.5,"duration":4.24},{"text":"clear what most of these parameters do.","start":1163.74,"duration":1.991},{"text":"Okay, to conclude, let\u2019s summarize the pros\nand cons. Capsule networks have reached state","start":1165.731,"duration":6.389},{"text":"of the art accuracy on MNIST. On CIFAR10,\nthey got a bit over 10% error, which is far","start":1172.12,"duration":5.439},{"text":"from state of the art, but it\u2019s similar\nto what was first obtained with other techniques","start":1177.559,"duration":5.031},{"text":"before years of efforts were put into them,\nso it\u2019s still a good start. Capsule networks","start":1182.59,"duration":5.16},{"text":"require less training data. They offer equivariance,\nwhich means that position and pose information","start":1187.75,"duration":5.48},{"text":"are preserved. And this is very promising\nfor image segmentation and object detection.","start":1193.23,"duration":5.53},{"text":"The routing by agreement algorithm is great\nfor crowded scenes. The routing tree also","start":1198.76,"duration":4.73},{"text":"maps the hierarchy of objects parts, so every\npart is assigned to a whole. And it\u2019s rather","start":1203.49,"duration":5.78},{"text":"robust to rotations, translations and other\naffine transformations. The activation vectors","start":1209.27,"duration":6.71},{"text":"somewhat are interpretable. And finally, obviously,\nit\u2019s Hinton\u2019s idea, so don\u2019t bet against","start":1215.98,"duration":5.37},{"text":"it.","start":1221.35,"duration":1.0},{"text":"However, there are a few cons: first, as I\nmentioned the results are not yet state of","start":1222.35,"duration":4.64},{"text":"the art on CIFAR10, even though it\u2019s a good\nstart. Plus, it\u2019s still unclear whether","start":1226.99,"duration":4.14},{"text":"capsule networks can scale to larger images,\nsuch as the ImageNet dataset. What will the","start":1231.13,"duration":5.67},{"text":"accuracy be? Capsule networks are also quite\nslow to train, in large part because of the","start":1236.8,"duration":6.55},{"text":"routing by agreement algorithm which has an\ninner loop, as you saw earlier. Finally, there","start":1243.35,"duration":5.371},{"text":"is only one capsule of any given type in a\ngiven location, so it\u2019s impossible for a","start":1248.721,"duration":5.06},{"text":"capsule network to detect two objects of the\nsame type if they are too close to one another.","start":1253.781,"duration":5.389},{"text":"This is called crowding, and it has been observed\nin human vision as well, so it\u2019s probably","start":1259.17,"duration":4.38},{"text":"not a show-stopper.","start":1263.55,"duration":1.0},{"text":"All right! I highly recommend you take a look\nat the code of a CapsNet implementation, such","start":1264.55,"duration":6.31},{"text":"as the ones listed here (I\u2019ll leave the\nlinks in the video description below). If","start":1270.86,"duration":4.471},{"text":"you take your time, you should have no problem\nunderstanding everything the code is doing.","start":1275.331,"duration":3.939},{"text":"The main difficulty in implementing CapsNets\nis that it contains an inner loop for the","start":1279.27,"duration":4.63},{"text":"routing by agreement algorithm. Implementing\nloops in Keras and TensorFlow can be a little","start":1283.9,"duration":4.99},{"text":"bit trickier than in PyTorch, but it can be\ndone. If you don\u2019t have a particular preference,","start":1288.89,"duration":6.26},{"text":"then I would say that the PyTorch code is\nthe easiest to understand.","start":1295.15,"duration":4.85},{"text":"And that\u2019s all I had, I hope you enjoyed\nthis video. If you did, please thumbs up,","start":1300.0,"duration":4.33},{"text":"share, comment, subscribe, blablabla. It\u2019s\nmy first real YouTube video, and if people","start":1304.33,"duration":4.53},{"text":"find it useful, I might make some more. If\nyou want to learn more about Machine Learning,","start":1308.86,"duration":5.04},{"text":"Deep Learning and Deep Reinforcement Learning,\nyou may want to read my O\u2019Reilly book Hands-on","start":1313.9,"duration":4.57},{"text":"Machine Learning with Scikit-Learn and TensorFlow.\nIt covers a ton of topics, with many code","start":1318.47,"duration":5.64},{"text":"examples that you will find on my github account,\nso I\u2019ll leave the links in the video description.","start":1324.11,"duration":5.97},{"text":"That\u2019s all for today, have fun and see you\nnext time!","start":1330.08,"duration":3.1}],"2Kawrd5szHE":[{"text":"Hi, I\u2019m Aur\u00e9lien G\u00e9ron, and today I\u2019m\ngoing to show you how to implement a capsule","start":1.18,"duration":4.239},{"text":"network using TensorFlow.","start":5.419,"duration":2.06},{"text":"In my previous video, I presented the key\nideas behind capsule networks, a recently","start":7.479,"duration":4.381},{"text":"published neural net architecture. If you\nhaven\u2019t seen this video, I encourage you","start":11.86,"duration":3.92},{"text":"to do so now, today I will focus on the TensorFlow\nimplementation.","start":15.78,"duration":4.98},{"text":"I wrote a Jupyter notebook containing all\nthe code and detailed explanations, and I","start":20.76,"duration":4.86},{"text":"published it on my github account (as always\nI\u2019ll put all the links in the video description","start":25.62,"duration":5.159},{"text":"below), so I encourage you to clone it, and\nplay with it.","start":30.779,"duration":3.291},{"text":"So, it reaches over 99.4% accuracy on the\ntest set, which is pretty good, considering","start":34.07,"duration":5.76},{"text":"it\u2019s a shallow network with just two capsule\nlayers and a total of about 1,200 capsules.","start":39.83,"duration":5.7},{"text":"There\u2019s a lot of code in this notebook,\nso I won\u2019t go through every single line","start":45.53,"duration":5.17},{"text":"in this video, but I\u2019ll explain the main\ndifficulties I came across, and hopefully","start":50.7,"duration":3.96},{"text":"this will be useful to you for other TensorFlow\nimplementations, not just CapsNets.","start":54.66,"duration":4.489},{"text":"Okay, let\u2019s build the network. First, we\nneed to feed the input images to the network.","start":59.149,"duration":6.451},{"text":"And that\u2019s our input layer.","start":65.6,"duration":1.9},{"text":"We implement it using a simple TensorFlow\nplaceholder. The batch size is unspecified,","start":67.5,"duration":5.61},{"text":"so that we can pass any number of images in\neach batch, in this example, 5. Note that","start":73.11,"duration":5.9},{"text":"we directly send 28x28 pixel images, with\na single channel, since the images are greyscale.","start":79.01,"duration":6.35},{"text":"Color images would typically have 3 channels,\nfor red, green and blue.","start":85.36,"duration":4.15},{"text":"And that\u2019s it for the input layer.","start":89.51,"duration":1.84},{"text":"Next, let\u2019s build the primary capsule layer.\nFor each digit in the batch it will output","start":91.35,"duration":6.33},{"text":"32 maps, each containing a 6x6 grid of 8 dimensional\nvectors.","start":97.68,"duration":5.56},{"text":"The capsules in this particular map seem to\ndetect the start of a line segment. You can","start":103.24,"duration":5.29},{"text":"see that the output vectors are long in the\nlocations where there\u2019s a start of a line.","start":108.53,"duration":5.5},{"text":"And the orientation of the 8D vector gives\nthe pose parameters, in this case, I\u2019ve","start":114.03,"duration":5.92},{"text":"represented the rotation angle, but the vector\u2019s\n8 dimensional orientation would also capture","start":119.95,"duration":5.09},{"text":"things like the thickness of the line, the\nprecise location of the start of the line","start":125.04,"duration":4.789},{"text":"relative to the cell in the 6x6 grid, and\nso on.","start":129.829,"duration":4.811},{"text":"The implementation is really straightforward.\nFirst, we define two regular convolutional","start":134.64,"duration":4.819},{"text":"layers. The input of the first layer is X,\nthe placeholder that will contain the input","start":139.459,"duration":5.86},{"text":"images we will feed at runtime. The second\nlayer takes the output of the first layer.","start":145.319,"duration":6.78},{"text":"And we use the parameters specified in the\npaper. The second layer is configured to output","start":152.099,"duration":5.081},{"text":"256 feature maps. And each feature map contains\na 6x6 grid of scalars. We want a 6x6 grid","start":157.18,"duration":8.429},{"text":"of vectors instead, so we use TensorFlow\u2019s\nreshape() function to get 32 maps of 8 dimensional","start":165.609,"duration":6.16},{"text":"vectors, instead of 256 maps of scalars. In\nfact, since the primary capsules will be fully","start":171.769,"duration":6.23},{"text":"connected to the digit capsules, we can simply\nreshape to one long list of 1,152 output vectors","start":177.999,"duration":8.32},{"text":"(that\u2019s 32*6*6), for each instance in the\nbatch. And the last step is to squash the","start":186.319,"duration":7.18},{"text":"vectors to ensure that their length is always\nbetween 0 and 1. For this, we use a home made","start":193.499,"duration":6.931},{"text":"squash function. There it is.","start":200.43,"duration":2.059},{"text":"This function implements the squash equation\ngiven in the paper.","start":202.489,"duration":4.661},{"text":"It squashes every vector in an array, along\nthe specified dimension, by default the last","start":207.15,"duration":4.8},{"text":"one.","start":211.95,"duration":1.0},{"text":"So, as you can see, it involves a division\nby the norm of the vector, so there\u2019s a","start":212.95,"duration":4.719},{"text":"risk of a division by zero if at least one\nof the vectors is a zero vector.","start":217.669,"duration":4.91},{"text":"So you could just add a tiny epsilon value\nin the denominator, and it would fix the division","start":222.579,"duration":5.0},{"text":"by zero problem. However you would still run\ninto another issue. The norm of a vector has","start":227.579,"duration":6.48},{"text":"no defined gradients when the vector is zero.\nSo if you just use tensorflow\u2019s norm() function","start":234.059,"duration":5.951},{"text":"to compute the norm in this equation, then\nif at least one of the vectors is zero, the","start":240.01,"duration":5.14},{"text":"gradients will be undefined (it will return\nn-a-n, nan, not a number). So, as a result,","start":245.15,"duration":6.69},{"text":"when gradient descent updates the weights\nof our model, the weights will end up being","start":251.84,"duration":5.03},{"text":"undefined as well. The model would effectively\nbe dead. You don\u2019t want that.","start":256.87,"duration":4.829},{"text":"So the trick is to compute a safe approximation\nof the norm, shown in the equation on the","start":261.699,"duration":5.571},{"text":"right.","start":267.27,"duration":1.03},{"text":"And, that's about it, that\u2019s all for the\nprimary capsules. Apart for computing the","start":268.3,"duration":5.149},{"text":"norm safely, it was pretty straightforward.","start":273.449,"duration":4.211},{"text":"On to the next layer where all the complexity\nis: the digit capsules. There are just 10","start":277.66,"duration":5.539},{"text":"of them, one for each digit, 0 to 9, and they\noutput 16 dimensional vectors. In this particular","start":283.199,"duration":6.981},{"text":"example, you can see that the longest output\nvector is the one for digit 4. And again its","start":290.18,"duration":6.15},{"text":"orientation in the 16 dimensional space gives\ninformation about the pose of this digit,","start":296.33,"duration":5.39},{"text":"its rotation, its thickness, its skew, its\nposition, and so on. By the way, note that","start":301.72,"duration":4.969},{"text":"most of the position information in the first\nlayer was encoded in the location of the active","start":306.689,"duration":5.91},{"text":"capsules in the 6x6 grid. So, for example,\nif I shift the digit 4 slightly to the left","start":312.599,"duration":6.79},{"text":"in the input image then different capsules\nin the first layer get activated. See? So,","start":319.389,"duration":7.731},{"text":"the output of these first layer capsules only\ncontain local shift information, relative","start":327.12,"duration":4.84},{"text":"to the position of the capsule in the 6x6\ngrid. But in the second capsule layer, the","start":331.96,"duration":5.979},{"text":"full position information is now encoded in\nthe orientation of the output vector in 16","start":337.939,"duration":6.16},{"text":"dimensional space.","start":344.099,"duration":1.081},{"text":"Okay, now let\u2019s see how to implement this\nlayer. The first step is to compute the predicted","start":345.18,"duration":5.609},{"text":"output vectors. Since this second layer is\nfully connected to the first layer, we will","start":350.789,"duration":5.72},{"text":"compute one predicted output for each pair\nof first and second layer capsules.","start":356.509,"duration":5.571},{"text":"For example, using the output of the first\nprimary capsule, we can predict the output","start":362.08,"duration":5.329},{"text":"vector of the first digit capsule.","start":367.409,"duration":2.421},{"text":"For this, we just use a transformation matrix\nW_1,1, which will gradually be learned during","start":369.83,"duration":6.11},{"text":"training, and we multiply it by the output\nof the first layer capsule. This gives us","start":375.94,"duration":5.79},{"text":"\u00fb_1|1, which is the predicted output of the\nfirst digit capsule, based on the output of","start":381.73,"duration":6.399},{"text":"the first primary capsule. Since the primary\ncapsules output 8 dimensional vectors, and","start":388.129,"duration":5.921},{"text":"the digit capsules output 16 dimensional vectors,\nthe transformation matrix W_1,1 must be a","start":394.05,"duration":7.17},{"text":"16x8 matrix.","start":401.22,"duration":2.11},{"text":"Next, we try to predict the output of the\nsecond digit capsule, still based on the output","start":403.33,"duration":5.88},{"text":"of the first primary capsule. Note that we\nare using a different transformation matrix,","start":409.21,"duration":6.459},{"text":"W_1,2.","start":415.669,"duration":1.571},{"text":"And we do the same for the third digit capsule,\nusing W_1,3.","start":417.24,"duration":4.549},{"text":"And so on for all the digit capsules.","start":421.789,"duration":3.271},{"text":"Then we move on to the second primary capsule,\nand we use its output to predict the output","start":425.06,"duration":5.099},{"text":"of the first digit capsule.","start":430.159,"duration":2.271},{"text":"And so on for all the digit capsules.","start":432.43,"duration":3.109},{"text":"Then we move on to the third primary capsule,\nwe make 10 predictions.","start":435.539,"duration":3.81},{"text":"And so on, you get the picture. There are\n1,152 primary capsules (multiply 6 * 6 * 32),","start":439.349,"duration":9.611},{"text":"and 10 digit capsules, so we end up with 11,520\npredicted output vectors. Now we could just","start":448.96,"duration":7.4},{"text":"compute them one by one, but it would be terribly\ninefficient. Let\u2019s see how we can get all","start":456.36,"duration":5.429},{"text":"the predicted output vectors in just one matmul()\noperation. Now you know that TensorFlow\u2019s","start":461.789,"duration":6.011},{"text":"matmul() function lets you multiply two matrices,\nbut you may not know that you can also use","start":467.8,"duration":5.32},{"text":"it to multiply many matrices in one shot.\nThis will be incredibly efficient, especially","start":473.12,"duration":4.93},{"text":"if you are using a GPU card, because it will\nperform all the matrix multiplications in","start":478.05,"duration":5.549},{"text":"parallel in many different GPU threads.","start":483.599,"duration":2.811},{"text":"So here\u2019s how it works. Suppose A, B, C,\nD, E, F and G, H, I, J, K, L, are all matrices.","start":486.41,"duration":7.409},{"text":"You can put these matrices in two arrays,\neach with 2 rows and 3 columns, for example.","start":493.819,"duration":5.991},{"text":"So we have 2 dimensions for this 2x3 grid\nof matrices, and each matrix is 2 dimensional,","start":499.81,"duration":6.669},{"text":"so these arrays are 2+2=4 dimensional arrays.\nIf you pass these arrays, these 4D arrays,","start":506.479,"duration":6.761},{"text":"to matmul(), it will perform an elementwise\nmatrix multiplication, so the result will","start":513.24,"duration":6.02},{"text":"be this 4 dimensional array containing A multiplied\nby G, here, B multiplied by H, here, and so","start":519.26,"duration":9.819},{"text":"on. So let\u2019s use this to compute all the\npredicted output vectors.","start":529.079,"duration":5.801},{"text":"We can create a first 4D array containing\nall the transformation matrices: there\u2019s","start":534.88,"duration":5.97},{"text":"one row per primary capsule, and one column\nper digit capsule. The second array must contain","start":540.85,"duration":6.88},{"text":"the output vectors of each primary capsule.\nThen we just pass these two arrays to the","start":547.73,"duration":6.59},{"text":"matmul() function, and it gives us the predicted\noutput vectors for all the pairs of primary","start":554.32,"duration":5.43},{"text":"and digit capsules.","start":559.75,"duration":3.12},{"text":"Since we need to predict the outputs of all\n10 digit capsules for each primary capsule,","start":562.87,"duration":5.63},{"text":"this array must contain 10 copies of the primary\ncapsules\u2019 outputs. We will use the tile","start":568.5,"duration":6.29},{"text":"function to replicate the first column of\noutput vectors, 10 times.","start":574.79,"duration":5.81},{"text":"But there\u2019s one additional catch. We want\nto make these predictions for all the instances","start":580.6,"duration":5.72},{"text":"in the batch, not just one instance. So there\u2019s\nan additional dimension for the batch size.","start":586.32,"duration":5.89},{"text":"It turns out that the primary output vectors\nwere already computed for every single instance,","start":592.21,"duration":5.97},{"text":"so the second array is fine. It already has\nthis dimension.","start":598.18,"duration":5.19},{"text":"But we need to replicate the 4D array containing\nall the transformation matrices, so that we","start":603.37,"duration":5.68},{"text":"end up with one copy per instance in the batch.\nNow if you understand this, then the code","start":609.05,"duration":6.089},{"text":"should be pretty clear.","start":615.139,"duration":1.711},{"text":"First, we create a variable containing all\nthe transformation matrices. It has one row","start":616.85,"duration":5.95},{"text":"per primary capsule, one column per digit\ncapsule, and it contains 16 by 8 matrices.","start":622.8,"duration":8.18},{"text":"That\u2019s 4 dimensions, and we add another\ndimension at the beginning of size one at","start":630.98,"duration":6.21},{"text":"the beginning to make it easy to tile this\narray for each instance in the batch. The","start":637.19,"duration":4.5},{"text":"variable is initialized randomly, using a\nnormal distribution of standard deviation","start":641.69,"duration":5.19},{"text":"0.01 (that\u2019s a hyperparameter you can tweak).\nAnd that's about it. Create this variable!","start":646.88,"duration":8.519},{"text":"Next we want to tile this array for each instance,\nso first we need to know the batch size. We","start":655.399,"duration":5.751},{"text":"don\u2019t actually know it at graph construction\ntime, it will only be known when we run the","start":661.15,"duration":4.65},{"text":"graph. But we can use TensorFlow\u2019s shape()\nfunction: it creates a tensor that *will*","start":665.8,"duration":4.83},{"text":"know the shape at runtime, and we grab its\nfirst dimension, which is the batch size.","start":670.63,"duration":6.519},{"text":"Then we simply tile our big W array, along\nthe first dimension, to get one copy per instance.","start":677.149,"duration":6.411},{"text":"Now, recall that the output of the primary\ncapsules was a 3 dimensional array: the first","start":683.56,"duration":6.26},{"text":"dimension is the batch size, that we will\nknow at runtime, then there\u2019s one row per","start":689.82,"duration":5.629},{"text":"capsule, and each capsule has 8 dimensions.\nSo we need to reshape this array a bit to","start":695.449,"duration":4.981},{"text":"get the shape that we are looking for, to\ndo the big matmul() operation.","start":700.43,"duration":6.55},{"text":"First we add an extra dimension at the end,\nusing TensorFlow\u2019s expand_dims() function.","start":706.98,"duration":5.45},{"text":"The vectors are now represented as column\nvectors, instead of 1 dimensional arrays.","start":712.43,"duration":5.48},{"text":"Each of these is a column vector. A column\nvector is a matrix, a 2D array, with a single","start":717.91,"duration":5.05},{"text":"column.","start":722.96,"duration":1.71},{"text":"Then we add another dimension, for the digit\ncapsules.","start":724.67,"duration":4.38},{"text":"And we replicate all the output vectors 10\ntimes across this new dimension, once per","start":729.05,"duration":4.83},{"text":"digit capsule.","start":733.88,"duration":3.22},{"text":"And lastly, we just use matmul to multiply\nthe transformation matrices with the primary","start":737.1,"duration":5.02},{"text":"capsules\u2019 output vectors, and we get all\nthe digit capsule\u2019s predicted outputs for","start":742.12,"duration":4.93},{"text":"each pair of primary and digit capsules, and\nfor each instance in the batch. In one shot.","start":747.05,"duration":6.59},{"text":"And that\u2019s the end of the first step for\ncomputing the digit capsules\u2019 outputs, we","start":753.64,"duration":4.569},{"text":"now have a bunch of predicted output vectors.\nThe second step is the routing by agreement","start":758.209,"duration":5.771},{"text":"algorithm.","start":763.98,"duration":1.469},{"text":"So first, we set all the raw routing weights\nto 0. For this, we just use tf.zeros(). There\u2019s","start":765.449,"duration":6.531},{"text":"one weight for each pair of primary and digits\ncapsules, for each instance. The last two","start":771.98,"duration":5.85},{"text":"dimensions here are equal to 1, they will\nbe useful in a minute.","start":777.83,"duration":5.369},{"text":"Next we compute the softmax of each primary\ncapsule\u2019s 10 raw routing weights. Okay?","start":783.199,"duration":6.281},{"text":"So softmax happens along this dimension.","start":789.48,"duration":3.979},{"text":"Next, we compute the weighted sum of all the\npredicted output vectors, for each digit capsule,","start":793.459,"duration":7.12},{"text":"using the routing weights. The weighted sum\nis along this dimension.","start":800.579,"duration":4.161},{"text":"This is pretty straightforward TensorFlow\ncode: first multiply the routing weights and","start":804.74,"duration":5.339},{"text":"the predicted vectors (this is an elementwise\nmultiplication, not a matrix multiplication),","start":810.079,"duration":5.831},{"text":"then just compute the sum over the primary\ncapsule dimension. And the two dimensions","start":815.91,"duration":4.78},{"text":"we added earlier for the routing weights are\nuseful in the multiplication step, so that","start":820.69,"duration":4.66},{"text":"the two arrays have the same number of dimensions,\nthe same rank. They don\u2019t have the exact","start":825.35,"duration":5.76},{"text":"same shape, but they have compatible shapes\nso TensorFlow will perform broadcasting.","start":831.11,"duration":5.969},{"text":"Now if you don't know what broadcasting is,\nthis should make it clear. I\u2019m multiplying","start":837.079,"duration":5.291},{"text":"two matrices, but one of them just has one\nrow, so TensorFlow will act as if this row","start":842.37,"duration":5.139},{"text":"were repeated the appropriate number of times.\nYou could achieve the same thing using tiling,","start":847.509,"duration":5.401},{"text":"as we did earlier, but this is more efficient.\nYou may wonder why we didn\u2019t use broadcasting","start":852.91,"duration":5.88},{"text":"earlier, but the reason is it does not work\nfor matrix multiplication. Here we are doing","start":858.79,"duration":4.56},{"text":"elementwise multiplication.","start":863.35,"duration":2.37},{"text":"Okay, back to the digit capsules. We computed\na weighted sum of the predicted vectors, for","start":865.72,"duration":6.0},{"text":"each digit capsule, and we just run the squash\nfunction, and we get the outputs of the digit","start":871.72,"duration":7.08},{"text":"capsules. Hurray! But wait, this is just the\nend of round 1 of the routing by agreement","start":878.8,"duration":6.45},{"text":"algorithm. Now, on to round #2.","start":885.25,"duration":3.34},{"text":"So first, we need to measure how good each\nprediction was, and use this to update the","start":888.59,"duration":5.29},{"text":"routing weights.","start":893.88,"duration":1.0},{"text":"For example, look at the predictions that\nwe made using this primary capsule\u2019s output.","start":894.88,"duration":6.49},{"text":"Notice that, for example, the prediction for\ndigit 4, is excellent.","start":901.37,"duration":4.579},{"text":"And this is measured using the scalar product\nof the predicted output vector and the actual","start":905.949,"duration":4.63},{"text":"output vector.","start":910.579,"duration":2.01},{"text":"These two vectors are actually represented\nas column vectors, meaning a matrix with a","start":912.589,"duration":4.411},{"text":"single column. So to compute the scalar product,\nwe must transpose the predicted column vector","start":917.0,"duration":6.44},{"text":"\u00fb_j|i to get a row vector, and multiply this\nrow vector and the actual output vector v_j,","start":923.44,"duration":9.069},{"text":"which is a column vector. We will get a 1x1\nmatrix containing the scalar product of the","start":932.509,"duration":4.841},{"text":"vectors. Now of course we need to do this\nfor each predicted vector, so once again,","start":937.35,"duration":5.679},{"text":"we can use the matmul() function to perform\nall the matrix multiplications in just one","start":943.029,"duration":4.93},{"text":"shot.","start":947.959,"duration":1.511},{"text":"First we must use the tile() function to get\none copy of the actual output vectors v_j,","start":949.47,"duration":5.45},{"text":"for each primary capsule. Then we use matmul(),\ntelling it to transpose each matrix in the","start":954.92,"duration":7.22},{"text":"first array, on the fly, and lo-and-behold,\nwe get all the scalar products at once. So","start":962.14,"duration":6.77},{"text":"now, we have a measure of the agreement between\neach predicted vector and the actual output","start":968.91,"duration":5.989},{"text":"vector.","start":974.899,"duration":1.06},{"text":"We can then add these scalar products to the\nraw weights, using a simple addition.","start":975.959,"duration":6.07},{"text":"And the rest of round 2 is exactly the same\nas the end of round 1. The code is really","start":982.029,"duration":4.5},{"text":"identical, except we\u2019re now using the raw\nrouting weights of round 2. We compute their","start":986.529,"duration":5.06},{"text":"softmax to get the actual routing weights\nfor round 2, then we compute the weighted","start":991.589,"duration":4.31},{"text":"sum of all the predicted vectors for each\ndigit capsule, and finally we squash the result.","start":995.899,"duration":6.071},{"text":"And now we have the new digit capsule outputs,\nand we\u2019ve finished round 2. We could do","start":1001.97,"duration":4.38},{"text":"a few more rounds exactly like this one, but\nI\u2019ll stop now, and use the current output","start":1006.35,"duration":5.96},{"text":"vectors at the end of round 2 as the output\nof the digit capsules.","start":1012.31,"duration":5.269},{"text":"Now you probably noticed that I implemented\nthe routing algorithm\u2019s loop without an","start":1017.579,"duration":4.031},{"text":"actual loop. It\u2019s a bit like computing the\nsum of squares from 1 to 100, with this code.","start":1021.61,"duration":5.51},{"text":"Of course, this will build a very big TensorFlow\ngraph. But it works. You can think of it as","start":1027.12,"duration":6.09},{"text":"an unrolled loop. Now, a cleaner way to do\nthis would be to write a for loop in Python,","start":1033.21,"duration":5.73},{"text":"like this.","start":1038.94,"duration":1.0},{"text":"Ah, much better. However, it\u2019s important\nto understand that the resulting TensorFlow","start":1039.94,"duration":4.77},{"text":"graph will be absolutely identical to the\none produced by the previous code. All we","start":1044.71,"duration":5.29},{"text":"are doing here is constructing a graph, and\nTensorFlow will not even know that we used","start":1050.0,"duration":4.75},{"text":"a loop to build the graph. Again, this works\nfine, it\u2019s just that you end up with a very","start":1054.75,"duration":5.12},{"text":"large graph. So you can think of this loop\nas a static loop, that only runs at graph","start":1059.87,"duration":5.48},{"text":"construction time. If you want a dynamic loop,\none that TensorFlow itself will run, then","start":1065.35,"duration":5.501},{"text":"you must use TensorFlow\u2019s while_loop() function\nlike this.","start":1070.851,"duration":4.129},{"text":"The while_loop() function takes 3 parameters:\nthe first one is a function that must return","start":1074.98,"duration":6.68},{"text":"a tensor that will determine whether the loop\nshould go on or not, at each iteration. The","start":1081.66,"duration":6.541},{"text":"second parameter is also a function that must\nbuild the body of the loop, that will also","start":1088.201,"duration":6.069},{"text":"be evaluated at each iteration. And finally,\nthe third parameter contains a list of tensors","start":1094.27,"duration":5.65},{"text":"that will be sent to both the condition()\nand loop_body() functions at the first iteration.","start":1099.92,"duration":6.35},{"text":"For the following iterations, these functions\nwill receive the output of the loop_body()","start":1106.27,"duration":4.74},{"text":"function. So you can pause the video if you\nneed to take a closer look at this code. Once","start":1111.01,"duration":4.981},{"text":"you get it, you can try modifying my capsnet\nimplementation to use a dynamic loop rather","start":1115.991,"duration":4.849},{"text":"than a static unrolled loop. Apart from making\nthe code cleaner and the graph smaller, using","start":1120.84,"duration":6.46},{"text":"a dynamic loop allows you to change the number\nof iterations using the exact same model.","start":1127.3,"duration":5.56},{"text":"Also, if you set the swap_memory parameter\nof the while_loop() function, if you set it","start":1132.86,"duration":5.91},{"text":"to True, TensorFlow will automatically swap\nthe GPU memory to CPU memory to save GPU memory.","start":1138.77,"duration":8.07},{"text":"Since CPU RAM is much cheaper and abundant,\nthis can really be useful.","start":1146.84,"duration":6.0},{"text":"And that\u2019s it! We\u2019ve computed the output\nof the digit capsules. Cool! Now the length","start":1152.84,"duration":5.4},{"text":"of each output vector represents the probability\nthat a digit of that class is present in the","start":1158.24,"duration":6.54},{"text":"image.","start":1164.78,"duration":1.0},{"text":"So, let\u2019s compute these probabilities. For\nthis, we can\u2019t use tensorflow\u2019s norm()","start":1165.78,"duration":6.42},{"text":"function because training will explode if\nthere\u2019s a zero vector at any point, as I","start":1172.2,"duration":4.72},{"text":"mentionned earlier. So instead we use a home-made\nsafe_norm() function, similar to what we did","start":1176.92,"duration":6.36},{"text":"with the squash() function. And note that\nthe sum of the probabilities don\u2019t necessarily","start":1183.28,"duration":5.77},{"text":"add up to 1, because we are not using a softmax\nlayer. This makes it possible to detect multiple","start":1189.05,"duration":6.76},{"text":"different digits in the same image (but they\nall have to be different digits: you can detect","start":1195.81,"duration":5.69},{"text":"a 5 and 3, but you can\u2019t detect, say, two\n5s).","start":1201.5,"duration":4.74},{"text":"Next, let\u2019s predict the most likely digit.","start":1206.24,"duration":4.28},{"text":"We just use the argmax() function that gives\nuse the index of the highest probability.","start":1210.52,"duration":5.5},{"text":"The index happens to be the number, the digit\nitself. Note that we first get a tensor that","start":1216.02,"duration":6.41},{"text":"has a couple extra dimensions of size 1 at\nthe end, so we get rid of them using the squeeze()","start":1222.43,"duration":6.13},{"text":"function. If we called squeeze() without specifying\nthe axes to remove, it would remove all dimensions","start":1228.56,"duration":7.27},{"text":"of size 1. This would generally be okay, except\nif the batch size was equal to one, in which","start":1235.83,"duration":6.85},{"text":"case, we would be left with a scalar value,\nrather than an array, and we don\u2019t want","start":1242.68,"duration":4.74},{"text":"that. So it's better to specify the axes.","start":1247.42,"duration":4.0},{"text":"Great, now we have a capsule network that\ncan estimate class probabilities and make","start":1251.42,"duration":5.59},{"text":"predictions.","start":1257.01,"duration":1.37},{"text":"We can measure the model\u2019s accuracy on the\nbatch by simply comparing the predictions","start":1258.38,"duration":4.68},{"text":"and the labels. In this case the prediction\nfor the last digit in the batch is wrong,","start":1263.06,"duration":4.28},{"text":"it\u2019s 7 instead of 1. So we get 80% accuracy.","start":1267.34,"duration":5.26},{"text":"The code is really straightforward: we just\nuse the equal() function to compare the labels","start":1272.6,"duration":3.82},{"text":"and the predictions y_pred, and this gives\nus an array of booleans, so we cast these","start":1276.42,"duration":5.87},{"text":"booleans to floats, which gives us a bunch\nof 0s (for bad predictions) and 1s (for good","start":1282.29,"duration":5.94},{"text":"predictions), and we compute the mean to get\nthe batch\u2019s accuracy. The labels y are just","start":1288.23,"duration":6.45},{"text":"a regular placeholder. Nothing special.","start":1294.68,"duration":3.71},{"text":"And that\u2019s it, we have a full model, able\nto make predictions. Now let\u2019s look at the","start":1298.39,"duration":4.07},{"text":"training code. This diagram is about to get\npretty crowded so I\u2019ll remove the accuracy","start":1302.46,"duration":6.11},{"text":"for clarity.","start":1308.57,"duration":1.98},{"text":"And now, first, we want to compute the margin\nloss.","start":1310.55,"duration":3.12},{"text":"It\u2019s given by this equation. By the way,\nI made a mistake in my first video: I squared","start":1313.67,"duration":5.19},{"text":"the norms instead of the max operations. Sorry\nabout that. This here is the correct equation.","start":1318.86,"duration":7.94},{"text":"Computing it is pretty straightforward, so\nI won\u2019t go through it in details. The only","start":1326.8,"duration":3.83},{"text":"trick is to understand how you can easily\ncompute all the T_k values. For a given instance,","start":1330.63,"duration":5.88},{"text":"T_k is equal to 1 if a digit of class k is\npresent in the image, otherwise it\u2019s equal","start":1336.51,"duration":4.9},{"text":"to 0.","start":1341.41,"duration":1.0},{"text":"So, you can get all the T_k values for each\ninstance by simply converting the labels to","start":1342.41,"duration":5.26},{"text":"a one-hot representation. For example, if\nan instance\u2019s label is 3, then for this","start":1347.67,"duration":6.08},{"text":"instance, T will contain a 10 dimensional\nvector full of zeros except for a 1 at index","start":1353.75,"duration":5.05},{"text":"3. Okay! Next, we want to compute the reconstruction\nloss.","start":1358.8,"duration":4.73},{"text":"So first, we must send the outputs of the\ndigit capsules to a decoder that will try","start":1363.53,"duration":4.87},{"text":"to use them to reconstruct the input images.","start":1368.4,"duration":3.57},{"text":"This decoder is just a regular feedforward\nneural net composed of 3 fully connected layers.","start":1371.97,"duration":5.43},{"text":"It\u2019s really simple code, so you can pause\nthe video if you want to take a close look","start":1377.4,"duration":4.72},{"text":"at it. It outputs an array containing 784\nvalues from 0 to 1, for each instance, representing","start":1382.12,"duration":7.3},{"text":"the pixel intensities of 28x28 pixel images.","start":1389.42,"duration":5.55},{"text":"And that\u2019s it, we have our reconstructed\nimages! We can now compute the reconstruction","start":1394.97,"duration":4.8},{"text":"loss.","start":1399.77,"duration":1.15},{"text":"This is just the squared difference between\nthe input images and their reconstructions.","start":1400.92,"duration":5.16},{"text":"Since the input images are 28x28x1, we first\nreshape them to one dimension per instance","start":1406.08,"duration":6.03},{"text":"with 784 values each. Then we compute the\nsquared difference.","start":1412.11,"duration":5.65},{"text":"Now we can compute the final loss!","start":1417.76,"duration":2.28},{"text":"It\u2019s just the sum of the margin loss and\nthe reconstruction loss, scaled down to let","start":1420.04,"duration":5.71},{"text":"the margin loss dominate training. Pretty\nsimple, as you can see.","start":1425.75,"duration":3.56},{"text":"Now let\u2019s add the training operation.","start":1429.31,"duration":2.66},{"text":"The paper mentions they used TensorFlow\u2019s\nimplementation of the Adam optimizer, using","start":1431.97,"duration":4.71},{"text":"the default parameters, so let\u2019s do that.","start":1436.68,"duration":2.41},{"text":"We create the optimizer, and call its minimize()\nmethod to get the training operation that","start":1439.09,"duration":4.66},{"text":"will tweak the model parameters to minimize\nthe loss. We\u2019re almost done, but there\u2019s","start":1443.75,"duration":4.89},{"text":"one last detail I didn\u2019t mention in the\nfirst video. The paper indicates that the","start":1448.64,"duration":4.84},{"text":"outputs of the digit capsules should all be\nmasked out except for the ones corresponding","start":1453.48,"duration":4.94},{"text":"to the target digit.","start":1458.42,"duration":1.55},{"text":"So instead of sending the digit capsules\u2019\noutputs directly to the decoder, we want to","start":1459.97,"duration":5.56},{"text":"apply a mask first, like this.","start":1465.53,"duration":3.13},{"text":"The mask will have the same shape as the digit\ncapsules output array, and it will be equal","start":1468.66,"duration":5.75},{"text":"to 0 everywhere except for 1s at the location\nof the target digits.","start":1474.41,"duration":6.09},{"text":"By multiplying the digit capsules\u2019 output\nand the mask, we get the input to the decoder.","start":1480.5,"duration":5.6},{"text":"But there\u2019s one catch. This picture is good\nfor training, but at test time, we won\u2019t","start":1486.1,"duration":5.89},{"text":"have the labels. So instead, we will mask\nthe output vectors using the predicted classes","start":1491.99,"duration":6.19},{"text":"rather than the labels, like this.","start":1498.18,"duration":3.32},{"text":"Now we could build a different graph for training\nand for testing, but it wouldn\u2019t be very","start":1501.5,"duration":5.27},{"text":"convenient. So instead, let\u2019s build a condition\noperation.","start":1506.77,"duration":3.81},{"text":"We will add a boolean placeholder called mask_with_labels.\nIf it is true, then we use the labels to build","start":1510.58,"duration":6.58},{"text":"the mask.","start":1517.16,"duration":1.0},{"text":"If it is False, then we use the prediction.\nNote the difference. Okay.","start":1518.16,"duration":5.65},{"text":"And here\u2019s the code. We build the mask_with_labels\nplaceholder, which will default to False so","start":1523.81,"duration":4.97},{"text":"that we only need to set it during training.\nAnd then we define the reconstruction targets","start":1528.78,"duration":4.73},{"text":"using TensorFlow\u2019s cond() function. It takes\n3 arguments: the first one is a tensor representing","start":1533.51,"duration":7.53},{"text":"the condition, in this case simply the mask_with_labels\nplaceholder. The second parameter is a function","start":1541.04,"duration":5.61},{"text":"that returns the tensor to use if the condition\nis True, and the third parameter is a function","start":1546.65,"duration":5.59},{"text":"that returns the tensor to use if the condition\nif False. Then to build the mask, we simply","start":1552.24,"duration":5.22},{"text":"use the one_hot() function. Now there actually\none slight problem with this implementation,","start":1557.46,"duration":6.26},{"text":"and to explain it, I need to step back for\na second and talk about how TensorFlow evaluates","start":1563.72,"duration":5.45},{"text":"a tensor.","start":1569.17,"duration":2.08},{"text":"Suppose we built this graph, these are all\ntensorflow operations, and we want to evaluate","start":1571.25,"duration":5.77},{"text":"the output of operation A.","start":1577.02,"duration":2.58},{"text":"The first thing TensorFlow will do is resolve\nthe dependencies.","start":1579.6,"duration":4.32},{"text":"It will find all the operations that A depends\non, directly or indirectly, by traversing","start":1583.92,"duration":6.43},{"text":"the graph backwards. In this case it will\nfind C, D and F.","start":1590.35,"duration":4.85},{"text":"Next, it will run any operation that has no\ninputs. These are called root nodes. In this","start":1595.2,"duration":5.58},{"text":"case F.","start":1600.78,"duration":1.94},{"text":"Once F is evaluated, operations C and D now\nhave all the inputs they need, so they can","start":1602.72,"duration":5.17},{"text":"be evaluated, and TensorFlow will actually\ntry to run them in parallel.","start":1607.89,"duration":5.45},{"text":"Say D finishes first, A still has one unevaluated\ninput so it can\u2019t run yet.","start":1613.34,"duration":6.91},{"text":"But as soon as C is finished, A can be evaluated.","start":1620.25,"duration":3.75},{"text":"And once it\u2019s done, the eval() method returns\nthe result, and we\u2019re good.","start":1624.0,"duration":3.85},{"text":"You can actually evaluate multiple operations\nat once, for example A and E, and the process","start":1627.85,"duration":5.22},{"text":"is really the same.\nIt finds all the dependencies, runs the root","start":1633.07,"duration":4.8},{"text":"operations, and then, you know, goes upward\nrunning every operation whose inputs are satisfied.","start":1637.87,"duration":6.86},{"text":"And once it's got both the values for both\nA and E, it returns the results.","start":1644.73,"duration":4.44},{"text":"So let\u2019s apply this to our reconstruction\ntargets. This tensor is the output of the","start":1649.17,"duration":6.69},{"text":"cond() operation, which has 3 parameters,\nmask_with_labels, a function that returns","start":1655.86,"duration":7.27},{"text":"y, and a function that returns y_pred.","start":1663.13,"duration":3.25},{"text":"And when we evaluate the reconstruction_targets,\nor any tensor that depends on it, such as","start":1666.38,"duration":5.3},{"text":"the final loss, which depends on the reconstruction\nloss, which eventually depends on the reconstruction_targets.","start":1671.68,"duration":5.88},{"text":"Well, what happens it, as earlier, TensorFlow\nstarts by resolving the dependencies. It finds","start":1677.56,"duration":5.83},{"text":"all three bottom nodes.","start":1683.39,"duration":2.51},{"text":"And it evaluates them all!","start":1685.9,"duration":1.8},{"text":"So y_pred may finish first. Since these operations\nare run in parallel, there\u2019s no way to know","start":1687.7,"duration":4.95},{"text":"in which order they will finish.","start":1692.65,"duration":2.08},{"text":"So, you know, y may finish next.\nAnd finally mask_with_labels finishes. So","start":1694.73,"duration":5.84},{"text":"suppose it evaluates to True. Now the reconstruction_targets\nhas all the inputs it needs, so it can be","start":1700.57,"duration":6.18},{"text":"evaluated.","start":1706.75,"duration":1.37},{"text":"And of course it does the right thing, since\nmask_with_labels is True, it returns the value","start":1708.12,"duration":4.49},{"text":"of y. Which is good.\nBut notice that y_pred was evaluated for nothing,","start":1712.61,"duration":5.35},{"text":"we\u2019re not using its output. It\u2019s not a\nbig deal since during training we need to","start":1717.96,"duration":4.34},{"text":"evaluate the margin loss, which depends on\nthe estimated class probabilities, which is","start":1722.3,"duration":4.83},{"text":"just one step away from the predictions, so\ncomputing the predictions won\u2019t add much","start":1727.13,"duration":4.36},{"text":"overhead. But still, it\u2019s a bit unfortunate.","start":1731.49,"duration":4.1},{"text":"Now suppose mask_with_labels evaluates to\nFalse.","start":1735.59,"duration":2.83},{"text":"Then, again, the reconstruction_targets will\ndo the right thing, it will output the value","start":1738.42,"duration":5.22},{"text":"of y_pred.","start":1743.64,"duration":1.0},{"text":"But this time, we evaluated y for nothing.\nIt\u2019s just a placeholder, so it won\u2019t add","start":1744.64,"duration":5.671},{"text":"much computation time, but it means that we\nmust feed y, even if mask_with_labels is False.","start":1750.311,"duration":5.759},{"text":"Well actually we can just pass an empty array,\nthat's fine. So it will work, but it's kind","start":1756.07,"duration":5.74},{"text":"of ugly.","start":1761.81,"duration":1.9},{"text":"So this unfortunate situation is due to the\nfact that the functions we passed to the cond()","start":1763.71,"duration":5.06},{"text":"function, do not actually create any tensor,\nthey just return tensors that were created","start":1768.77,"duration":5.81},{"text":"outside of these functions. If you build tensors\nwithin these functions, then TensorFlow will","start":1774.58,"duration":5.87},{"text":"do what you expect. It will stitch together\nthe partial graphs created by these functions","start":1780.45,"duration":5.5},{"text":"into a graph that will properly handle the\ndependencies. So you might be able to modify","start":1785.95,"duration":5.59},{"text":"my code and fix this ugliness. I tried, but\nI ended up with pretty convoluted code, so","start":1791.54,"duration":4.941},{"text":"I decided to stick with this implementation.\nI hope it won\u2019t keep you awake at night.","start":1796.481,"duration":5.119},{"text":"Sooo! We\u2019ve actually finished! Here\u2019s\nthe full picture again. The construction phase","start":1801.6,"duration":5.38},{"text":"is over, our graph is built, now on to the\nexecution phase, let\u2019s run this graph. First,","start":1806.98,"duration":7.23},{"text":"let\u2019s look at the training code.","start":1814.21,"duration":2.11},{"text":"It\u2019s really really completely standard.\nWe create a session, if a checkpoint file","start":1816.32,"duration":6.11},{"text":"exists, load it, or else initialize all the\nvariables. Then run the main training loop,","start":1822.43,"duration":6.97},{"text":"for a number of epochs, and for each epoch,\nrun enough iterations to go through the full","start":1829.4,"duration":4.8},{"text":"training set. And inside this loop, we simply\nevaluate the training operation, and the loss,","start":1834.2,"duration":7.92},{"text":"on the next batch. We feed the images and\nthe labels of the current training batch,","start":1842.12,"duration":5.69},{"text":"and we set mask_with_labels to True. That\u2019s\npretty much all there is to it. In the notebook,","start":1847.81,"duration":5.58},{"text":"I also added a simple implementation of early\nstopping, and I print out the progress, plus","start":1853.39,"duration":5.06},{"text":"I evaluate the model on the validation set\nat the end of each epoch. But the most important","start":1858.45,"duration":5.28},{"text":"part is here.","start":1863.73,"duration":1.44},{"text":"After training, I just run a few test images\nthrough the network and get the predictions","start":1865.17,"duration":5.2},{"text":"and reconstructions. As you can see, the predictions\nare all correct, and the reconstructions are","start":1870.37,"duration":5.65},{"text":"pretty good, they're pretty close to the original\nimages, except that they\u2019re slightly fuzzier,","start":1876.02,"duration":4.57},{"text":"as you can see.","start":1880.59,"duration":1.82},{"text":"Here\u2019s the code, there\u2019s really nothing\nspecial about it: I take a few test images,","start":1882.41,"duration":5.54},{"text":"I start a session and load the model, then\nI just evaluate the predictions and the decoder\u2019s","start":1887.95,"duration":7.07},{"text":"output (and I also get the capsules\u2019 outputs\nso I can tweak them later). The ugliness I","start":1895.02,"duration":7.19},{"text":"mentionned earlier is right here. I'm forced\nto pass an empty array. This value will be","start":1902.21,"duration":6.83},{"text":"ignored anyway.","start":1909.04,"duration":1.0},{"text":"And finally, the code tweaks the output vectors\nand passes the result to the decoder. So we","start":1910.04,"duration":6.54},{"text":"can see what each of of the 16 dimensions\nrepresent in the digit capsule\u2019s output","start":1916.58,"duration":5.28},{"text":"vector. For example, this image shows the\nreconstructions we get by tweaking the first","start":1921.86,"duration":4.48},{"text":"parameter (the notebook produces one such\nimage for each of the 16 parameters). And","start":1926.34,"duration":5.59},{"text":"as you can see, in the first, second and last\nrows, we see that the digits become thinner","start":1931.93,"duration":6.26},{"text":"and thinner, going to the right, or thicker\nand thicker to the left, so it holds information","start":1938.19,"duration":5.26},{"text":"about thickness. And in the middle row, you\ncan see that the bottom part of the number","start":1943.45,"duration":5.48},{"text":"5 gets lifted towards the top, so probably\nthat's what this parameter does for this digit.","start":1948.93,"duration":7.98},{"text":"Before I finish, I\u2019d like to thank everyone\nwho shared and commented on my first video,","start":1956.91,"duration":5.11},{"text":"I really had no idea it would receive such\nan enthusiastic response, and I\u2019m very very","start":1962.02,"duration":5.48},{"text":"grateful to all of you, it definitely motivates\nme to create more videos. If you want to learn","start":1967.5,"duration":5.0},{"text":"more about Machine Learning and support this\nchannel, check out my O\u2019Reilly book Hands-on","start":1972.5,"duration":4.28},{"text":"Machine Learning with Scikit-Learn and TensorFlow,\nI\u2019ll leave the links in the video description.","start":1976.78,"duration":4.41},{"text":"If you speak German, there\u2019s actually a\nGerman translation coming up for Christmas.","start":1981.19,"duration":3.77},{"text":"And if you speak French, the translation is\nalready available. It was split in two books","start":1984.96,"duration":4.61},{"text":"but it\u2019s really the same content.\nAnd that\u2019s all I had for today, I hope you","start":1989.57,"duration":4.04},{"text":"enjoyed this video and that you learned a\nthing or two about TensorFlow and capsule","start":1993.61,"duration":3.68},{"text":"networks. If you did, please, like, share,\ncomment, subscribe, and click on the bell","start":1997.29,"duration":4.59},{"text":"icon next to the subscribe button, to receive\nnotifications when I upload new videos. See","start":2001.88,"duration":4.711},{"text":"you next time!","start":2006.591,"duration":0.519}]}}